{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mostafa-ja/mal_adv3/blob/main/4_adverserial_attacks_ipynb_(2).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy import sparse\n",
        "import gdown\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "import time"
      ],
      "metadata": {
        "id": "JKDdI3K9LrlF"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NgkPo5lth4ru"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "download_link = 'https://github.com/mostafa-ja/mal_adv3/raw/main/data/X_redefined_sparse_matrix.npz'\n",
        "output_filepath = '/content/'\n",
        "gdown.download(download_link, output_filepath)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "f5e87ca6-40b8-448a-83fc-fdf8ef1e0206",
        "id": "sOMLdx09h5jS"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv3/raw/main/data/X_redefined_sparse_matrix.npz\n",
            "To: /content/X_redefined_sparse_matrix.npz\n",
            "100%|██████████| 2.31M/2.31M [00:00<00:00, 20.6MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/X_redefined_sparse_matrix.npz'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "download_link = 'https://github.com/mostafa-ja/mal_adv3/raw/main/data/DNN_params%20.pth'\n",
        "output_filepath = '/content/'\n",
        "gdown.download(download_link, output_filepath)"
      ],
      "metadata": {
        "id": "y3O3o6ZHLpI8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "7591b8cf-f96a-4335-ef35-d1ddca973808"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv3/raw/main/data/DNN_params%20.pth\n",
            "To: /content/DNN_params%20.pth\n",
            "100%|██████████| 8.17M/8.17M [00:00<00:00, 39.0MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/DNN_params%20.pth'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "download_link = 'https://github.com/mostafa-ja/mal_adv3/raw/main/data/labels.pt'\n",
        "output_filepath = '/content/'\n",
        "gdown.download(download_link, output_filepath)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "9AHVFwq3i5eQ",
        "outputId": "509cc7b4-881c-430c-a316-ff2c66a81011"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv3/raw/main/data/labels.pt\n",
            "To: /content/labels.pt\n",
            "100%|██████████| 517k/517k [00:00<00:00, 5.38MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/labels.pt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "download_link = 'https://github.com/mostafa-ja/mal_adv3/raw/main/data/vocab.pkl'\n",
        "output_filepath = '/content/'\n",
        "gdown.download(download_link, output_filepath)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "H-VZRklXi5J9",
        "outputId": "e595b898-c81b-44c5-c2f3-f4b14b7aeda0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv3/raw/main/data/vocab.pkl\n",
            "To: /content/vocab.pkl\n",
            "100%|██████████| 9.18M/9.18M [00:00<00:00, 61.8MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/vocab.pkl'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "download_link = 'https://github.com/mostafa-ja/mal_adv3/raw/main/data/adverserial_attacks_functions.py'\n",
        "output_filepath = '/content/'\n",
        "gdown.download(download_link, output_filepath)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "7GRMOHl4i4zE",
        "outputId": "bef4df72-25d9-4c86-d36c-f5d4270e569c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv3/raw/main/data/adverserial_attacks_functions.py\n",
            "To: /content/adverserial_attacks_functions.py\n",
            "45.5kB [00:00, 51.7MB/s]                   \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/adverserial_attacks_functions.py'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "download_link = 'https://github.com/mostafa-ja/mal_adv3/raw/main/data/best_model%20_RFGSM.pth'\n",
        "output_filepath = '/content/'\n",
        "gdown.download(download_link, output_filepath)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "Sbjk1-LGi4bF",
        "outputId": "0a44008d-b758-4ca5-82ef-097e25daea9c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv3/raw/main/data/best_model%20_RFGSM.pth\n",
            "To: /content/best_model%20_RFGSM.pth\n",
            "100%|██████████| 8.17M/8.17M [00:00<00:00, 53.9MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/best_model%20_RFGSM.pth'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dictionary from the file\n",
        "with open('vocab.pkl', 'rb') as f:\n",
        "    vocab = pickle.load(f)\n",
        "\n",
        "for i, (key, value) in enumerate(vocab.items()):\n",
        "    print((key, value))\n",
        "    if i >= 5:\n",
        "        break"
      ],
      "metadata": {
        "id": "L0rDH5Q6HOmd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "529b61b0-095c-4691-eb08-5236c3865746"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('android/media/mediaplayer->start', 141045)\n",
            "('android/app/activity->setcontentview', 140900)\n",
            "('android/os/vibrator->cancel', 141093)\n",
            "('android.permission.vibrate', 140720)\n",
            "('android.hardware.touchscreen', 137091)\n",
            "('android.intent.action.main', 138335)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Memory-Efficient but slow when we want to convert back to tensor by\n",
        ".to_dense().to(torch.float32)\n",
        "\n",
        "```\n",
        "from scipy import sparse\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load dataset\n",
        "X_redefined = sparse.load_npz(\"X_redefined_sparse_matrix.npz\")\n",
        "labels_tensor = torch.load('labels.pt')\n",
        "\n",
        "# Split data into train, validation, and test sets with stratified sampling\n",
        "X_train_val, X_test, labels_train_val, labels_test = train_test_split(X_redefined, labels_tensor, test_size=0.2, stratify=labels_tensor, random_state=42)\n",
        "X_train, X_val, labels_train, labels_val = train_test_split(X_train_val, labels_train_val, test_size=0.2, stratify=labels_train_val, random_state=42)\n",
        "\n",
        "# Create PyTorch sparse tensors directly from the sparse matrices\n",
        "train_dataset = TensorDataset(torch.sparse_coo_tensor(torch.tensor(X_train.nonzero()), torch.tensor(X_train.data), X_train.shape), labels_train)\n",
        "val_dataset = TensorDataset(torch.sparse_coo_tensor(torch.tensor(X_val.nonzero()), torch.tensor(X_val.data), X_val.shape), labels_val)\n",
        "test_dataset = TensorDataset(torch.sparse_coo_tensor(torch.tensor(X_test.nonzero()), torch.tensor(X_test.data), X_test.shape), labels_test)\n",
        "\n",
        "# Clear unnecessary variables\n",
        "del X_redefined, labels_tensor, X_train_val, X_test, labels_train_val, labels_test, X_train, X_val, labels_train, labels_val\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "MhY3eqbYzWAq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "X_redefined = sparse.load_npz(\"X_redefined_sparse_matrix.npz\")\n",
        "labels_tensor = torch.load('labels.pt')\n",
        "\n",
        "# Split data into train, validation, and test sets with stratified sampling\n",
        "X_train_val, X_test, labels_train_val, labels_test = train_test_split(X_redefined, labels_tensor, test_size=0.2, stratify=labels_tensor, random_state=42)\n",
        "X_train, X_val, labels_train, labels_val = train_test_split(X_train_val, labels_train_val, test_size=0.2, stratify=labels_train_val, random_state=42)\n",
        "\n",
        "# Combine features and labels into datasets\n",
        "# we use dtype=torch.int8, for Memory-Efficient here, later we will convert to float\n",
        "train_dataset = TensorDataset(torch.tensor(X_train.toarray(), dtype=torch.int8), labels_train)\n",
        "val_dataset = TensorDataset(torch.tensor(X_val.toarray(), dtype=torch.int8), labels_val)\n",
        "test_dataset = TensorDataset(torch.tensor(X_test.toarray(), dtype=torch.int8), labels_test)\n",
        "\n",
        "# Clear unnecessary variables\n",
        "del X_redefined, labels_tensor, X_train_val, X_test, labels_train_val, labels_test, X_train, X_val, labels_train, labels_val"
      ],
      "metadata": {
        "id": "AWfz_HxX0rYj"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the DataLoader for training, validation, and test sets\n",
        "batch_size = 256\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "T97WdRj9s2hk"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MalwareDetectionModel(nn.Module):\n",
        "    def __init__(self, input_size=10000, hidden_1_size=200, hidden_2_size=200, num_labels=2, dropout_prob=0.6):\n",
        "        super(MalwareDetectionModel, self).__init__()\n",
        "\n",
        "        self.input_size = input_size\n",
        "        self.hidden_1_size = hidden_1_size\n",
        "        self.hidden_2_size = hidden_2_size\n",
        "        self.num_labels = num_labels\n",
        "        self.dropout_prob = dropout_prob\n",
        "\n",
        "        self.fc1 = nn.Linear(input_size, hidden_1_size)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.dropout1 = nn.Dropout(dropout_prob)\n",
        "        self.fc2 = nn.Linear(hidden_1_size, hidden_2_size)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.dropout2 = nn.Dropout(dropout_prob)\n",
        "        self.fc3 = nn.Linear(hidden_2_size, num_labels)\n",
        "        self.log_softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.dropout1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc3(x)\n",
        "        x = self.log_softmax(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "xdNbTvxTTqyw"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(0)\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FkBU7G3V6Qz1",
        "outputId": "a6abb676-8b53-4d55-cd27-b1b79a73f226"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from adverserial_attacks_functions import *\n"
      ],
      "metadata": {
        "id": "OU1MMeo-7suv"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MalwareDetectionModel().to(device)"
      ],
      "metadata": {
        "id": "0MavlKAt6mb8"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def adversarial_training(model, train_loader, val_loader, attack, adv_epochs=10, lr=0.001, weight_decay=0., device=device, verbose=True, **kwargs):\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    total_time = 0.\n",
        "    nbatches = len(train_loader)\n",
        "    best_acc_val = 0.\n",
        "    acc_val_adv_be = 0.\n",
        "    best_epoch = 0\n",
        "\n",
        "    for epoch in range(adv_epochs):\n",
        "        epoch_losses = []\n",
        "        epoch_accuracies = []\n",
        "\n",
        "        for idx_batch, (x_batch, y_batch) in enumerate(train_loader):\n",
        "            x_batch, y_batch = x_batch.to(torch.float32).to(device), y_batch.to(device)\n",
        "            batch_size = x_batch.shape[0]\n",
        "\n",
        "            # Separate malicious and benign samples\n",
        "            mal_x_batch, ben_x_batch = x_batch[y_batch.squeeze() == 1], x_batch[y_batch.squeeze() == 0]\n",
        "            mal_y_batch, ben_y_batch = y_batch[y_batch.squeeze() == 1], y_batch[y_batch.squeeze() == 0]\n",
        "\n",
        "            # Generate adversarial examples\n",
        "            model.eval()\n",
        "            pertb_mal_x = attack(mal_x_batch, mal_y_batch, model, **kwargs)\n",
        "            x_batch = torch.cat([ben_x_batch, pertb_mal_x], dim=0)\n",
        "            y_batch = torch.cat([ben_y_batch, mal_y_batch])\n",
        "            model.train()\n",
        "\n",
        "            # Forward pass and backward pass\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(x_batch)\n",
        "            loss_train = criterion(outputs, y_batch.view(-1).long())\n",
        "            loss_train.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Calculate metrics\n",
        "            epoch_losses.append(loss_train.item())\n",
        "            _, predicted = torch.topk(outputs, k=1)\n",
        "            acc_train = (predicted == y_batch).sum().item() / len(y_batch)\n",
        "            epoch_accuracies.append(acc_train)\n",
        "\n",
        "            # Print batch level information\n",
        "            if verbose:\n",
        "                print(f'Mini batch: {idx_batch + 1}/{nbatches} | Epoch: {epoch + 1}/{adv_epochs} | Batch Loss: {loss_train.item():.4f} | Batch Accuracy: {acc_train * 100:.2f}%')\n",
        "\n",
        "        # Calculate epoch level metrics\n",
        "        mean_loss = np.mean(epoch_losses)\n",
        "        mean_accuracy = np.mean(epoch_accuracies) * 100\n",
        "\n",
        "        # Print epoch level information\n",
        "        if verbose:\n",
        "            print(f'Training loss (epoch level): {mean_loss:.4f} | Train accuracy: {mean_accuracy:.2f}%')\n",
        "\n",
        "        # Evaluation on validation set\n",
        "        model.eval()\n",
        "        avg_acc_ad_val = []\n",
        "        avg_acc_val = []\n",
        "        for x_val, y_val in val_loader:\n",
        "            x_val, y_val = x_val.to(device), y_val.to(device)\n",
        "            outputs = model(x_val)\n",
        "            _, predicted = torch.topk(outputs, k=1)\n",
        "            acc_val = (predicted == y_val).sum().item() / len(y_val)\n",
        "            avg_acc_val.append(acc_val)\n",
        "\n",
        "            # Generate adversarial examples for validation set\n",
        "            mal_x_batch, mal_y_batch = x_val[y_val.squeeze() == 1], y_val[y_val.squeeze() == 1]\n",
        "            pertb_mal_x = attack(mal_x_batch, mal_y_batch, model)\n",
        "            outputs = model(pertb_mal_x)\n",
        "            _, y_pred = torch.topk(outputs, k=1)\n",
        "\n",
        "            acc_ad_val = (y_pred == 1.).sum().item() / len(y_pred)\n",
        "            avg_acc_ad_val.append(acc_ad_val)\n",
        "\n",
        "        # Calculate validation accuracy\n",
        "        assert len(avg_acc_ad_val) > 0\n",
        "        acc_all = (np.mean(avg_acc_val) + np.mean(avg_acc_ad_val)) / 2.\n",
        "\n",
        "        # Update best validation accuracy\n",
        "        if acc_all >= best_acc_val:\n",
        "            best_acc_val = acc_all\n",
        "            acc_val_adv_be = np.mean(avg_acc_ad_val)\n",
        "            best_epoch = epoch + 1\n",
        "            torch.save(model.state_dict(), 'best_model.pth')\n",
        "\n",
        "        # Print validation results\n",
        "        if verbose:\n",
        "            print(f\"\\tVal accuracy(without attack) {np.mean(avg_acc_val) * 100:.4}% and accuracy(with attack) {np.mean(avg_acc_ad_val) * 100:.4}% under attack and overall accuracy {acc_all * 100:.4}%.\")\n",
        "            print(f\"\\tModel select at epoch {best_epoch} with validation accuracy {best_acc_val * 100:.4}% and accuracy {acc_val_adv_be * 100:.4}% under attack.\")\n"
      ],
      "metadata": {
        "id": "B0v7V8W7lidM"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# AT-rFGSM: Adversarial Taraining based on rFGSM attack\n",
        "attack_param = {\"k\":50, \"epsilon\":0.02, 'random':True, \"is_sample\":False, 'is_report_loss_diff':True}\n",
        "adversarial_training(model, train_loader, val_loader, adv_epochs=50, attack=dfgsm_k, **attack_param)"
      ],
      "metadata": {
        "id": "E8zaItRUryCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def adv_predict(test_loader, model, attack, device, **kwargs):\n",
        "    model.eval()\n",
        "    avg_acc_ad_test = []\n",
        "    avg_acc_test = []\n",
        "    for x_test, y_test in test_loader:\n",
        "        x_test, y_test = x_test.to(torch.float32).to(device), y_test.to(device)\n",
        "        outputs = model(x_test)\n",
        "        _, predicted = torch.topk(outputs, k=1)\n",
        "        acc_test = (predicted == y_test).sum().item() / len(y_test)\n",
        "        avg_acc_test.append(acc_test)\n",
        "\n",
        "        # Generate adversarial examples for test set\n",
        "        mal_x_batch, mal_y_batch = x_test[y_test.squeeze() == 1], y_test[y_test.squeeze() == 1]\n",
        "        pertb_mal_x = attack(mal_x_batch, mal_y_batch, model, **kwargs)\n",
        "        outputs = model(pertb_mal_x)\n",
        "        _, y_pred = torch.topk(outputs, k=1)\n",
        "\n",
        "        acc_ad_test = (y_pred == 1.).sum().item() / len(y_pred)\n",
        "        avg_acc_ad_test.append(acc_ad_test)\n",
        "\n",
        "    # Calculate test accuracy\n",
        "    print(f\"Adversarial accuracy (without attack): {np.mean(avg_acc_test) * 100:.4}% | Under attack: {np.mean(avg_acc_ad_test) * 100:.4}%.\")\n"
      ],
      "metadata": {
        "id": "a1_OgLgnvQLb"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of your model\n",
        "model_AT_rFGSM = MalwareDetectionModel().to(device)\n",
        "\n",
        "# Load model parameters\n",
        "model_AT_rFGSM.load_state_dict(torch.load('best_model%20_RFGSM.pth', map_location=torch.device(device)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNbO4UcTbDau",
        "outputId": "f26b6af0-fd9f-4343-9a40-a41737ebe5f9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adv_predict(test_loader, model, attack=pgd, is_report_loss_diff=False, device=device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hZyGeB3umw4",
        "outputId": "c13bb3e5-6f66-4298-bdf2-2341c3cbb379"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adversarial accuracy (without attack): 95.69% | Under attack: 0.0%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adv_predict(test_loader, model_AT_rFGSM, attack=pgd, is_report_loss_diff=False, device=device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9I9WmuKLbSc4",
        "outputId": "b4aee245-0c81-4900-dd03-bcc6952e0d23"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adversarial accuracy (without attack): 99.36% | Under attack: 90.83%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attack_params = {\"k\":50, \"epsilon\":0.02, 'is_report_loss_diff' : False}\n",
        "adv_predict(test_loader, model_AT_rFGSM, dfgsm_k, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJpu7bfRw4U0",
        "outputId": "c8baee91-b903-4424-ed1b-0e63071c55cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adversarial accuracy (without attack): 99.25% | Under attack: 83.43%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attack_params = {\"k\":150,'is_report_loss_diff' : False}\n",
        "adv_predict(test_loader, model_AT_rFGSM, grosse_k, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFCunjZGxR2P",
        "outputId": "03859ca1-a3cf-4757-a573-1ffd2249eb72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adversarial accuracy (without attack): 99.25% | Under attack: 87.09%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attack_params = {'step_lengths':{\"l1\": 1.0, \"l2\": 0.05, \"linf\": 0.001}, \"steps\":500}\n",
        "adv_predict(test_loader, model_AT_rFGSM, StepwiseMax_onestep2, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xylm8-33y2uc",
        "outputId": "76299ea8-4ec6-425a-bd64-d96e9dc5264f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step-wise max: attack effectiveness 0.000%.\n",
            "step-wise max: attack effectiveness 10.000%.\n",
            "step-wise max: attack effectiveness 33.333%.\n",
            "step-wise max: attack effectiveness 0.000%.\n",
            "step-wise max: attack effectiveness 15.789%.\n",
            "step-wise max: attack effectiveness 20.000%.\n",
            "step-wise max: attack effectiveness 25.000%.\n",
            "step-wise max: attack effectiveness 12.500%.\n",
            "step-wise max: attack effectiveness 12.500%.\n",
            "step-wise max: attack effectiveness 7.692%.\n",
            "step-wise max: attack effectiveness 11.765%.\n",
            "step-wise max: attack effectiveness 15.385%.\n",
            "step-wise max: attack effectiveness 14.286%.\n",
            "step-wise max: attack effectiveness 20.000%.\n",
            "step-wise max: attack effectiveness 0.000%.\n",
            "step-wise max: attack effectiveness 5.882%.\n",
            "step-wise max: attack effectiveness 15.789%.\n",
            "step-wise max: attack effectiveness 8.333%.\n",
            "step-wise max: attack effectiveness 12.500%.\n",
            "step-wise max: attack effectiveness 20.000%.\n",
            "step-wise max: attack effectiveness 11.111%.\n",
            "step-wise max: attack effectiveness 7.692%.\n",
            "step-wise max: attack effectiveness 0.000%.\n",
            "step-wise max: attack effectiveness 33.333%.\n",
            "step-wise max: attack effectiveness 11.111%.\n",
            "step-wise max: attack effectiveness 0.000%.\n",
            "step-wise max: attack effectiveness 0.000%.\n",
            "step-wise max: attack effectiveness 7.692%.\n",
            "step-wise max: attack effectiveness 9.091%.\n",
            "step-wise max: attack effectiveness 10.000%.\n",
            "step-wise max: attack effectiveness 7.143%.\n",
            "step-wise max: attack effectiveness 15.385%.\n",
            "step-wise max: attack effectiveness 7.143%.\n",
            "step-wise max: attack effectiveness 14.286%.\n",
            "step-wise max: attack effectiveness 7.692%.\n",
            "step-wise max: attack effectiveness 23.077%.\n",
            "step-wise max: attack effectiveness 16.667%.\n",
            "step-wise max: attack effectiveness 8.333%.\n",
            "step-wise max: attack effectiveness 22.222%.\n",
            "step-wise max: attack effectiveness 0.000%.\n",
            "step-wise max: attack effectiveness 27.273%.\n",
            "step-wise max: attack effectiveness 13.333%.\n",
            "step-wise max: attack effectiveness 17.647%.\n",
            "step-wise max: attack effectiveness 26.667%.\n",
            "step-wise max: attack effectiveness 20.000%.\n",
            "step-wise max: attack effectiveness 8.333%.\n",
            "step-wise max: attack effectiveness 9.091%.\n",
            "step-wise max: attack effectiveness 0.000%.\n",
            "step-wise max: attack effectiveness 16.667%.\n",
            "step-wise max: attack effectiveness 0.000%.\n",
            "step-wise max: attack effectiveness 9.091%.\n",
            "step-wise max: attack effectiveness 16.667%.\n",
            "step-wise max: attack effectiveness 18.182%.\n",
            "step-wise max: attack effectiveness 0.000%.\n",
            "step-wise max: attack effectiveness 8.333%.\n",
            "step-wise max: attack effectiveness 0.000%.\n",
            "step-wise max: attack effectiveness 0.000%.\n",
            "step-wise max: attack effectiveness 0.000%.\n",
            "step-wise max: attack effectiveness 0.000%.\n",
            "step-wise max: attack effectiveness 18.182%.\n",
            "step-wise max: attack effectiveness 35.714%.\n",
            "step-wise max: attack effectiveness 14.286%.\n",
            "step-wise max: attack effectiveness 10.000%.\n",
            "step-wise max: attack effectiveness 8.333%.\n",
            "step-wise max: attack effectiveness 7.143%.\n",
            "step-wise max: attack effectiveness 9.091%.\n",
            "step-wise max: attack effectiveness 7.692%.\n",
            "step-wise max: attack effectiveness 27.273%.\n",
            "step-wise max: attack effectiveness 15.385%.\n",
            "step-wise max: attack effectiveness 14.286%.\n",
            "step-wise max: attack effectiveness 0.000%.\n",
            "step-wise max: attack effectiveness 8.333%.\n",
            "step-wise max: attack effectiveness 12.500%.\n",
            "step-wise max: attack effectiveness 16.667%.\n",
            "step-wise max: attack effectiveness 0.000%.\n",
            "step-wise max: attack effectiveness 28.571%.\n",
            "step-wise max: attack effectiveness 0.000%.\n",
            "step-wise max: attack effectiveness 20.000%.\n",
            "step-wise max: attack effectiveness 7.692%.\n",
            "step-wise max: attack effectiveness 18.182%.\n",
            "step-wise max: attack effectiveness 11.111%.\n",
            "step-wise max: attack effectiveness 13.333%.\n",
            "step-wise max: attack effectiveness 0.000%.\n",
            "step-wise max: attack effectiveness 16.667%.\n",
            "step-wise max: attack effectiveness 33.333%.\n",
            "step-wise max: attack effectiveness 25.000%.\n",
            "step-wise max: attack effectiveness 0.000%.\n",
            "step-wise max: attack effectiveness 10.000%.\n",
            "step-wise max: attack effectiveness 21.429%.\n",
            "step-wise max: attack effectiveness 14.286%.\n",
            "step-wise max: attack effectiveness 22.222%.\n",
            "step-wise max: attack effectiveness 6.250%.\n",
            "step-wise max: attack effectiveness 9.091%.\n",
            "step-wise max: attack effectiveness 6.667%.\n",
            "step-wise max: attack effectiveness 20.000%.\n",
            "step-wise max: attack effectiveness 20.000%.\n",
            "step-wise max: attack effectiveness 0.000%.\n",
            "step-wise max: attack effectiveness 20.000%.\n",
            "step-wise max: attack effectiveness 0.000%.\n",
            "step-wise max: attack effectiveness 35.714%.\n",
            "step-wise max: attack effectiveness 12.500%.\n",
            "Adversarial accuracy (without attack): 99.25% | Under attack: 87.71%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define different attacks with their parameters\n",
        "attacks = [\n",
        "    (dfgsm_k, {\"k\":100, \"epsilon\":0.02, 'is_report_loss_diff' : False}),\n",
        "    (bga_k, {\"k\":100, 'is_report_loss_diff' : False}),\n",
        "    (bca_k, {\"k\":100, 'is_report_loss_diff' : False}),\n",
        "    (grosse_k, {\"k\":100, 'is_report_loss_diff' : False}),\n",
        "\n",
        "    (pgd, {'k': 100, 'step_length': 1., 'norm': 'l1', 'is_report_loss_diff' : False}),\n",
        "    (pgd, {'k': 200, 'step_length': 0.05, 'norm': 'l2', 'is_report_loss_diff' : False}),\n",
        "    (pgd, {'k': 100, 'step_length': 0.02, 'norm': 'linf', 'is_report_loss_diff' : False}),\n",
        "    (StepwiseMax_onestep2, {'step_lengths':{\"l1\": 1.0, \"l2\": 0.05, \"linf\": 0.0008}, \"steps\":650}),\n",
        "\n",
        "    # Add more attacks as needed\n",
        "]\n",
        "\n",
        "# Iterate over each attack and its parameters\n",
        "for attack_func, attack_params in attacks:\n",
        "    print(f\"Running attack: {attack_func.__name__} with parameters: {attack_params}\")\n",
        "    adv_predict(test_loader, model_AT_rFGSM, attack_func, device, **attack_params)\n",
        "    print()  # Print an empty line for separation\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JDuv4WBvq54",
        "outputId": "24045f6f-205a-483c-fb74-49842ac7bc35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running attack: dfgsm_k with parameters: {'k': 50, 'epsilon': 0.02, 'is_report_loss_diff': False}\n",
            "Adversarial accuracy (without attack): 99.25% | Under attack: 83.43%.\n",
            "\n",
            "Running attack: bga_k with parameters: {'k': 25, 'is_report_loss_diff': False}\n",
            "Adversarial accuracy (without attack): 99.25% | Under attack: 91.57%.\n",
            "\n",
            "Running attack: bca_k with parameters: {'k': 25, 'is_report_loss_diff': False}\n",
            "Adversarial accuracy (without attack): 99.25% | Under attack: 87.93%.\n",
            "\n",
            "Running attack: grosse_k with parameters: {'k': 25, 'is_report_loss_diff': False}\n",
            "Adversarial accuracy (without attack): 99.25% | Under attack: 87.93%.\n",
            "\n",
            "Running attack: pgd with parameters: {'k': 100, 'step_length': 1.0, 'norm': 'l1', 'is_report_loss_diff': False}\n",
            "Adversarial accuracy (without attack): 99.25% | Under attack: 87.24%.\n",
            "\n",
            "Running attack: pgd with parameters: {'k': 200, 'step_length': 0.05, 'norm': 'l2', 'is_report_loss_diff': False}\n",
            "Adversarial accuracy (without attack): 99.25% | Under attack: 91.67%.\n",
            "\n",
            "Running attack: pgd with parameters: {'k': 500, 'step_length': 0.002, 'norm': 'linf', 'is_report_loss_diff': False}\n",
            "Adversarial accuracy (without attack): 99.25% | Under attack: 87.98%.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def mimic_attack_effectiveness_optimized(test_loader, model, seed, trials=1000, device=\"cuda:0\"):\n",
        "  \"\"\"\n",
        "  Calculates the effectiveness of the mimic attack on the given model.\n",
        "\n",
        "  Args:\n",
        "      test_loader: A PyTorch dataloader containing the test data.\n",
        "      model: The PyTorch model to be attacked.\n",
        "      seed: The random seed for reproducibility.\n",
        "      trials: The number of random samples to use from the benign class (default: 1000).\n",
        "      device: The device to use for computations (default: \"cuda:0\" if available, otherwise \"cpu\").\n",
        "\n",
        "  Returns:\n",
        "      The effectiveness of the mimic attack as a percentage (float).\n",
        "  \"\"\"\n",
        "\n",
        "  torch.manual_seed(seed)\n",
        "  model.eval()\n",
        "\n",
        "  # Initialize counters\n",
        "  successful_attacks = 0\n",
        "  total_malicious_samples = 0\n",
        "\n",
        "  # Pre-select benign samples for efficiency\n",
        "  benign_samples = []\n",
        "  for x_batch, y_batch in test_loader:\n",
        "    benign_samples.append(x_batch[y_batch.squeeze() == 0])\n",
        "\n",
        "  ben_x = torch.cat(benign_samples, dim=0).to(device)\n",
        "\n",
        "  # Clear unnecessary variables\n",
        "  del benign_samples\n",
        "\n",
        "  trials = min(trials, len(ben_x))\n",
        "\n",
        "\n",
        "  for x_batch, y_batch in test_loader:\n",
        "    x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
        "    malicious_samples = x_batch[y_batch.squeeze() == 1]\n",
        "\n",
        "    if len(malicious_samples) > 0:\n",
        "      # Expand dimensions for efficient broadcasting\n",
        "      malicious_samples_expanded = malicious_samples.unsqueeze(1).expand(-1, trials, -1)\n",
        "\n",
        "      # Generate random indices outside the loop\n",
        "      seed += 1\n",
        "      torch.manual_seed(seed)\n",
        "      indices = torch.randperm(len(ben_x), device=device)[:trials]\n",
        "      trial_vectors_expanded = ben_x[indices].unsqueeze(0)\n",
        "\n",
        "      # Perform the mimic attack and update counters\n",
        "      modified_x = torch.clamp(malicious_samples_expanded + trial_vectors_expanded, min=0., max=1.)\n",
        "      _, done = get_loss(modified_x.view(-1, modified_x.shape[-1]), torch.ones(trials * malicious_samples.shape[0], 1, device=device), model)\n",
        "      successful_attacks += (done.view(malicious_samples.shape[0], trials).sum(dim=1) > 0).sum().item()\n",
        "      total_malicious_samples += malicious_samples.shape[0]\n",
        "\n",
        "  # Calculate and print attack effectiveness\n",
        "  attack_effectiveness = (successful_attacks / total_malicious_samples) * 100 if total_malicious_samples > 0 else 0\n",
        "  print(f\"Mimic attack effectiveness: {attack_effectiveness:.3f}%.\")\n",
        "\n",
        "  return attack_effectiveness  # Added return statement for clarity\n"
      ],
      "metadata": {
        "id": "NpnhzTu07Aep"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mimic_attack_effectiveness_optimized(test_loader, model_AT_rFGSM , seed=230, trials=30, device=device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iemV-2EK6wng",
        "outputId": "e848c162-992e-44cd-f427-e2cee8228fc7"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mimic attack effectiveness: 11.871%.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11.870503597122301"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    }
  ]
}