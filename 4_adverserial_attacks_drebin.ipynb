{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mostafa-ja/mal_adv3/blob/main/4_adverserial_attacks_drebin.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "download_links = ['https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/sparse_matrix_0.npz',\n",
        "                  'https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/sparse_matrix_1.npz',\n",
        "                  'https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/sparse_matrix_2.npz',\n",
        "                  'https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/sparse_matrix_y0.npz',\n",
        "                  'https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/sparse_matrix_y1.npz',\n",
        "                  'https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/sparse_matrix_y2.npz',\n",
        "                  'https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/model_DNN_drebin_best.pth',\n",
        "                  'https://github.com/mostafa-ja/mal_adv3/raw/main/data/adverserial_attacks_functions.py',\n",
        "                  'https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/model_AT_rFGSM_weightedLoss.pth'\n",
        "]"
      ],
      "metadata": {
        "id": "1IW4pHac9VLq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "output_filepath = '/content/'\n",
        "for link in download_links:\n",
        "  gdown.download(link, output_filepath)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6kzSbjaXGVeG",
        "outputId": "e8961bc8-3b07-433e-d74d-1f90e430780c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/sparse_matrix_0.npz\n",
            "To: /content/sparse_matrix_0.npz\n",
            "100%|██████████| 461k/461k [00:00<00:00, 6.60MB/s]\n",
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/sparse_matrix_1.npz\n",
            "To: /content/sparse_matrix_1.npz\n",
            "100%|██████████| 148k/148k [00:00<00:00, 3.40MB/s]\n",
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/sparse_matrix_2.npz\n",
            "To: /content/sparse_matrix_2.npz\n",
            "100%|██████████| 150k/150k [00:00<00:00, 2.56MB/s]\n",
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/sparse_matrix_y0.npz\n",
            "To: /content/sparse_matrix_y0.npz\n",
            "100%|██████████| 5.79k/5.79k [00:00<00:00, 14.8MB/s]\n",
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/sparse_matrix_y1.npz\n",
            "To: /content/sparse_matrix_y1.npz\n",
            "100%|██████████| 2.64k/2.64k [00:00<00:00, 10.5MB/s]\n",
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/sparse_matrix_y2.npz\n",
            "To: /content/sparse_matrix_y2.npz\n",
            "100%|██████████| 2.71k/2.71k [00:00<00:00, 5.90MB/s]\n",
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/model_DNN_drebin_best.pth\n",
            "To: /content/model_DNN_drebin_best.pth\n",
            "100%|██████████| 8.17M/8.17M [00:00<00:00, 15.4MB/s]\n",
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv3/raw/main/data/adverserial_attacks_functions.py\n",
            "To: /content/adverserial_attacks_functions.py\n",
            "49.1kB [00:00, 15.2MB/s]                   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score,balanced_accuracy_score\n",
        "import numpy as np\n",
        "from scipy import sparse\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import random\n",
        "import time\n",
        "\n",
        "from adverserial_attacks_functions import *\n",
        "\n",
        "torch.manual_seed(0)\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "id": "JKDdI3K9LrlF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd6cc3a0-5c1c-45db-b43e-bbca081bd413"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load dataset\n",
        "X_train = sparse.load_npz(\"/content/sparse_matrix_0.npz\").toarray()\n",
        "X_val = sparse.load_npz(\"/content/sparse_matrix_1.npz\").toarray()\n",
        "X_test = sparse.load_npz(\"/content/sparse_matrix_2.npz\").toarray()\n",
        "\n",
        "X_train = torch.tensor(X_train, dtype=torch.int8)\n",
        "X_val = torch.tensor(X_val, dtype=torch.int8)\n",
        "X_test = torch.tensor(X_test, dtype=torch.int8)\n",
        "\n",
        "\n",
        "y_train = sparse.load_npz(\"/content/sparse_matrix_y0.npz\").toarray().reshape((-1, 1))\n",
        "y_val = sparse.load_npz(\"/content/sparse_matrix_y1.npz\").toarray().reshape((-1, 1))\n",
        "y_test = sparse.load_npz(\"/content/sparse_matrix_y2.npz\").toarray().reshape((-1, 1))\n",
        "\n",
        "y_train = torch.tensor(y_train, dtype=torch.int8)\n",
        "y_val = torch.tensor(y_val, dtype=torch.int8)\n",
        "y_test = torch.tensor(y_test, dtype=torch.int8)\n",
        "\n",
        "\n",
        "print(\"Shapes:\")\n",
        "print(\"x_train:\", X_train.shape)\n",
        "print(\"x_val:\", X_val.shape)\n",
        "print(\"x_test:\", X_test.shape)\n",
        "print(\"y_train:\", y_train.shape)\n",
        "print(\"y_val:\", y_val.shape)\n",
        "print(\"y_test:\", y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5blmEg4h-GKy",
        "outputId": "1df7f811-3ff7-4e23-9b47-591a4684bce3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shapes:\n",
            "x_train: torch.Size([28683, 10000])\n",
            "x_val: torch.Size([9562, 10000])\n",
            "x_test: torch.Size([9562, 10000])\n",
            "y_train: torch.Size([28683, 1])\n",
            "y_val: torch.Size([9562, 1])\n",
            "y_test: torch.Size([9562, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# number of benigns and malicious sample in training dataset\n",
        "n_ben = (y_train.squeeze()== 0).sum().item()\n",
        "n_mal = (y_train.squeeze()== 1).sum().item()\n",
        "print('the proportion of malwares : ', n_mal/(n_mal+n_ben))\n",
        "\n",
        "# Combine features and labels into datasets\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "val_dataset = TensorDataset(X_val, y_val)\n",
        "test_dataset = TensorDataset(X_test, y_test)\n",
        "\n",
        "# Define the DataLoader for training, validation, and test sets\n",
        "batch_size = 128\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Clear unnecessary variables\n",
        "del train_dataset, val_dataset, test_dataset, y_train, y_val, y_test\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81AZSXOV-HoW",
        "outputId": "cfe7966a-4b5a-463b-aae2-90e54835076b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the proportion of malwares :  0.11386535578565701\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MalwareDetectionModel(nn.Module):\n",
        "    def __init__(self, input_size=10000, hidden_1_size=200, hidden_2_size=200, num_labels=2, dropout_prob=0.6):\n",
        "        super(MalwareDetectionModel, self).__init__()\n",
        "\n",
        "        self.input_size = input_size\n",
        "        self.hidden_1_size = hidden_1_size\n",
        "        self.hidden_2_size = hidden_2_size\n",
        "        self.num_labels = num_labels\n",
        "        self.dropout_prob = dropout_prob\n",
        "\n",
        "        self.fc1 = nn.Linear(input_size, hidden_1_size)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        #self.dropout1 = nn.Dropout(dropout_prob)\n",
        "        self.fc2 = nn.Linear(hidden_1_size, hidden_2_size)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.dropout2 = nn.Dropout(dropout_prob)\n",
        "        self.fc3 = nn.Linear(hidden_2_size, num_labels)\n",
        "        #self.log_softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu1(x)\n",
        "        #x = self.dropout1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc3(x)\n",
        "        #x = self.log_softmax(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "xdNbTvxTTqyw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_DNN = MalwareDetectionModel().to(device)\n",
        "# Load model parameters\n",
        "model_DNN.load_state_dict(torch.load('model_DNN_drebin_best.pth', map_location=torch.device(device)))"
      ],
      "metadata": {
        "id": "0MavlKAt6mb8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96c46467-4f57-43db-a0eb-b491717a9a29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def model_evaluation(model, test_loader, device):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    predictions = []\n",
        "    true_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X_batch, labels_batch in test_loader:\n",
        "            X_batch, labels_batch = X_batch.to(torch.float32).to(device), labels_batch.to(device)\n",
        "            outputs = model(X_batch)\n",
        "            _, predicted = torch.topk(outputs, k=1)\n",
        "            predictions.extend(predicted.tolist())\n",
        "            true_labels.extend(labels_batch.tolist())\n",
        "\n",
        "    # Convert predictions and true labels to numpy arrays\n",
        "    predictions = np.array(predictions)\n",
        "    true_labels = np.array(true_labels)\n",
        "\n",
        "    # Calculate and print test accuracy\n",
        "    accuracy = accuracy_score(true_labels, predictions)\n",
        "    balanced_acc = balanced_accuracy_score(true_labels, predictions)\n",
        "    print(f'Test Accuracy: {accuracy:.4f}')\n",
        "    print(f'Test balanced Accuracy: {balanced_acc:.4f}')\n",
        "\n",
        "    # Calculate and print precision, recall, and F1-score\n",
        "    precision = precision_score(true_labels, predictions)\n",
        "    recall = recall_score(true_labels, predictions)\n",
        "    f1 = f1_score(true_labels, predictions)\n",
        "\n",
        "    print(f'Precision: {precision:.4f}')\n",
        "    print(f'Recall: {recall:.4f}')\n",
        "    print(f'F1-score: {f1:.4f}')\n",
        "\n",
        "    # Calculate and print true positives, true negatives, false positives, and false negatives\n",
        "    TP = ((predictions == 1) & (true_labels == 1)).sum()\n",
        "    TN = ((predictions == 0) & (true_labels == 0)).sum()\n",
        "    FP = ((predictions == 1) & (true_labels == 0)).sum()\n",
        "    FN = ((predictions == 0) & (true_labels == 1)).sum()\n",
        "\n",
        "    print(f'True Positives (TP): {TP}')\n",
        "    print(f'True Negatives (TN): {TN}')\n",
        "    print(f'False Positives (FP): {FP}')\n",
        "    print(f'False Negatives (FN): {FN}')\n",
        "\n",
        "    # Calculate and print False Negative Rate (FNR) and False Positive Rate (FPR)\n",
        "    FNR = (FN / (FN + TP)) * 100\n",
        "    FPR = (FP / (FP + TN)) * 100\n",
        "\n",
        "    print(f'False Negative Rate (FNR): {FNR:.4f}')\n",
        "    print(f'False Positive Rate (FPR): {FPR:.4f}')"
      ],
      "metadata": {
        "id": "yX_2SRH7_PnB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_evaluation(model_DNN, test_loader, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPz3iDpi_R1x",
        "outputId": "875dc7f6-c70f-44f8-8371-75c325898683"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.9912\n",
            "Test balanced Accuracy: 0.9785\n",
            "Precision: 0.9637\n",
            "Recall: 0.9619\n",
            "F1-score: 0.9628\n",
            "True Positives (TP): 1087\n",
            "True Negatives (TN): 8391\n",
            "False Positives (FP): 41\n",
            "False Negatives (FN): 43\n",
            "False Negative Rate (FNR): 3.8053\n",
            "False Positive Rate (FPR): 0.4862\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def adjust_learning_rate(optimizer, epoch, lr_step=(25,35,45), lr_decay_ratio=0.2):\n",
        "    \"\"\"Adjust the learning rate based on the epoch number.\"\"\"\n",
        "    if epoch == 0:\n",
        "        optimizer.param_groups[0]['lr'] /= 8\n",
        "    elif epoch in [1, 2, 3]:  # in step five , we finish warm up ,and start normal learning rate\n",
        "        optimizer.param_groups[0]['lr'] *= 2\n",
        "    if epoch in lr_step: # in these steps , we are geting close to optimal point so we need to have shorter step\n",
        "        optimizer.param_groups[0]['lr'] *= lr_decay_ratio\n",
        "    return optimizer\n"
      ],
      "metadata": {
        "id": "5QhoGvdY_w4M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def adversarial_training(model, train_loader, val_loader, attack, adv_epochs=50, lr=0.001, weight_decay=0., device=device, verbose=True, **kwargs):\n",
        "\n",
        "    # Assuming positive class (malware) is label 1\n",
        "    class_weights = torch.tensor([0.11, 0.89]).to(device)  # Adjust the weights based on the class distribution, higher weight for positive class\n",
        "\n",
        "    # Define Loss Function and Optimizer\n",
        "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "    total_time = 0.\n",
        "    nbatches = len(train_loader)\n",
        "    best_acc_val = 0.\n",
        "    acc_val_adv_be = 0.\n",
        "    best_epoch = 0\n",
        "\n",
        "    for epoch in range(adv_epochs):\n",
        "        epoch_losses = []\n",
        "        epoch_accuracies = []\n",
        "        optimizer = adjust_learning_rate(optimizer, epoch)\n",
        "\n",
        "        for idx_batch, (x_batch, y_batch) in enumerate(train_loader):\n",
        "            x_batch, y_batch = x_batch.to(torch.float32).to(device), y_batch.to(device)\n",
        "            batch_size = x_batch.shape[0]\n",
        "\n",
        "            # Separate malicious and benign samples\n",
        "            mal_x_batch, ben_x_batch = x_batch[y_batch.squeeze() == 1], x_batch[y_batch.squeeze() == 0]\n",
        "            mal_y_batch, ben_y_batch = y_batch[y_batch.squeeze() == 1], y_batch[y_batch.squeeze() == 0]\n",
        "\n",
        "            # Generate adversarial examples\n",
        "            model.eval()\n",
        "            pertb_mal_x = attack(mal_x_batch, mal_y_batch, model, **kwargs)\n",
        "            x_batch = torch.cat([ben_x_batch, pertb_mal_x], dim=0)\n",
        "            y_batch = torch.cat([ben_y_batch, mal_y_batch])\n",
        "            model.train()\n",
        "\n",
        "            # Forward pass and backward pass\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(x_batch)\n",
        "            loss_train = criterion(outputs, y_batch.view(-1).long())\n",
        "            loss_train.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Calculate metrics\n",
        "            epoch_losses.append(loss_train.item())\n",
        "            predicted = outputs.argmax(1).unsqueeze(1)\n",
        "            acc_train = (predicted == y_batch).sum().item() / len(y_batch)\n",
        "            epoch_accuracies.append(acc_train)\n",
        "\n",
        "            # Print batch level information\n",
        "            #if verbose:\n",
        "                #print(f'Mini batch: {idx_batch + 1}/{nbatches} | Epoch: {epoch + 1}/{adv_epochs} | Batch Loss: {loss_train.item():.4f} | Batch Accuracy: {acc_train * 100:.2f}%')\n",
        "\n",
        "        # Calculate epoch level metrics\n",
        "        mean_loss = np.mean(epoch_losses)\n",
        "        mean_accuracy = np.mean(epoch_accuracies) * 100\n",
        "\n",
        "        # Print epoch level information\n",
        "        if verbose:\n",
        "            print(f'Epoch: {epoch+1}/{adv_epochs} | Training loss (epoch level): {mean_loss:.4f} | Train accuracy: {mean_accuracy:.2f}%')\n",
        "\n",
        "        # Evaluation on validation set\n",
        "        model.eval()\n",
        "        avg_acc_ad_val = []\n",
        "        avg_acc_val = []\n",
        "        for x_val, y_val in val_loader:\n",
        "            x_val, y_val = x_val.to(torch.float32).to(device), y_val.to(device)\n",
        "            outputs = model(x_val)\n",
        "            predicted = outputs.argmax(1).unsqueeze(1)\n",
        "            acc_val = (predicted == y_val).sum().item() / len(y_val)\n",
        "            avg_acc_val.append(acc_val)\n",
        "\n",
        "            # Generate adversarial examples for validation set\n",
        "            mal_x_batch, mal_y_batch = x_val[y_val.squeeze() == 1], y_val[y_val.squeeze() == 1]\n",
        "            pertb_mal_x = attack(mal_x_batch, mal_y_batch, model, **kwargs)\n",
        "            outputs = model(pertb_mal_x)\n",
        "            y_pred = outputs.argmax(1).unsqueeze(1)\n",
        "\n",
        "            acc_ad_val = (y_pred == 1.).sum().item() / len(y_pred)\n",
        "            avg_acc_ad_val.append(acc_ad_val)\n",
        "\n",
        "        # Calculate validation accuracy\n",
        "        assert len(avg_acc_ad_val) > 0\n",
        "        acc_all = (np.mean(avg_acc_val) + np.mean(avg_acc_ad_val)) / 2.\n",
        "\n",
        "        # Update best validation accuracy\n",
        "        if acc_all >= best_acc_val:\n",
        "            best_acc_val = acc_all\n",
        "            acc_val_adv_be = np.mean(avg_acc_ad_val)\n",
        "            best_epoch = epoch + 1\n",
        "            torch.save(model.state_dict(), 'best_AT_model.pth')\n",
        "\n",
        "        # Print validation results\n",
        "        if verbose:\n",
        "            print(f\"\\tVal accuracy(without attack) {np.mean(avg_acc_val) * 100:.4}% and accuracy(with attack) {np.mean(avg_acc_ad_val) * 100:.4}% under attack and overall accuracy {acc_all * 100:.4}%.\")\n",
        "            print(f\"\\tModel select at epoch {best_epoch} with validation accuracy {best_acc_val * 100:.4}% and accuracy {acc_val_adv_be * 100:.4}% under attack.\")\n"
      ],
      "metadata": {
        "id": "B0v7V8W7lidM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def adv_predict(test_loader, model, attack, device, **kwargs):\n",
        "\n",
        "    if attack == mimicry:\n",
        "      # Pre-select benign samples\n",
        "      benign_samples = []\n",
        "      for x_batch, y_batch in test_loader:\n",
        "        benign_samples.append(x_batch[y_batch.squeeze() == 0])\n",
        "\n",
        "      ben_x = torch.cat(benign_samples, dim=0).to(device)\n",
        "      del benign_samples\n",
        "\n",
        "    model.eval()\n",
        "    avg_acc_ad_test = []\n",
        "    avg_acc_test = []\n",
        "    with torch.no_grad():\n",
        "        for x_test, y_test in test_loader:\n",
        "            x_test, y_test = x_test.to(torch.float32).to(device), y_test.to(device)\n",
        "            outputs = model(x_test)\n",
        "            _, predicted = torch.topk(outputs, k=1)\n",
        "            acc_test = (predicted == y_test).sum().item() / len(y_test)\n",
        "            avg_acc_test.append(acc_test)\n",
        "\n",
        "            # Generate adversarial examples for test set\n",
        "            mal_x_batch, mal_y_batch = x_test[y_test.squeeze() == 1], y_test[y_test.squeeze() == 1]\n",
        "\n",
        "            if attack == mimicry:\n",
        "                pertb_mal_x = mimicry(ben_x, mal_x_batch, model, **kwargs)\n",
        "            else :\n",
        "                with torch.enable_grad():\n",
        "                    pertb_mal_x = attack(mal_x_batch, mal_y_batch, model, **kwargs)\n",
        "\n",
        "            outputs = model(pertb_mal_x)\n",
        "            _, y_pred = torch.topk(outputs, k=1)\n",
        "\n",
        "            acc_ad_test = (y_pred == 1.).sum().item() / len(y_pred)\n",
        "            avg_acc_ad_test.append(acc_ad_test)\n",
        "\n",
        "    # Calculate test accuracy\n",
        "    print(f\"Adversarial accuracy (without attack): {np.mean(avg_acc_test) * 100:.4}% | Under attack: {np.mean(avg_acc_ad_test) * 100:.4}%.\")\n",
        "    if attack == mimicry:\n",
        "      del ben_x\n"
      ],
      "metadata": {
        "id": "yRuxHXXjqeOa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# AT-rFGSM: Adversarial Taraining based on rFGSM attack\n",
        "model_AT = MalwareDetectionModel().to(device)\n",
        "\n",
        "attack_param = {\"k\":50, \"epsilon\":0.02, 'random':True, \"is_sample\":False, 'is_report_loss_diff':False}\n",
        "adversarial_training(model_AT, train_loader, val_loader, adv_epochs=50, attack=dfgsm_k, **attack_param)"
      ],
      "metadata": {
        "id": "E8zaItRUryCv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2516f45-7e3e-46d6-c66a-447d5513abeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss (epoch level): 0.4688 | Train accuracy: 84.47%\n",
            "\tVal accuracy(without attack) 96.55% and accuracy(with attack) 71.52% under attack and overall accuracy 84.04%.\n",
            "\tModel select at epoch 1 with validation accuracy 84.04% and accuracy 71.52% under attack.\n",
            "Training loss (epoch level): 0.1100 | Train accuracy: 96.80%\n",
            "\tVal accuracy(without attack) 98.09% and accuracy(with attack) 85.61% under attack and overall accuracy 91.85%.\n",
            "\tModel select at epoch 2 with validation accuracy 91.85% and accuracy 85.61% under attack.\n",
            "Training loss (epoch level): 0.0643 | Train accuracy: 98.12%\n",
            "\tVal accuracy(without attack) 98.39% and accuracy(with attack) 89.02% under attack and overall accuracy 93.7%.\n",
            "\tModel select at epoch 3 with validation accuracy 93.7% and accuracy 89.02% under attack.\n",
            "Training loss (epoch level): 0.0489 | Train accuracy: 98.43%\n",
            "\tVal accuracy(without attack) 98.78% and accuracy(with attack) 88.53% under attack and overall accuracy 93.66%.\n",
            "\tModel select at epoch 3 with validation accuracy 93.7% and accuracy 89.02% under attack.\n",
            "Training loss (epoch level): 0.0292 | Train accuracy: 99.20%\n",
            "\tVal accuracy(without attack) 98.72% and accuracy(with attack) 90.7% under attack and overall accuracy 94.71%.\n",
            "\tModel select at epoch 5 with validation accuracy 94.71% and accuracy 90.7% under attack.\n",
            "Training loss (epoch level): 0.0219 | Train accuracy: 99.42%\n",
            "\tVal accuracy(without attack) 98.6% and accuracy(with attack) 89.88% under attack and overall accuracy 94.24%.\n",
            "\tModel select at epoch 5 with validation accuracy 94.71% and accuracy 90.7% under attack.\n",
            "Training loss (epoch level): 0.0176 | Train accuracy: 99.56%\n",
            "\tVal accuracy(without attack) 98.93% and accuracy(with attack) 84.54% under attack and overall accuracy 91.74%.\n",
            "\tModel select at epoch 5 with validation accuracy 94.71% and accuracy 90.7% under attack.\n",
            "Training loss (epoch level): 0.0139 | Train accuracy: 99.67%\n",
            "\tVal accuracy(without attack) 98.95% and accuracy(with attack) 90.21% under attack and overall accuracy 94.58%.\n",
            "\tModel select at epoch 5 with validation accuracy 94.71% and accuracy 90.7% under attack.\n",
            "Training loss (epoch level): 0.0109 | Train accuracy: 99.78%\n",
            "\tVal accuracy(without attack) 98.91% and accuracy(with attack) 88.77% under attack and overall accuracy 93.84%.\n",
            "\tModel select at epoch 5 with validation accuracy 94.71% and accuracy 90.7% under attack.\n",
            "Training loss (epoch level): 0.0138 | Train accuracy: 99.65%\n",
            "\tVal accuracy(without attack) 98.7% and accuracy(with attack) 91.74% under attack and overall accuracy 95.22%.\n",
            "\tModel select at epoch 10 with validation accuracy 95.22% and accuracy 91.74% under attack.\n",
            "Training loss (epoch level): 0.0112 | Train accuracy: 99.74%\n",
            "\tVal accuracy(without attack) 98.83% and accuracy(with attack) 93.28% under attack and overall accuracy 96.06%.\n",
            "\tModel select at epoch 11 with validation accuracy 96.06% and accuracy 93.28% under attack.\n",
            "Training loss (epoch level): 0.0136 | Train accuracy: 99.71%\n",
            "\tVal accuracy(without attack) 99.01% and accuracy(with attack) 90.86% under attack and overall accuracy 94.93%.\n",
            "\tModel select at epoch 11 with validation accuracy 96.06% and accuracy 93.28% under attack.\n",
            "Training loss (epoch level): 0.0085 | Train accuracy: 99.83%\n",
            "\tVal accuracy(without attack) 98.99% and accuracy(with attack) 90.21% under attack and overall accuracy 94.6%.\n",
            "\tModel select at epoch 11 with validation accuracy 96.06% and accuracy 93.28% under attack.\n",
            "Training loss (epoch level): 0.0071 | Train accuracy: 99.88%\n",
            "\tVal accuracy(without attack) 98.94% and accuracy(with attack) 91.64% under attack and overall accuracy 95.29%.\n",
            "\tModel select at epoch 11 with validation accuracy 96.06% and accuracy 93.28% under attack.\n",
            "Training loss (epoch level): 0.0073 | Train accuracy: 99.88%\n",
            "\tVal accuracy(without attack) 98.86% and accuracy(with attack) 90.7% under attack and overall accuracy 94.78%.\n",
            "\tModel select at epoch 11 with validation accuracy 96.06% and accuracy 93.28% under attack.\n",
            "Training loss (epoch level): 0.0062 | Train accuracy: 99.88%\n",
            "\tVal accuracy(without attack) 98.9% and accuracy(with attack) 90.89% under attack and overall accuracy 94.89%.\n",
            "\tModel select at epoch 11 with validation accuracy 96.06% and accuracy 93.28% under attack.\n",
            "Training loss (epoch level): 0.0093 | Train accuracy: 99.82%\n",
            "\tVal accuracy(without attack) 98.89% and accuracy(with attack) 92.16% under attack and overall accuracy 95.52%.\n",
            "\tModel select at epoch 11 with validation accuracy 96.06% and accuracy 93.28% under attack.\n",
            "Training loss (epoch level): 0.0070 | Train accuracy: 99.86%\n",
            "\tVal accuracy(without attack) 98.9% and accuracy(with attack) 91.36% under attack and overall accuracy 95.13%.\n",
            "\tModel select at epoch 11 with validation accuracy 96.06% and accuracy 93.28% under attack.\n",
            "Training loss (epoch level): 0.0077 | Train accuracy: 99.85%\n",
            "\tVal accuracy(without attack) 98.93% and accuracy(with attack) 90.14% under attack and overall accuracy 94.53%.\n",
            "\tModel select at epoch 11 with validation accuracy 96.06% and accuracy 93.28% under attack.\n",
            "Training loss (epoch level): 0.0093 | Train accuracy: 99.78%\n",
            "\tVal accuracy(without attack) 98.93% and accuracy(with attack) 90.4% under attack and overall accuracy 94.66%.\n",
            "\tModel select at epoch 11 with validation accuracy 96.06% and accuracy 93.28% under attack.\n",
            "Training loss (epoch level): 0.0067 | Train accuracy: 99.86%\n",
            "\tVal accuracy(without attack) 98.96% and accuracy(with attack) 92.16% under attack and overall accuracy 95.56%.\n",
            "\tModel select at epoch 11 with validation accuracy 96.06% and accuracy 93.28% under attack.\n",
            "Training loss (epoch level): 0.0070 | Train accuracy: 99.88%\n",
            "\tVal accuracy(without attack) 98.89% and accuracy(with attack) 92.12% under attack and overall accuracy 95.5%.\n",
            "\tModel select at epoch 11 with validation accuracy 96.06% and accuracy 93.28% under attack.\n",
            "Training loss (epoch level): 0.0073 | Train accuracy: 99.84%\n",
            "\tVal accuracy(without attack) 99.02% and accuracy(with attack) 90.99% under attack and overall accuracy 95.0%.\n",
            "\tModel select at epoch 11 with validation accuracy 96.06% and accuracy 93.28% under attack.\n",
            "Training loss (epoch level): 0.0063 | Train accuracy: 99.86%\n",
            "\tVal accuracy(without attack) 98.88% and accuracy(with attack) 91.35% under attack and overall accuracy 95.11%.\n",
            "\tModel select at epoch 11 with validation accuracy 96.06% and accuracy 93.28% under attack.\n",
            "Training loss (epoch level): 0.0081 | Train accuracy: 99.84%\n",
            "\tVal accuracy(without attack) 99.06% and accuracy(with attack) 92.55% under attack and overall accuracy 95.81%.\n",
            "\tModel select at epoch 11 with validation accuracy 96.06% and accuracy 93.28% under attack.\n",
            "Training loss (epoch level): 0.0035 | Train accuracy: 99.93%\n",
            "\tVal accuracy(without attack) 98.99% and accuracy(with attack) 92.55% under attack and overall accuracy 95.77%.\n",
            "\tModel select at epoch 11 with validation accuracy 96.06% and accuracy 93.28% under attack.\n",
            "Training loss (epoch level): 0.0035 | Train accuracy: 99.94%\n",
            "\tVal accuracy(without attack) 99.02% and accuracy(with attack) 92.99% under attack and overall accuracy 96.0%.\n",
            "\tModel select at epoch 11 with validation accuracy 96.06% and accuracy 93.28% under attack.\n",
            "Training loss (epoch level): 0.0030 | Train accuracy: 99.94%\n",
            "\tVal accuracy(without attack) 98.95% and accuracy(with attack) 92.74% under attack and overall accuracy 95.84%.\n",
            "\tModel select at epoch 11 with validation accuracy 96.06% and accuracy 93.28% under attack.\n",
            "Training loss (epoch level): 0.0027 | Train accuracy: 99.95%\n",
            "\tVal accuracy(without attack) 98.99% and accuracy(with attack) 91.82% under attack and overall accuracy 95.41%.\n",
            "\tModel select at epoch 11 with validation accuracy 96.06% and accuracy 93.28% under attack.\n",
            "Training loss (epoch level): 0.0025 | Train accuracy: 99.95%\n",
            "\tVal accuracy(without attack) 98.91% and accuracy(with attack) 93.21% under attack and overall accuracy 96.06%.\n",
            "\tModel select at epoch 11 with validation accuracy 96.06% and accuracy 93.28% under attack.\n",
            "Training loss (epoch level): 0.0032 | Train accuracy: 99.95%\n",
            "\tVal accuracy(without attack) 98.94% and accuracy(with attack) 93.15% under attack and overall accuracy 96.04%.\n",
            "\tModel select at epoch 11 with validation accuracy 96.06% and accuracy 93.28% under attack.\n",
            "Training loss (epoch level): 0.0028 | Train accuracy: 99.95%\n",
            "\tVal accuracy(without attack) 98.9% and accuracy(with attack) 92.9% under attack and overall accuracy 95.9%.\n",
            "\tModel select at epoch 11 with validation accuracy 96.06% and accuracy 93.28% under attack.\n",
            "Training loss (epoch level): 0.0029 | Train accuracy: 99.94%\n",
            "\tVal accuracy(without attack) 98.88% and accuracy(with attack) 93.19% under attack and overall accuracy 96.03%.\n",
            "\tModel select at epoch 11 with validation accuracy 96.06% and accuracy 93.28% under attack.\n",
            "Training loss (epoch level): 0.0026 | Train accuracy: 99.94%\n",
            "\tVal accuracy(without attack) 98.86% and accuracy(with attack) 93.56% under attack and overall accuracy 96.21%.\n",
            "\tModel select at epoch 34 with validation accuracy 96.21% and accuracy 93.56% under attack.\n",
            "Training loss (epoch level): 0.0026 | Train accuracy: 99.94%\n",
            "\tVal accuracy(without attack) 98.86% and accuracy(with attack) 93.6% under attack and overall accuracy 96.23%.\n",
            "\tModel select at epoch 35 with validation accuracy 96.23% and accuracy 93.6% under attack.\n",
            "Training loss (epoch level): 0.0021 | Train accuracy: 99.95%\n",
            "\tVal accuracy(without attack) 98.89% and accuracy(with attack) 93.52% under attack and overall accuracy 96.2%.\n",
            "\tModel select at epoch 35 with validation accuracy 96.23% and accuracy 93.6% under attack.\n",
            "Training loss (epoch level): 0.0023 | Train accuracy: 99.94%\n",
            "\tVal accuracy(without attack) 98.89% and accuracy(with attack) 92.82% under attack and overall accuracy 95.85%.\n",
            "\tModel select at epoch 35 with validation accuracy 96.23% and accuracy 93.6% under attack.\n",
            "Training loss (epoch level): 0.0020 | Train accuracy: 99.96%\n",
            "\tVal accuracy(without attack) 98.93% and accuracy(with attack) 93.06% under attack and overall accuracy 95.99%.\n",
            "\tModel select at epoch 35 with validation accuracy 96.23% and accuracy 93.6% under attack.\n",
            "Training loss (epoch level): 0.0021 | Train accuracy: 99.95%\n",
            "\tVal accuracy(without attack) 98.92% and accuracy(with attack) 92.86% under attack and overall accuracy 95.89%.\n",
            "\tModel select at epoch 35 with validation accuracy 96.23% and accuracy 93.6% under attack.\n",
            "Training loss (epoch level): 0.0022 | Train accuracy: 99.95%\n",
            "\tVal accuracy(without attack) 98.9% and accuracy(with attack) 93.09% under attack and overall accuracy 95.99%.\n",
            "\tModel select at epoch 35 with validation accuracy 96.23% and accuracy 93.6% under attack.\n",
            "Training loss (epoch level): 0.0021 | Train accuracy: 99.94%\n",
            "\tVal accuracy(without attack) 98.86% and accuracy(with attack) 93.43% under attack and overall accuracy 96.15%.\n",
            "\tModel select at epoch 35 with validation accuracy 96.23% and accuracy 93.6% under attack.\n",
            "Training loss (epoch level): 0.0019 | Train accuracy: 99.95%\n",
            "\tVal accuracy(without attack) 98.91% and accuracy(with attack) 93.29% under attack and overall accuracy 96.1%.\n",
            "\tModel select at epoch 35 with validation accuracy 96.23% and accuracy 93.6% under attack.\n",
            "Training loss (epoch level): 0.0028 | Train accuracy: 99.95%\n",
            "\tVal accuracy(without attack) 98.88% and accuracy(with attack) 93.23% under attack and overall accuracy 96.05%.\n",
            "\tModel select at epoch 35 with validation accuracy 96.23% and accuracy 93.6% under attack.\n",
            "Training loss (epoch level): 0.0019 | Train accuracy: 99.95%\n",
            "\tVal accuracy(without attack) 98.92% and accuracy(with attack) 93.03% under attack and overall accuracy 95.97%.\n",
            "\tModel select at epoch 35 with validation accuracy 96.23% and accuracy 93.6% under attack.\n",
            "Training loss (epoch level): 0.0018 | Train accuracy: 99.96%\n",
            "\tVal accuracy(without attack) 98.92% and accuracy(with attack) 93.14% under attack and overall accuracy 96.03%.\n",
            "\tModel select at epoch 35 with validation accuracy 96.23% and accuracy 93.6% under attack.\n",
            "Training loss (epoch level): 0.0019 | Train accuracy: 99.95%\n",
            "\tVal accuracy(without attack) 98.93% and accuracy(with attack) 93.03% under attack and overall accuracy 95.98%.\n",
            "\tModel select at epoch 35 with validation accuracy 96.23% and accuracy 93.6% under attack.\n",
            "Training loss (epoch level): 0.0020 | Train accuracy: 99.95%\n",
            "\tVal accuracy(without attack) 98.93% and accuracy(with attack) 93.13% under attack and overall accuracy 96.03%.\n",
            "\tModel select at epoch 35 with validation accuracy 96.23% and accuracy 93.6% under attack.\n",
            "Training loss (epoch level): 0.0019 | Train accuracy: 99.95%\n",
            "\tVal accuracy(without attack) 98.93% and accuracy(with attack) 93.31% under attack and overall accuracy 96.12%.\n",
            "\tModel select at epoch 35 with validation accuracy 96.23% and accuracy 93.6% under attack.\n",
            "Training loss (epoch level): 0.0025 | Train accuracy: 99.95%\n",
            "\tVal accuracy(without attack) 98.94% and accuracy(with attack) 92.67% under attack and overall accuracy 95.8%.\n",
            "\tModel select at epoch 35 with validation accuracy 96.23% and accuracy 93.6% under attack.\n",
            "Training loss (epoch level): 0.0020 | Train accuracy: 99.95%\n",
            "\tVal accuracy(without attack) 98.94% and accuracy(with attack) 93.11% under attack and overall accuracy 96.02%.\n",
            "\tModel select at epoch 35 with validation accuracy 96.23% and accuracy 93.6% under attack.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of your model\n",
        "model_AT_rFGSM = MalwareDetectionModel().to(device)\n",
        "\n",
        "# Load model parameters\n",
        "model_AT_rFGSM.load_state_dict(torch.load('best_model.pth', map_location=torch.device(device)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNbO4UcTbDau",
        "outputId": "67080f4b-a546-42dc-d70d-71e5a2e839fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_evaluation(model_AT_rFGSM,test_loader,device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkgEyoFYKKVW",
        "outputId": "bfea7c7a-7f40-4824-c04b-f356cd984dbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.9886\n",
            "Test balanced Accuracy: 0.9663\n",
            "Precision: 0.9654\n",
            "Recall: 0.9372\n",
            "F1-score: 0.9511\n",
            "True Positives (TP): 1059\n",
            "True Negatives (TN): 8394\n",
            "False Positives (FP): 38\n",
            "False Negatives (FN): 71\n",
            "False Negative Rate (FNR): 6.2832\n",
            "False Positive Rate (FPR): 0.4507\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# with weighted loss\n",
        "# AT-rFGSM: Adversarial Taraining based on rFGSM attack\n",
        "model_AT2 = MalwareDetectionModel().to(device)\n",
        "\n",
        "attack_param = {\"k\":50, \"epsilon\":0.02, 'random':True, \"is_sample\":False, 'is_report_loss_diff':False}\n",
        "adversarial_training(model_AT2, train_loader, val_loader, adv_epochs=50, attack=dfgsm_k, **attack_param)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae17e99f-c5fe-4f41-cf8c-5e0c571eb0e3",
        "id": "ISid8mnBKkP6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/50 | Training loss (epoch level): 0.5498 | Train accuracy: 80.06%\n",
            "\tVal accuracy(without attack) 90.37% and accuracy(with attack) 93.56% under attack and overall accuracy 91.96%.\n",
            "\tModel select at epoch 1 with validation accuracy 91.96% and accuracy 93.56% under attack.\n",
            "Epoch: 2/50 | Training loss (epoch level): 0.2260 | Train accuracy: 94.87%\n",
            "\tVal accuracy(without attack) 95.99% and accuracy(with attack) 93.56% under attack and overall accuracy 94.77%.\n",
            "\tModel select at epoch 2 with validation accuracy 94.77% and accuracy 93.56% under attack.\n",
            "Epoch: 3/50 | Training loss (epoch level): 0.1326 | Train accuracy: 96.29%\n",
            "\tVal accuracy(without attack) 95.99% and accuracy(with attack) 95.85% under attack and overall accuracy 95.92%.\n",
            "\tModel select at epoch 3 with validation accuracy 95.92% and accuracy 95.85% under attack.\n",
            "Epoch: 4/50 | Training loss (epoch level): 0.1006 | Train accuracy: 96.87%\n",
            "\tVal accuracy(without attack) 96.51% and accuracy(with attack) 96.57% under attack and overall accuracy 96.54%.\n",
            "\tModel select at epoch 4 with validation accuracy 96.54% and accuracy 96.57% under attack.\n",
            "Epoch: 5/50 | Training loss (epoch level): 0.0622 | Train accuracy: 98.31%\n",
            "\tVal accuracy(without attack) 97.28% and accuracy(with attack) 95.97% under attack and overall accuracy 96.63%.\n",
            "\tModel select at epoch 5 with validation accuracy 96.63% and accuracy 95.97% under attack.\n",
            "Epoch: 6/50 | Training loss (epoch level): 0.0443 | Train accuracy: 98.84%\n",
            "\tVal accuracy(without attack) 98.55% and accuracy(with attack) 94.83% under attack and overall accuracy 96.69%.\n",
            "\tModel select at epoch 6 with validation accuracy 96.69% and accuracy 94.83% under attack.\n",
            "Epoch: 7/50 | Training loss (epoch level): 0.0383 | Train accuracy: 99.05%\n",
            "\tVal accuracy(without attack) 98.94% and accuracy(with attack) 90.33% under attack and overall accuracy 94.64%.\n",
            "\tModel select at epoch 6 with validation accuracy 96.69% and accuracy 94.83% under attack.\n",
            "Epoch: 8/50 | Training loss (epoch level): 0.0344 | Train accuracy: 99.18%\n",
            "\tVal accuracy(without attack) 98.29% and accuracy(with attack) 93.36% under attack and overall accuracy 95.83%.\n",
            "\tModel select at epoch 6 with validation accuracy 96.69% and accuracy 94.83% under attack.\n",
            "Epoch: 9/50 | Training loss (epoch level): 0.0311 | Train accuracy: 99.27%\n",
            "\tVal accuracy(without attack) 98.7% and accuracy(with attack) 92.96% under attack and overall accuracy 95.83%.\n",
            "\tModel select at epoch 6 with validation accuracy 96.69% and accuracy 94.83% under attack.\n",
            "Epoch: 10/50 | Training loss (epoch level): 0.0278 | Train accuracy: 99.43%\n",
            "\tVal accuracy(without attack) 98.99% and accuracy(with attack) 92.58% under attack and overall accuracy 95.79%.\n",
            "\tModel select at epoch 6 with validation accuracy 96.69% and accuracy 94.83% under attack.\n",
            "Epoch: 11/50 | Training loss (epoch level): 0.0194 | Train accuracy: 99.67%\n",
            "\tVal accuracy(without attack) 98.62% and accuracy(with attack) 95.05% under attack and overall accuracy 96.83%.\n",
            "\tModel select at epoch 11 with validation accuracy 96.83% and accuracy 95.05% under attack.\n",
            "Epoch: 12/50 | Training loss (epoch level): 0.0200 | Train accuracy: 99.61%\n",
            "\tVal accuracy(without attack) 98.67% and accuracy(with attack) 94.3% under attack and overall accuracy 96.49%.\n",
            "\tModel select at epoch 11 with validation accuracy 96.83% and accuracy 95.05% under attack.\n",
            "Epoch: 13/50 | Training loss (epoch level): 0.0215 | Train accuracy: 99.54%\n",
            "\tVal accuracy(without attack) 97.35% and accuracy(with attack) 95.81% under attack and overall accuracy 96.58%.\n",
            "\tModel select at epoch 11 with validation accuracy 96.83% and accuracy 95.05% under attack.\n",
            "Epoch: 14/50 | Training loss (epoch level): 0.0202 | Train accuracy: 99.68%\n",
            "\tVal accuracy(without attack) 98.74% and accuracy(with attack) 93.28% under attack and overall accuracy 96.01%.\n",
            "\tModel select at epoch 11 with validation accuracy 96.83% and accuracy 95.05% under attack.\n",
            "Epoch: 15/50 | Training loss (epoch level): 0.0174 | Train accuracy: 99.75%\n",
            "\tVal accuracy(without attack) 98.99% and accuracy(with attack) 92.3% under attack and overall accuracy 95.64%.\n",
            "\tModel select at epoch 11 with validation accuracy 96.83% and accuracy 95.05% under attack.\n",
            "Epoch: 16/50 | Training loss (epoch level): 0.0198 | Train accuracy: 99.63%\n",
            "\tVal accuracy(without attack) 98.86% and accuracy(with attack) 93.05% under attack and overall accuracy 95.96%.\n",
            "\tModel select at epoch 11 with validation accuracy 96.83% and accuracy 95.05% under attack.\n",
            "Epoch: 17/50 | Training loss (epoch level): 0.0145 | Train accuracy: 99.77%\n",
            "\tVal accuracy(without attack) 98.9% and accuracy(with attack) 93.42% under attack and overall accuracy 96.16%.\n",
            "\tModel select at epoch 11 with validation accuracy 96.83% and accuracy 95.05% under attack.\n",
            "Epoch: 18/50 | Training loss (epoch level): 0.0138 | Train accuracy: 99.76%\n",
            "\tVal accuracy(without attack) 98.8% and accuracy(with attack) 93.07% under attack and overall accuracy 95.93%.\n",
            "\tModel select at epoch 11 with validation accuracy 96.83% and accuracy 95.05% under attack.\n",
            "Epoch: 19/50 | Training loss (epoch level): 0.0137 | Train accuracy: 99.72%\n",
            "\tVal accuracy(without attack) 98.83% and accuracy(with attack) 93.21% under attack and overall accuracy 96.02%.\n",
            "\tModel select at epoch 11 with validation accuracy 96.83% and accuracy 95.05% under attack.\n",
            "Epoch: 20/50 | Training loss (epoch level): 0.0123 | Train accuracy: 99.78%\n",
            "\tVal accuracy(without attack) 98.9% and accuracy(with attack) 93.06% under attack and overall accuracy 95.98%.\n",
            "\tModel select at epoch 11 with validation accuracy 96.83% and accuracy 95.05% under attack.\n",
            "Epoch: 21/50 | Training loss (epoch level): 0.0140 | Train accuracy: 99.69%\n",
            "\tVal accuracy(without attack) 98.88% and accuracy(with attack) 93.63% under attack and overall accuracy 96.25%.\n",
            "\tModel select at epoch 11 with validation accuracy 96.83% and accuracy 95.05% under attack.\n",
            "Epoch: 22/50 | Training loss (epoch level): 0.0107 | Train accuracy: 99.76%\n",
            "\tVal accuracy(without attack) 98.53% and accuracy(with attack) 93.95% under attack and overall accuracy 96.24%.\n",
            "\tModel select at epoch 11 with validation accuracy 96.83% and accuracy 95.05% under attack.\n",
            "Epoch: 23/50 | Training loss (epoch level): 0.0154 | Train accuracy: 99.59%\n",
            "\tVal accuracy(without attack) 98.6% and accuracy(with attack) 94.13% under attack and overall accuracy 96.37%.\n",
            "\tModel select at epoch 11 with validation accuracy 96.83% and accuracy 95.05% under attack.\n",
            "Epoch: 24/50 | Training loss (epoch level): 0.0095 | Train accuracy: 99.85%\n",
            "\tVal accuracy(without attack) 98.74% and accuracy(with attack) 93.53% under attack and overall accuracy 96.13%.\n",
            "\tModel select at epoch 11 with validation accuracy 96.83% and accuracy 95.05% under attack.\n",
            "Epoch: 25/50 | Training loss (epoch level): 0.0133 | Train accuracy: 99.74%\n",
            "\tVal accuracy(without attack) 98.44% and accuracy(with attack) 95.11% under attack and overall accuracy 96.78%.\n",
            "\tModel select at epoch 11 with validation accuracy 96.83% and accuracy 95.05% under attack.\n",
            "Epoch: 26/50 | Training loss (epoch level): 0.0060 | Train accuracy: 99.89%\n",
            "\tVal accuracy(without attack) 98.76% and accuracy(with attack) 93.91% under attack and overall accuracy 96.33%.\n",
            "\tModel select at epoch 11 with validation accuracy 96.83% and accuracy 95.05% under attack.\n",
            "Epoch: 27/50 | Training loss (epoch level): 0.0051 | Train accuracy: 99.94%\n",
            "\tVal accuracy(without attack) 98.81% and accuracy(with attack) 94.53% under attack and overall accuracy 96.67%.\n",
            "\tModel select at epoch 11 with validation accuracy 96.83% and accuracy 95.05% under attack.\n",
            "Epoch: 28/50 | Training loss (epoch level): 0.0049 | Train accuracy: 99.93%\n",
            "\tVal accuracy(without attack) 98.74% and accuracy(with attack) 94.46% under attack and overall accuracy 96.6%.\n",
            "\tModel select at epoch 11 with validation accuracy 96.83% and accuracy 95.05% under attack.\n",
            "Epoch: 29/50 | Training loss (epoch level): 0.0056 | Train accuracy: 99.93%\n",
            "\tVal accuracy(without attack) 98.87% and accuracy(with attack) 93.97% under attack and overall accuracy 96.42%.\n",
            "\tModel select at epoch 11 with validation accuracy 96.83% and accuracy 95.05% under attack.\n",
            "Epoch: 30/50 | Training loss (epoch level): 0.0060 | Train accuracy: 99.91%\n",
            "\tVal accuracy(without attack) 98.54% and accuracy(with attack) 94.56% under attack and overall accuracy 96.55%.\n",
            "\tModel select at epoch 11 with validation accuracy 96.83% and accuracy 95.05% under attack.\n",
            "Epoch: 31/50 | Training loss (epoch level): 0.0055 | Train accuracy: 99.93%\n",
            "\tVal accuracy(without attack) 98.53% and accuracy(with attack) 94.61% under attack and overall accuracy 96.57%.\n",
            "\tModel select at epoch 11 with validation accuracy 96.83% and accuracy 95.05% under attack.\n",
            "Epoch: 32/50 | Training loss (epoch level): 0.0033 | Train accuracy: 99.95%\n",
            "\tVal accuracy(without attack) 98.61% and accuracy(with attack) 94.82% under attack and overall accuracy 96.72%.\n",
            "\tModel select at epoch 11 with validation accuracy 96.83% and accuracy 95.05% under attack.\n",
            "Epoch: 33/50 | Training loss (epoch level): 0.0043 | Train accuracy: 99.91%\n",
            "\tVal accuracy(without attack) 98.78% and accuracy(with attack) 94.27% under attack and overall accuracy 96.53%.\n",
            "\tModel select at epoch 11 with validation accuracy 96.83% and accuracy 95.05% under attack.\n",
            "Epoch: 34/50 | Training loss (epoch level): 0.0031 | Train accuracy: 99.95%\n",
            "\tVal accuracy(without attack) 98.72% and accuracy(with attack) 94.37% under attack and overall accuracy 96.55%.\n",
            "\tModel select at epoch 11 with validation accuracy 96.83% and accuracy 95.05% under attack.\n",
            "Epoch: 35/50 | Training loss (epoch level): 0.0046 | Train accuracy: 99.93%\n",
            "\tVal accuracy(without attack) 98.51% and accuracy(with attack) 95.13% under attack and overall accuracy 96.82%.\n",
            "\tModel select at epoch 11 with validation accuracy 96.83% and accuracy 95.05% under attack.\n",
            "Epoch: 36/50 | Training loss (epoch level): 0.0039 | Train accuracy: 99.93%\n",
            "\tVal accuracy(without attack) 98.71% and accuracy(with attack) 94.14% under attack and overall accuracy 96.43%.\n",
            "\tModel select at epoch 11 with validation accuracy 96.83% and accuracy 95.05% under attack.\n",
            "Epoch: 37/50 | Training loss (epoch level): 0.0024 | Train accuracy: 99.95%\n",
            "\tVal accuracy(without attack) 98.76% and accuracy(with attack) 94.06% under attack and overall accuracy 96.41%.\n",
            "\tModel select at epoch 11 with validation accuracy 96.83% and accuracy 95.05% under attack.\n",
            "Epoch: 38/50 | Training loss (epoch level): 0.0024 | Train accuracy: 99.96%\n",
            "\tVal accuracy(without attack) 98.78% and accuracy(with attack) 94.27% under attack and overall accuracy 96.52%.\n",
            "\tModel select at epoch 11 with validation accuracy 96.83% and accuracy 95.05% under attack.\n",
            "Epoch: 39/50 | Training loss (epoch level): 0.0020 | Train accuracy: 99.96%\n",
            "\tVal accuracy(without attack) 98.79% and accuracy(with attack) 93.8% under attack and overall accuracy 96.29%.\n",
            "\tModel select at epoch 11 with validation accuracy 96.83% and accuracy 95.05% under attack.\n",
            "Epoch: 40/50 | Training loss (epoch level): 0.0027 | Train accuracy: 99.94%\n",
            "\tVal accuracy(without attack) 98.8% and accuracy(with attack) 93.93% under attack and overall accuracy 96.36%.\n",
            "\tModel select at epoch 11 with validation accuracy 96.83% and accuracy 95.05% under attack.\n",
            "Epoch: 41/50 | Training loss (epoch level): 0.0027 | Train accuracy: 99.94%\n",
            "\tVal accuracy(without attack) 98.8% and accuracy(with attack) 94.05% under attack and overall accuracy 96.42%.\n",
            "\tModel select at epoch 11 with validation accuracy 96.83% and accuracy 95.05% under attack.\n",
            "Epoch: 42/50 | Training loss (epoch level): 0.0030 | Train accuracy: 99.94%\n",
            "\tVal accuracy(without attack) 98.78% and accuracy(with attack) 94.71% under attack and overall accuracy 96.74%.\n",
            "\tModel select at epoch 11 with validation accuracy 96.83% and accuracy 95.05% under attack.\n",
            "Epoch: 43/50 | Training loss (epoch level): 0.0024 | Train accuracy: 99.96%\n",
            "\tVal accuracy(without attack) 98.83% and accuracy(with attack) 94.5% under attack and overall accuracy 96.66%.\n",
            "\tModel select at epoch 11 with validation accuracy 96.83% and accuracy 95.05% under attack.\n",
            "Epoch: 44/50 | Training loss (epoch level): 0.0025 | Train accuracy: 99.94%\n",
            "\tVal accuracy(without attack) 98.77% and accuracy(with attack) 94.11% under attack and overall accuracy 96.44%.\n",
            "\tModel select at epoch 11 with validation accuracy 96.83% and accuracy 95.05% under attack.\n",
            "Epoch: 45/50 | Training loss (epoch level): 0.0027 | Train accuracy: 99.95%\n",
            "\tVal accuracy(without attack) 98.71% and accuracy(with attack) 94.73% under attack and overall accuracy 96.72%.\n",
            "\tModel select at epoch 11 with validation accuracy 96.83% and accuracy 95.05% under attack.\n",
            "Epoch: 46/50 | Training loss (epoch level): 0.0019 | Train accuracy: 99.95%\n",
            "\tVal accuracy(without attack) 98.72% and accuracy(with attack) 94.42% under attack and overall accuracy 96.57%.\n",
            "\tModel select at epoch 11 with validation accuracy 96.83% and accuracy 95.05% under attack.\n",
            "Epoch: 47/50 | Training loss (epoch level): 0.0032 | Train accuracy: 99.95%\n",
            "\tVal accuracy(without attack) 98.72% and accuracy(with attack) 94.25% under attack and overall accuracy 96.49%.\n",
            "\tModel select at epoch 11 with validation accuracy 96.83% and accuracy 95.05% under attack.\n",
            "Epoch: 48/50 | Training loss (epoch level): 0.0031 | Train accuracy: 99.95%\n",
            "\tVal accuracy(without attack) 98.75% and accuracy(with attack) 94.2% under attack and overall accuracy 96.47%.\n",
            "\tModel select at epoch 11 with validation accuracy 96.83% and accuracy 95.05% under attack.\n",
            "Epoch: 49/50 | Training loss (epoch level): 0.0024 | Train accuracy: 99.96%\n",
            "\tVal accuracy(without attack) 98.75% and accuracy(with attack) 94.17% under attack and overall accuracy 96.46%.\n",
            "\tModel select at epoch 11 with validation accuracy 96.83% and accuracy 95.05% under attack.\n",
            "Epoch: 50/50 | Training loss (epoch level): 0.0027 | Train accuracy: 99.95%\n",
            "\tVal accuracy(without attack) 98.75% and accuracy(with attack) 94.34% under attack and overall accuracy 96.54%.\n",
            "\tModel select at epoch 11 with validation accuracy 96.83% and accuracy 95.05% under attack.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of your model\n",
        "model_AT_rFGSM_weightedLoss = MalwareDetectionModel().to(device)\n",
        "\n",
        "# Load model parameters\n",
        "model_AT_rFGSM_weightedLoss.load_state_dict(torch.load('best_AT_model.pth', map_location=torch.device(device)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce62ce0c-bf85-4c8b-c17d-d3ff8fd9460d",
        "id": "CHO0asXWKkQG"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_evaluation(model_AT_rFGSM_weightedLoss,test_loader,device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18986395-174d-406c-c3a3-e4ad63ced288",
        "id": "BC6ROTzzKkQG"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.9861\n",
            "Test balanced Accuracy: 0.9745\n",
            "Precision: 0.9257\n",
            "Recall: 0.9593\n",
            "F1-score: 0.9422\n",
            "True Positives (TP): 1084\n",
            "True Negatives (TN): 8345\n",
            "False Positives (FP): 87\n",
            "False Negatives (FN): 46\n",
            "False Negative Rate (FNR): 4.0708\n",
            "False Positive Rate (FPR): 1.0318\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# rFGSM\n",
        "attack_params = {\"k\":50, \"epsilon\":0.02, 'random':True, 'is_report_loss_diff':False, 'is_sample':False}\n",
        "adv_predict(test_loader, model_DNN, dfgsm_k, device, **attack_params)\n",
        "adv_predict(test_loader, model_AT_rFGSM, dfgsm_k, device, **attack_params)\n",
        "adv_predict(test_loader, model_AT_rFGSM_weightedLoss, dfgsm_k, device, **attack_params)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqfTOzwROvHv",
        "outputId": "2c35c8d2-927a-427f-d97d-51db2b0e30aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adversarial accuracy (without attack): 99.12% | Under attack: 0.0%.\n",
            "Adversarial accuracy (without attack): 98.86% | Under attack: 93.51%.\n",
            "Adversarial accuracy (without attack): 98.61% | Under attack: 94.8%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# rFGSM\n",
        "attack_params = {\"k\":100, \"epsilon\":0.02, 'random':True, 'is_report_loss_diff':False, 'is_sample':False}\n",
        "adv_predict(test_loader, model_DNN, dfgsm_k, device, **attack_params)\n",
        "adv_predict(test_loader, model_AT_rFGSM, dfgsm_k, device, **attack_params)\n",
        "adv_predict(test_loader, model_AT_rFGSM_weightedLoss, dfgsm_k, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpmIzWPcPobq",
        "outputId": "0658890f-cd59-4171-abb2-cc22eae53bbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adversarial accuracy (without attack): 99.12% | Under attack: 0.0%.\n",
            "Adversarial accuracy (without attack): 98.86% | Under attack: 93.44%.\n",
            "Adversarial accuracy (without attack): 98.61% | Under attack: 95.05%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "summary(model_AT_rFGSM, input_size=(10000,))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z78Usym2lnYz",
        "outputId": "f2852eac-ad50-45ba-fb50-33988717ffe6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1                  [-1, 200]       2,000,200\n",
            "              ReLU-2                  [-1, 200]               0\n",
            "           Dropout-3                  [-1, 200]               0\n",
            "            Linear-4                  [-1, 200]          40,200\n",
            "              ReLU-5                  [-1, 200]               0\n",
            "           Dropout-6                  [-1, 200]               0\n",
            "            Linear-7                    [-1, 2]             402\n",
            "        LogSoftmax-8                    [-1, 2]               0\n",
            "================================================================\n",
            "Total params: 2,040,802\n",
            "Trainable params: 2,040,802\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.04\n",
            "Forward/backward pass size (MB): 0.01\n",
            "Params size (MB): 7.79\n",
            "Estimated Total Size (MB): 7.83\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_evaluation(model_AT_rFGSM,test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ij9DGjvBedLq",
        "outputId": "23a6754e-9af7-4aba-e594-33e81a5804cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.9936\n",
            "Precision: 0.9365\n",
            "Recall: 0.9146\n",
            "F1-score: 0.9254\n",
            "True Positives (TP): 1017\n",
            "True Negatives (TN): 24622\n",
            "False Positives (FP): 69\n",
            "False Negatives (FN): 95\n",
            "False Negative Rate (FNR): 0.0854\n",
            "False Positive Rate (FPR): 0.0028\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_evaluation(model_DNN,test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlvGyZI2jk3N",
        "outputId": "ed661cf4-d96d-4744-c8ad-91cae260b8ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.9934\n",
            "Precision: 0.9654\n",
            "Recall: 0.8786\n",
            "F1-score: 0.9200\n",
            "True Positives (TP): 977\n",
            "True Negatives (TN): 24656\n",
            "False Positives (FP): 35\n",
            "False Negatives (FN): 135\n",
            "False Negative Rate (FNR): 0.1214\n",
            "False Positive Rate (FPR): 0.0014\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Evaluate the trained model on the test set\n",
        "model_AT_rFGSM.eval()  # Set the model to evaluation mode\n",
        "predictions = []\n",
        "true_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for X_batch, labels_batch in test_loader:\n",
        "        outputs = model_AT_rFGSM(X_batch)\n",
        "        _, predicted = torch.topk(outputs, k=1)\n",
        "        predictions.extend(predicted.tolist())\n",
        "        true_labels.extend(labels_batch.tolist())\n",
        "\n",
        "# Convert predictions and true labels to numpy arrays\n",
        "predictions = np.array(predictions)\n",
        "true_labels = np.array(true_labels)\n",
        "\n",
        "# Calculate test accuracy\n",
        "accuracy = accuracy_score(true_labels, predictions)\n",
        "print(f'Test Accuracy: {accuracy:.4f}')\n",
        "\n",
        "# Calculate precision, recall, and F1-score\n",
        "precision = precision_score(true_labels, predictions)\n",
        "recall = recall_score(true_labels, predictions)\n",
        "f1 = f1_score(true_labels, predictions)\n",
        "\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print(f'F1-score: {f1:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "9KpsMmX_dshg",
        "outputId": "de9a9e44-8392-4d53-974c-6e3f52a5469d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 must have the same dtype, but got Char and Float",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-d9285cfb3ead>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_AT_rFGSM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-0d2881a5e67e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 must have the same dtype, but got Char and Float"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adv_predict(test_loader, model_DNN, attack=pgd, is_report_loss_diff=False, device=device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hZyGeB3umw4",
        "outputId": "49022b95-dcee-44d7-a3e0-bb1febca0582"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adversarial accuracy (without attack): 99.34% | Under attack: 0.0%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adv_predict(test_loader, model_AT_rFGSM, attack=pgd, is_report_loss_diff=False, device=device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9I9WmuKLbSc4",
        "outputId": "808b07ea-223a-4d31-befd-131aee0c2a0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adversarial accuracy (without attack): 99.36% | Under attack: 90.83%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Groose\n",
        "attack_params = {\"k\":100, 'is_report_loss_diff':False}\n",
        "adv_predict(test_loader, model_DNN, grosse_k, device, **attack_params)\n",
        "adv_predict(test_loader, model_AT_rFGSM, grosse_k, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wONb0rUJRvzW",
        "outputId": "5f74495b-d92f-4537-92d8-7c513d6469ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adversarial accuracy (without attack): 99.34% | Under attack: 0.0%.\n",
            "Adversarial accuracy (without attack): 99.36% | Under attack: 83.93%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BCA\n",
        "attack_params = {\"k\":100, 'is_report_loss_diff':False, 'use_sample':False}\n",
        "adv_predict(test_loader, model_DNN, bca_k, device, **attack_params)\n",
        "adv_predict(test_loader, model_AT_rFGSM, bca_k, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJGl4w0BSacY",
        "outputId": "ab944b0f-64bc-442f-cb45-b0ff2e344134"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adversarial accuracy (without attack): 99.34% | Under attack: 0.0%.\n",
            "Adversarial accuracy (without attack): 99.36% | Under attack: 83.93%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BGA\n",
        "attack_params = {\"k\":100, 'is_report_loss_diff':False, 'use_sample':False}\n",
        "adv_predict(test_loader, model_DNN, bga_k, device, **attack_params)\n",
        "adv_predict(test_loader, model_AT_rFGSM, bga_k, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smmqoxFBTSBn",
        "outputId": "ee0dc6bf-d1d5-49c9-a90e-90a52a9083b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adversarial accuracy (without attack): 99.34% | Under attack: 0.0%.\n",
            "Adversarial accuracy (without attack): 99.36% | Under attack: 90.87%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# rFGSM\n",
        "attack_params = {\"k\":100, \"epsilon\":0.02, 'random':True, 'is_report_loss_diff':False, 'is_sample':False}\n",
        "adv_predict(test_loader, model_DNN, dfgsm_k, device, **attack_params)\n",
        "adv_predict(test_loader, model_AT_rFGSM, dfgsm_k, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4PPi7cYTn6P",
        "outputId": "c8c0f90f-fb99-46f6-f4c5-45ee46993c12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adversarial accuracy (without attack): 99.34% | Under attack: 0.0%.\n",
            "Adversarial accuracy (without attack): 99.36% | Under attack: 89.91%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PGD-l1\n",
        "attack_params = {\"k\":500, \"step_length\":1., 'norm':'l1', 'random':False, 'is_report_loss_diff':False, 'is_sample':False}\n",
        "adv_predict(test_loader, model_DNN, pgd, device, **attack_params)\n",
        "adv_predict(test_loader, model_AT_rFGSM, pgd, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TkyHWVekVDVm",
        "outputId": "2a3d4e03-43d5-4b05-fbb5-9f605a562ce7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adversarial accuracy (without attack): 99.34% | Under attack: 0.0%.\n",
            "Adversarial accuracy (without attack): 99.36% | Under attack: 82.9%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PGD-l2\n",
        "attack_params = {\"k\":200, \"step_length\":0.05, 'norm':'l2', 'random':False, 'is_report_loss_diff':False, 'is_sample':False}\n",
        "adv_predict(test_loader, model_DNN, pgd, device, **attack_params)\n",
        "adv_predict(test_loader, model_AT_rFGSM, pgd, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vB4Edv2wVnH9",
        "outputId": "b1a62e4c-4ff9-4f10-fea7-36b08bd20c6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adversarial accuracy (without attack): 99.34% | Under attack: 40.03%.\n",
            "Adversarial accuracy (without attack): 99.36% | Under attack: 91.56%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PGD-linf\n",
        "attack_params = {\"k\":500, \"step_length\":0.002, 'norm':'linf', 'random':False, 'is_report_loss_diff':False, 'is_sample':False}\n",
        "adv_predict(test_loader, model_DNN, pgd, device, **attack_params)\n",
        "adv_predict(test_loader, model_AT_rFGSM, pgd, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5noPLfF6V5Wm",
        "outputId": "6f0fcdd7-5592-4de6-e167-bdd6517c410c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adversarial accuracy (without attack): 99.34% | Under attack: 0.0%.\n",
            "Adversarial accuracy (without attack): 99.36% | Under attack: 86.74%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mimicry×1\n",
        "attack_params = {\"trials\":1, 'is_report_loss_diff':False}\n",
        "adv_predict(test_loader, model_DNN, mimicry, device, **attack_params)\n",
        "adv_predict(test_loader, model_AT_rFGSM, mimicry, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffeGFo4kqm2I",
        "outputId": "d809984c-c855-494a-c64c-217639252a4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adversarial accuracy (without attack): 99.34% | Under attack: 84.44%.\n",
            "Adversarial accuracy (without attack): 99.36% | Under attack: 92.63%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mimicry×10\n",
        "attack_params = {\"trials\":10, 'is_report_loss_diff':False}\n",
        "adv_predict(test_loader, model_DNN, mimicry, device, **attack_params)\n",
        "adv_predict(test_loader, model_AT_rFGSM, mimicry, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcWutrM5qpV9",
        "outputId": "b79c61ee-8f74-4b8a-d8e3-2a07ab83e7d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adversarial accuracy (without attack): 99.34% | Under attack: 4.929%.\n",
            "Adversarial accuracy (without attack): 99.36% | Under attack: 83.69%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mimicry×30\n",
        "attack_params = {\"trials\":30, 'is_report_loss_diff':False}\n",
        "adv_predict(test_loader, model_DNN, mimicry, device, **attack_params)\n",
        "adv_predict(test_loader, model_AT_rFGSM, mimicry, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2uu0nOrWRnM",
        "outputId": "217144f7-0519-47db-fe1d-4b144ae4c91e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adversarial accuracy (without attack): 99.34% | Under attack: 4.929%.\n",
            "Adversarial accuracy (without attack): 99.36% | Under attack: 83.69%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mimicry×100\n",
        "attack_params = {\"trials\":100, 'is_report_loss_diff':False}\n",
        "adv_predict(test_loader, model_DNN, mimicry, device, **attack_params)\n",
        "adv_predict(test_loader, model_AT_rFGSM, mimicry, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mfW_K--ErFY-",
        "outputId": "f48a6cd8-10dc-424d-8821-6e8a29d29194"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adversarial accuracy (without attack): 99.34% | Under attack: 4.929%.\n",
            "Adversarial accuracy (without attack): 99.36% | Under attack: 83.59%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mimicry×1000\n",
        "attack_params = {\"trials\":1000, 'is_report_loss_diff':False}\n",
        "adv_predict(test_loader, model_DNN, mimicry, device, **attack_params)\n",
        "adv_predict(test_loader, model_AT_rFGSM, mimicry, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KdwkoNeZ_hjk",
        "outputId": "23cfe68e-a7c3-4c07-edcf-d81cea29aa04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adversarial accuracy (without attack): 99.34% | Under attack: 1.517%.\n",
            "Adversarial accuracy (without attack): 99.36% | Under attack: 82.68%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mimicry×1000\n",
        "attack_params = {\"trials\":5000, 'is_report_loss_diff':False}\n",
        "adv_predict(test_loader, model_DNN, mimicry, device, **attack_params)\n",
        "adv_predict(test_loader, model_AT_rFGSM, mimicry, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTP15xFADZkm",
        "outputId": "158c7f5a-1539-4e25-f01c-83a4713060d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adversarial accuracy (without attack): 99.34% | Under attack: 0.0%.\n",
            "Adversarial accuracy (without attack): 99.36% | Under attack: 74.55%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attack_params = {'step_lengths':{\"l1\": 1.0, \"l2\": 0.05, \"linf\": 0.001}, \"steps\":500}\n",
        "adv_predict(test_loader, model_AT_rFGSM, StepwiseMax_onestep2, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "xylm8-33y2uc",
        "outputId": "3d6737b2-ef8f-4c76-d1be-345b057e242b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step-wise max: attack effectiveness 0.000%.\n",
            "step-wise max: attack effectiveness 10.000%.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-e8a25759aed8>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mattack_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'step_lengths'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"l1\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"l2\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"linf\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"steps\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0madv_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_AT_rFGSM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStepwiseMax_onestep2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mattack_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-13-b64b9f5a7c87>\u001b[0m in \u001b[0;36madv_predict\u001b[0;34m(test_loader, model, attack, device, **kwargs)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m# Generate adversarial examples for test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mmal_x_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmal_y_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mpertb_mal_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmal_x_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmal_y_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpertb_mal_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/adverserial_attacks_functions.py\u001b[0m in \u001b[0;36mStepwiseMax_onestep2\u001b[0;34m(x, label, model, attack_list, step_lengths, steps, random_start, round_threshold)\u001b[0m\n\u001b[1;32m   1140\u001b[0m       \u001b[0mnum_sample_red\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1142\u001b[0;31m       \u001b[0mpertbx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpgd_one_step2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madv_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_lengths\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/adverserial_attacks_functions.py\u001b[0m in \u001b[0;36mpgd_one_step2\u001b[0;34m(x, y, model, step_lengths, x_initial)\u001b[0m\n\u001b[1;32m   1047\u001b[0m     \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m     \u001b[0mx_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_next\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m     \u001b[0my_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1050\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-0d2881a5e67e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define different attacks with their parameters\n",
        "attacks = [\n",
        "    (dfgsm_k, {\"k\":100, \"epsilon\":0.02, 'is_report_loss_diff' : False}),\n",
        "    (bga_k, {\"k\":100, 'is_report_loss_diff' : False}),\n",
        "    (bca_k, {\"k\":100, 'is_report_loss_diff' : False}),\n",
        "    (grosse_k, {\"k\":100, 'is_report_loss_diff' : False}),\n",
        "\n",
        "    (pgd, {'k': 100, 'step_length': 1., 'norm': 'l1', 'is_report_loss_diff' : False}),\n",
        "    (pgd, {'k': 200, 'step_length': 0.05, 'norm': 'l2', 'is_report_loss_diff' : False}),\n",
        "    (pgd, {'k': 100, 'step_length': 0.02, 'norm': 'linf', 'is_report_loss_diff' : False}),\n",
        "    (StepwiseMax_onestep2, {'step_lengths':{\"l1\": 1.0, \"l2\": 0.05, \"linf\": 0.0008}, \"steps\":650}),\n",
        "\n",
        "    # Add more attacks as needed\n",
        "]\n",
        "\n",
        "# Iterate over each attack and its parameters\n",
        "for attack_func, attack_params in attacks:\n",
        "    print(f\"Running attack: {attack_func.__name__} with parameters: {attack_params}\")\n",
        "    adv_predict(test_loader, model_AT_rFGSM, attack_func, device, **attack_params)\n",
        "    print()  # Print an empty line for separation\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JDuv4WBvq54",
        "outputId": "24045f6f-205a-483c-fb74-49842ac7bc35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running attack: dfgsm_k with parameters: {'k': 50, 'epsilon': 0.02, 'is_report_loss_diff': False}\n",
            "Adversarial accuracy (without attack): 99.25% | Under attack: 83.43%.\n",
            "\n",
            "Running attack: bga_k with parameters: {'k': 25, 'is_report_loss_diff': False}\n",
            "Adversarial accuracy (without attack): 99.25% | Under attack: 91.57%.\n",
            "\n",
            "Running attack: bca_k with parameters: {'k': 25, 'is_report_loss_diff': False}\n",
            "Adversarial accuracy (without attack): 99.25% | Under attack: 87.93%.\n",
            "\n",
            "Running attack: grosse_k with parameters: {'k': 25, 'is_report_loss_diff': False}\n",
            "Adversarial accuracy (without attack): 99.25% | Under attack: 87.93%.\n",
            "\n",
            "Running attack: pgd with parameters: {'k': 100, 'step_length': 1.0, 'norm': 'l1', 'is_report_loss_diff': False}\n",
            "Adversarial accuracy (without attack): 99.25% | Under attack: 87.24%.\n",
            "\n",
            "Running attack: pgd with parameters: {'k': 200, 'step_length': 0.05, 'norm': 'l2', 'is_report_loss_diff': False}\n",
            "Adversarial accuracy (without attack): 99.25% | Under attack: 91.67%.\n",
            "\n",
            "Running attack: pgd with parameters: {'k': 500, 'step_length': 0.002, 'norm': 'linf', 'is_report_loss_diff': False}\n",
            "Adversarial accuracy (without attack): 99.25% | Under attack: 87.98%.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1vpuDgt1W-0R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "def mimic_attack_effectiveness_optimized(test_loader, model, seed, trials=1000, device=\"cuda:0\"):\n",
        "  \"\"\"\n",
        "  Calculates the effectiveness of the mimic attack on the given model.\n",
        "\n",
        "  Args:\n",
        "      test_loader: A PyTorch dataloader containing the test data.\n",
        "      model: The PyTorch model to be attacked.\n",
        "      seed: The random seed for reproducibility.\n",
        "      trials: The number of random samples to use from the benign class (default: 1000).\n",
        "      device: The device to use for computations (default: \"cuda:0\" if available, otherwise \"cpu\").\n",
        "\n",
        "  Returns:\n",
        "      The effectiveness of the mimic attack as a percentage (float).\n",
        "  \"\"\"\n",
        "\n",
        "  torch.manual_seed(seed)\n",
        "  model.eval()\n",
        "\n",
        "  # Initialize counters\n",
        "  successful_attacks = 0\n",
        "  total_malicious_samples = 0\n",
        "\n",
        "  # Pre-select benign samples for efficiency\n",
        "  benign_samples = []\n",
        "  for x_batch, y_batch in test_loader:\n",
        "    benign_samples.append(x_batch[y_batch.squeeze() == 0])\n",
        "\n",
        "  ben_x = torch.cat(benign_samples, dim=0).to(device)\n",
        "\n",
        "  # Clear unnecessary variables\n",
        "  del benign_samples\n",
        "\n",
        "  trials = min(trials, len(ben_x))\n",
        "\n",
        "\n",
        "  for x_batch, y_batch in test_loader:\n",
        "    x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
        "    malicious_samples = x_batch[y_batch.squeeze() == 1]\n",
        "\n",
        "    if len(malicious_samples) > 0:\n",
        "      # Expand dimensions for efficient broadcasting\n",
        "      malicious_samples_expanded = malicious_samples.unsqueeze(1).expand(-1, trials, -1)\n",
        "\n",
        "      # Generate random indices outside the loop\n",
        "      seed += 1\n",
        "      torch.manual_seed(seed)\n",
        "      indices = torch.randperm(len(ben_x), device=device)[:trials]\n",
        "      trial_vectors_expanded = ben_x[indices].unsqueeze(0)\n",
        "\n",
        "      # Perform the mimic attack and update counters\n",
        "      modified_x = torch.clamp(malicious_samples_expanded + trial_vectors_expanded, min=0., max=1.)\n",
        "      _, done = get_loss(modified_x.view(-1, modified_x.shape[-1]), torch.ones(trials * malicious_samples.shape[0], 1, device=device), model)\n",
        "      successful_attacks += (done.view(malicious_samples.shape[0], trials).sum(dim=1) > 0).sum().item()\n",
        "      total_malicious_samples += malicious_samples.shape[0]\n",
        "\n",
        "  # Calculate and print attack effectiveness\n",
        "  attack_effectiveness = (successful_attacks / total_malicious_samples) * 100 if total_malicious_samples > 0 else 0\n",
        "  print(f\"Mimic attack effectiveness: {attack_effectiveness:.3f}%.\")\n",
        "\n",
        "  return attack_effectiveness  # Added return statement for clarity\n",
        "\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "kVA4nOM0YUVa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mimicry(ben_x, malicious_samples, model_DNN, trials=30, seed=230, is_report_loss_diff=False):\n",
        "    \"\"\"\n",
        "    Perform a mimicry attack.\n",
        "\n",
        "    Args:\n",
        "    - ben_x (torch.Tensor): Benign samples tensor.\n",
        "    - malicious_samples (torch.Tensor): Malicious samples tensor.\n",
        "    - model_DNN (torch.nn.Module): PyTorch model used for the attack.\n",
        "    - trials (int): Number of trials for the attack.\n",
        "    - seed (int): Random seed for reproducibility.\n",
        "    - is_report_loss_diff (bool): Flag to indicate whether to report attack effectiveness.\n",
        "\n",
        "    Returns:\n",
        "    - adv_x (torch.Tensor): Adversarial examples tensor.\n",
        "    \"\"\"\n",
        "\n",
        "    # Ensure trials do not exceed the length of ben_x\n",
        "    trials = min(trials, len(ben_x))\n",
        "\n",
        "    # Get the number of malicious samples\n",
        "    n_samples = len(malicious_samples)\n",
        "\n",
        "    if n_samples > 0:\n",
        "        # Expand dimensions for efficient broadcasting\n",
        "        malicious_samples_expanded = malicious_samples.unsqueeze(1).expand(-1, trials, -1)\n",
        "\n",
        "        # Generate random indices for sampling from ben_x\n",
        "        torch.manual_seed(seed)\n",
        "        indices = torch.randperm(len(ben_x), device=ben_x.device)[:trials]\n",
        "        trial_vectors_expanded = ben_x[indices].unsqueeze(0)\n",
        "\n",
        "        # Perform the mimic attack\n",
        "        pertbx = torch.clamp(malicious_samples_expanded + trial_vectors_expanded, min=0., max=1.)\n",
        "\n",
        "        # Compute the loss and check if adversarial examples are successful\n",
        "        loss, done = get_loss(pertbx.view(-1, pertbx.shape[-1]), torch.ones(n_samples * trials, 1, device=ben_x.device), model_DNN)\n",
        "\n",
        "        # Add maximum loss to successful attacks to differentiate\n",
        "        max_v = loss.max()\n",
        "        loss[done] += max_v\n",
        "\n",
        "        # Reshape the loss and done tensors\n",
        "        loss = loss.view(n_samples, trials)\n",
        "        done = done.view(n_samples, trials)\n",
        "\n",
        "        # Report attack effectiveness if required\n",
        "        if is_report_loss_diff:\n",
        "            n_done = torch.any(done, dim=-1).sum()\n",
        "            print(f\"Mimicry*{trials}: Attack effectiveness {n_done / n_samples * 100:.3f}%.\")\n",
        "\n",
        "        # Get the index of the maximum loss for each sample\n",
        "        _, indices = loss.max(dim=-1)\n",
        "        adv_x = pertbx[torch.arange(n_samples), indices]\n",
        "\n",
        "        del pertbx, loss, done, malicious_samples_expanded, trial_vectors_expanded\n",
        "\n",
        "        return adv_x\n",
        "    else:\n",
        "        print(\"No malicious samples found.\")\n",
        "        return None\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "iL-Dn7PrhtZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mimicry×30\n",
        "attack_params = {\"trials\":10, 'is_report_loss_diff':True}\n",
        "#adv_predict(test_loader, model_DNN, mimicry, device, **attack_params)\n",
        "adv_predict(test_loader, model_AT_rFGSM, mimicry, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d98baa4-a59b-4fe2-bdc9-f3df5653dfef",
        "id": "cGzkqvHCqD-P"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mimicry*10: Attack effectiveness 0.000%.\n",
            "Mimicry*10: Attack effectiveness 0.000%.\n",
            "Mimicry*10: Attack effectiveness 33.333%.\n",
            "Mimicry*10: Attack effectiveness 0.000%.\n",
            "Mimicry*10: Attack effectiveness 10.526%.\n",
            "Mimicry*10: Attack effectiveness 40.000%.\n",
            "Mimicry*10: Attack effectiveness 37.500%.\n",
            "Mimicry*10: Attack effectiveness 18.750%.\n",
            "Mimicry*10: Attack effectiveness 12.500%.\n",
            "Mimicry*10: Attack effectiveness 7.692%.\n",
            "Mimicry*10: Attack effectiveness 23.529%.\n",
            "Mimicry*10: Attack effectiveness 30.769%.\n",
            "Mimicry*10: Attack effectiveness 21.429%.\n",
            "Mimicry*10: Attack effectiveness 20.000%.\n",
            "Mimicry*10: Attack effectiveness 0.000%.\n",
            "Mimicry*10: Attack effectiveness 17.647%.\n",
            "Mimicry*10: Attack effectiveness 36.842%.\n",
            "Mimicry*10: Attack effectiveness 8.333%.\n",
            "Mimicry*10: Attack effectiveness 12.500%.\n",
            "Mimicry*10: Attack effectiveness 20.000%.\n",
            "Mimicry*10: Attack effectiveness 22.222%.\n",
            "Mimicry*10: Attack effectiveness 23.077%.\n",
            "Mimicry*10: Attack effectiveness 11.111%.\n",
            "Mimicry*10: Attack effectiveness 33.333%.\n",
            "Mimicry*10: Attack effectiveness 11.111%.\n",
            "Mimicry*10: Attack effectiveness 12.500%.\n",
            "Mimicry*10: Attack effectiveness 0.000%.\n",
            "Mimicry*10: Attack effectiveness 15.385%.\n",
            "Mimicry*10: Attack effectiveness 9.091%.\n",
            "Mimicry*10: Attack effectiveness 20.000%.\n",
            "Mimicry*10: Attack effectiveness 7.143%.\n",
            "Mimicry*10: Attack effectiveness 15.385%.\n",
            "Mimicry*10: Attack effectiveness 7.143%.\n",
            "Mimicry*10: Attack effectiveness 35.714%.\n",
            "Mimicry*10: Attack effectiveness 15.385%.\n",
            "Mimicry*10: Attack effectiveness 15.385%.\n",
            "Mimicry*10: Attack effectiveness 8.333%.\n",
            "Mimicry*10: Attack effectiveness 16.667%.\n",
            "Mimicry*10: Attack effectiveness 11.111%.\n",
            "Mimicry*10: Attack effectiveness 11.111%.\n",
            "Mimicry*10: Attack effectiveness 27.273%.\n",
            "Mimicry*10: Attack effectiveness 20.000%.\n",
            "Mimicry*10: Attack effectiveness 23.529%.\n",
            "Mimicry*10: Attack effectiveness 26.667%.\n",
            "Mimicry*10: Attack effectiveness 26.667%.\n",
            "Mimicry*10: Attack effectiveness 25.000%.\n",
            "Mimicry*10: Attack effectiveness 9.091%.\n",
            "Mimicry*10: Attack effectiveness 16.667%.\n",
            "Mimicry*10: Attack effectiveness 0.000%.\n",
            "Mimicry*10: Attack effectiveness 9.091%.\n",
            "Mimicry*10: Attack effectiveness 27.273%.\n",
            "Mimicry*10: Attack effectiveness 33.333%.\n",
            "Mimicry*10: Attack effectiveness 27.273%.\n",
            "Mimicry*10: Attack effectiveness 0.000%.\n",
            "Mimicry*10: Attack effectiveness 8.333%.\n",
            "Mimicry*10: Attack effectiveness 0.000%.\n",
            "Mimicry*10: Attack effectiveness 11.111%.\n",
            "Mimicry*10: Attack effectiveness 16.667%.\n",
            "Mimicry*10: Attack effectiveness 12.500%.\n",
            "Mimicry*10: Attack effectiveness 18.182%.\n",
            "Mimicry*10: Attack effectiveness 42.857%.\n",
            "Mimicry*10: Attack effectiveness 42.857%.\n",
            "Mimicry*10: Attack effectiveness 20.000%.\n",
            "Mimicry*10: Attack effectiveness 33.333%.\n",
            "Mimicry*10: Attack effectiveness 14.286%.\n",
            "Mimicry*10: Attack effectiveness 18.182%.\n",
            "Mimicry*10: Attack effectiveness 7.692%.\n",
            "Mimicry*10: Attack effectiveness 27.273%.\n",
            "Mimicry*10: Attack effectiveness 23.077%.\n",
            "Mimicry*10: Attack effectiveness 14.286%.\n",
            "Mimicry*10: Attack effectiveness 0.000%.\n",
            "Mimicry*10: Attack effectiveness 16.667%.\n",
            "Mimicry*10: Attack effectiveness 12.500%.\n",
            "Mimicry*10: Attack effectiveness 16.667%.\n",
            "Mimicry*10: Attack effectiveness 0.000%.\n",
            "Mimicry*10: Attack effectiveness 28.571%.\n",
            "Mimicry*10: Attack effectiveness 0.000%.\n",
            "Mimicry*10: Attack effectiveness 20.000%.\n",
            "Mimicry*10: Attack effectiveness 7.692%.\n",
            "Mimicry*10: Attack effectiveness 9.091%.\n",
            "Mimicry*10: Attack effectiveness 22.222%.\n",
            "Mimicry*10: Attack effectiveness 13.333%.\n",
            "Mimicry*10: Attack effectiveness 0.000%.\n",
            "Mimicry*10: Attack effectiveness 16.667%.\n",
            "Mimicry*10: Attack effectiveness 33.333%.\n",
            "Mimicry*10: Attack effectiveness 25.000%.\n",
            "Mimicry*10: Attack effectiveness 0.000%.\n",
            "Mimicry*10: Attack effectiveness 20.000%.\n",
            "Mimicry*10: Attack effectiveness 14.286%.\n",
            "Mimicry*10: Attack effectiveness 21.429%.\n",
            "Mimicry*10: Attack effectiveness 22.222%.\n",
            "Mimicry*10: Attack effectiveness 6.250%.\n",
            "Mimicry*10: Attack effectiveness 9.091%.\n",
            "Mimicry*10: Attack effectiveness 6.667%.\n",
            "Mimicry*10: Attack effectiveness 30.000%.\n",
            "Mimicry*10: Attack effectiveness 20.000%.\n",
            "Mimicry*10: Attack effectiveness 0.000%.\n",
            "Mimicry*10: Attack effectiveness 20.000%.\n",
            "Mimicry*10: Attack effectiveness 0.000%.\n",
            "Mimicry*10: Attack effectiveness 42.857%.\n",
            "Mimicry*10: Attack effectiveness 12.500%.\n",
            "Adversarial accuracy (without attack): 99.36% | Under attack: 83.35%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for x_test, y_test in test_loader:\n",
        "\n",
        "        # Generate adversarial examples for test set\n",
        "        mal_x_batch, mal_y_batch = x_test[y_test.squeeze() == 1], y_test[y_test.squeeze() == 1]\n",
        "\n",
        "        pertb_mal_x = mimicry(ben_x, mal_x_batch, model_AT_rFGSM, trials=30, seed=230, is_report_loss_diff=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kpl1HyDQnzjf",
        "outputId": "8d3922c9-e1e4-42db-f382-582af9f79e31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mimicry*30: Attack effectiveness 0.000%.\n",
            "Mimicry*30: Attack effectiveness 0.000%.\n",
            "Mimicry*30: Attack effectiveness 33.333%.\n",
            "Mimicry*30: Attack effectiveness 0.000%.\n",
            "Mimicry*30: Attack effectiveness 10.526%.\n",
            "Mimicry*30: Attack effectiveness 40.000%.\n",
            "Mimicry*30: Attack effectiveness 37.500%.\n",
            "Mimicry*30: Attack effectiveness 18.750%.\n",
            "Mimicry*30: Attack effectiveness 12.500%.\n",
            "Mimicry*30: Attack effectiveness 7.692%.\n",
            "Mimicry*30: Attack effectiveness 23.529%.\n",
            "Mimicry*30: Attack effectiveness 30.769%.\n",
            "Mimicry*30: Attack effectiveness 21.429%.\n",
            "Mimicry*30: Attack effectiveness 20.000%.\n",
            "Mimicry*30: Attack effectiveness 0.000%.\n",
            "Mimicry*30: Attack effectiveness 17.647%.\n",
            "Mimicry*30: Attack effectiveness 36.842%.\n",
            "Mimicry*30: Attack effectiveness 8.333%.\n",
            "Mimicry*30: Attack effectiveness 12.500%.\n",
            "Mimicry*30: Attack effectiveness 20.000%.\n",
            "Mimicry*30: Attack effectiveness 22.222%.\n",
            "Mimicry*30: Attack effectiveness 23.077%.\n",
            "Mimicry*30: Attack effectiveness 11.111%.\n",
            "Mimicry*30: Attack effectiveness 33.333%.\n",
            "Mimicry*30: Attack effectiveness 11.111%.\n",
            "Mimicry*30: Attack effectiveness 12.500%.\n",
            "Mimicry*30: Attack effectiveness 0.000%.\n",
            "Mimicry*30: Attack effectiveness 15.385%.\n",
            "Mimicry*30: Attack effectiveness 9.091%.\n",
            "Mimicry*30: Attack effectiveness 20.000%.\n",
            "Mimicry*30: Attack effectiveness 7.143%.\n",
            "Mimicry*30: Attack effectiveness 15.385%.\n",
            "Mimicry*30: Attack effectiveness 7.143%.\n",
            "Mimicry*30: Attack effectiveness 35.714%.\n",
            "Mimicry*30: Attack effectiveness 15.385%.\n",
            "Mimicry*30: Attack effectiveness 15.385%.\n",
            "Mimicry*30: Attack effectiveness 8.333%.\n",
            "Mimicry*30: Attack effectiveness 16.667%.\n",
            "Mimicry*30: Attack effectiveness 11.111%.\n",
            "Mimicry*30: Attack effectiveness 11.111%.\n",
            "Mimicry*30: Attack effectiveness 27.273%.\n",
            "Mimicry*30: Attack effectiveness 20.000%.\n",
            "Mimicry*30: Attack effectiveness 23.529%.\n",
            "Mimicry*30: Attack effectiveness 26.667%.\n",
            "Mimicry*30: Attack effectiveness 26.667%.\n",
            "Mimicry*30: Attack effectiveness 25.000%.\n",
            "Mimicry*30: Attack effectiveness 9.091%.\n",
            "Mimicry*30: Attack effectiveness 16.667%.\n",
            "Mimicry*30: Attack effectiveness 0.000%.\n",
            "Mimicry*30: Attack effectiveness 9.091%.\n",
            "Mimicry*30: Attack effectiveness 27.273%.\n",
            "Mimicry*30: Attack effectiveness 33.333%.\n",
            "Mimicry*30: Attack effectiveness 27.273%.\n",
            "Mimicry*30: Attack effectiveness 0.000%.\n",
            "Mimicry*30: Attack effectiveness 8.333%.\n",
            "Mimicry*30: Attack effectiveness 0.000%.\n",
            "Mimicry*30: Attack effectiveness 11.111%.\n",
            "Mimicry*30: Attack effectiveness 16.667%.\n",
            "Mimicry*30: Attack effectiveness 12.500%.\n",
            "Mimicry*30: Attack effectiveness 18.182%.\n",
            "Mimicry*30: Attack effectiveness 42.857%.\n",
            "Mimicry*30: Attack effectiveness 42.857%.\n",
            "Mimicry*30: Attack effectiveness 20.000%.\n",
            "Mimicry*30: Attack effectiveness 33.333%.\n",
            "Mimicry*30: Attack effectiveness 14.286%.\n",
            "Mimicry*30: Attack effectiveness 18.182%.\n",
            "Mimicry*30: Attack effectiveness 7.692%.\n",
            "Mimicry*30: Attack effectiveness 27.273%.\n",
            "Mimicry*30: Attack effectiveness 23.077%.\n",
            "Mimicry*30: Attack effectiveness 14.286%.\n",
            "Mimicry*30: Attack effectiveness 0.000%.\n",
            "Mimicry*30: Attack effectiveness 16.667%.\n",
            "Mimicry*30: Attack effectiveness 12.500%.\n",
            "Mimicry*30: Attack effectiveness 16.667%.\n",
            "Mimicry*30: Attack effectiveness 0.000%.\n",
            "Mimicry*30: Attack effectiveness 28.571%.\n",
            "Mimicry*30: Attack effectiveness 0.000%.\n",
            "Mimicry*30: Attack effectiveness 20.000%.\n",
            "Mimicry*30: Attack effectiveness 7.692%.\n",
            "Mimicry*30: Attack effectiveness 9.091%.\n",
            "Mimicry*30: Attack effectiveness 22.222%.\n",
            "Mimicry*30: Attack effectiveness 13.333%.\n",
            "Mimicry*30: Attack effectiveness 0.000%.\n",
            "Mimicry*30: Attack effectiveness 16.667%.\n",
            "Mimicry*30: Attack effectiveness 33.333%.\n",
            "Mimicry*30: Attack effectiveness 25.000%.\n",
            "Mimicry*30: Attack effectiveness 0.000%.\n",
            "Mimicry*30: Attack effectiveness 20.000%.\n",
            "Mimicry*30: Attack effectiveness 14.286%.\n",
            "Mimicry*30: Attack effectiveness 21.429%.\n",
            "Mimicry*30: Attack effectiveness 22.222%.\n",
            "Mimicry*30: Attack effectiveness 6.250%.\n",
            "Mimicry*30: Attack effectiveness 9.091%.\n",
            "Mimicry*30: Attack effectiveness 6.667%.\n",
            "Mimicry*30: Attack effectiveness 30.000%.\n",
            "Mimicry*30: Attack effectiveness 20.000%.\n",
            "Mimicry*30: Attack effectiveness 0.000%.\n",
            "Mimicry*30: Attack effectiveness 20.000%.\n",
            "Mimicry*30: Attack effectiveness 0.000%.\n",
            "Mimicry*30: Attack effectiveness 42.857%.\n",
            "Mimicry*30: Attack effectiveness 12.500%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trials = 30\n",
        "seed = 230\n",
        "is_report_loss_diff = True\n",
        "\n",
        "model_DNN.eval()\n",
        "\n",
        "# Ensure trials do not exceed the length of ben_x\n",
        "trials = min(trials, len(ben_x))\n",
        "\n",
        "# Get the number of malicious samples\n",
        "n_samples = len(malicious_samples)\n",
        "\n",
        "if n_samples > 0:\n",
        "    # Expand dimensions for efficient broadcasting\n",
        "    malicious_samples_expanded = malicious_samples.unsqueeze(1).expand(-1, trials, -1)\n",
        "\n",
        "    # Generate random indices for sampling from ben_x\n",
        "    seed += 1\n",
        "    torch.manual_seed(seed)\n",
        "    indices = torch.randperm(len(ben_x), device=device)[:trials]\n",
        "    trial_vectors_expanded = ben_x[indices].unsqueeze(0)\n",
        "\n",
        "    # Perform the mimic attack\n",
        "    pertbx = torch.clamp(malicious_samples_expanded + trial_vectors_expanded, min=0., max=1.)\n",
        "\n",
        "    # Compute the loss and check if adversarial examples are successful\n",
        "    loss, done = get_loss(pertbx.view(-1, pertbx.shape[-1]), torch.ones(n_samples * trials, 1, device=device), model_DNN)\n",
        "    print(done)\n",
        "    # Add maximum loss to successful attacks to differentiate\n",
        "    max_v = loss.max()\n",
        "    loss[done] += max_v\n",
        "\n",
        "    # Reshape the loss and done tensors\n",
        "    loss = loss.view(n_samples, trials)\n",
        "    done = done.view(n_samples, trials)\n",
        "\n",
        "    # Report attack effectiveness if required\n",
        "    if is_report_loss_diff:\n",
        "        n_done = torch.any(done, dim=-1).sum()\n",
        "        print(n_done)\n",
        "        print(f\"Mimicry*{trials}: Attack effectiveness {n_done / n_samples * 100:.3f}%.\")\n",
        "\n",
        "    # Get the index of the maximum loss for each sample\n",
        "    _, indices = loss.max(dim=-1)\n",
        "    adv_x = pertbx[torch.arange(n_samples), indices]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bIilgMw1cWuE",
        "outputId": "9a454514-da5b-4e0f-c409-c0e430a79410"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([False, False, False, False, False, False, False, False, False, False,\n",
            "         True,  True, False, False, False,  True, False, False, False, False,\n",
            "         True, False, False, False, False, False, False,  True, False, False,\n",
            "         True, False, False,  True,  True, False,  True, False, False, False,\n",
            "         True,  True, False,  True, False,  True, False, False,  True, False,\n",
            "         True, False,  True,  True, False, False,  True,  True, False,  True,\n",
            "        False, False, False, False,  True, False, False, False, False, False,\n",
            "         True,  True, False, False, False,  True, False, False, False, False,\n",
            "         True, False, False, False, False, False, False,  True, False, False,\n",
            "        False, False, False,  True,  True, False,  True, False, False,  True,\n",
            "         True,  True, False,  True, False,  True, False, False,  True, False,\n",
            "         True, False,  True,  True, False, False, False,  True, False, False,\n",
            "        False, False, False, False, False, False, False, False, False, False,\n",
            "        False,  True, False, False, False, False, False, False, False, False,\n",
            "        False, False, False, False, False, False, False,  True, False, False,\n",
            "        False, False, False, False,  True, False, False, False, False, False,\n",
            "         True,  True, False, False, False,  True, False, False,  True, False,\n",
            "         True, False, False, False, False, False, False,  True, False, False,\n",
            "        False, False, False, False, False, False, False, False, False, False,\n",
            "         True,  True, False, False, False,  True, False, False, False, False,\n",
            "         True, False, False, False, False, False, False,  True, False, False,\n",
            "        False, False, False, False,  True, False, False, False, False, False,\n",
            "         True,  True, False, False, False,  True, False, False,  True, False,\n",
            "         True, False, False, False, False, False, False,  True, False, False,\n",
            "        False, False, False, False, False, False, False, False, False, False,\n",
            "        False, False, False, False, False, False, False, False, False, False,\n",
            "        False, False, False, False, False, False, False, False, False, False,\n",
            "        False, False, False, False, False, False, False, False, False, False,\n",
            "        False,  True, False, False, False, False, False, False, False, False,\n",
            "        False, False, False, False, False, False, False,  True, False, False,\n",
            "        False, False, False, False,  True, False, False, False, False, False,\n",
            "         True,  True, False, False, False,  True, False, False,  True, False,\n",
            "         True, False, False, False, False, False, False,  True, False, False,\n",
            "        False, False, False, False,  True, False, False, False, False, False,\n",
            "         True,  True, False, False, False,  True, False, False,  True, False,\n",
            "         True, False, False, False, False, False, False,  True, False, False])\n",
            "tensor(11)\n",
            "Mimicry*30: Attack effectiveness 91.667%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adv_x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7QK3DYDlkag",
        "outputId": "6aa17073-9d33-4c1b-c745-50894efc612e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([12, 10000])"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage:\n",
        "trials = 30\n",
        "seed = 230\n",
        "is_report_loss_diff = True\n",
        "\n",
        "adv_x = mimicry(ben_x, malicious_samples, model_DNN, trials, seed, is_report_loss_diff, device=\"cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbuPZffKiWkP",
        "outputId": "1967238c-7a55-4394-9020-6de24138b670"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mimicry*30: Attack effectiveness 91.667%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model_AT_rFGSM(adv_x)\n",
        "_, y_pred = torch.topk(outputs, k=1)\n",
        "\n",
        "acc_ad_test = (y_pred == 1.).sum().item() / len(y_pred)\n",
        "acc_ad_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgLF4XbClzmr",
        "outputId": "fa53553c-d55e-41f6-b303-1e9170648e61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def mimicry(ben_x, malicious_samples, model, seed, trials=1000, device=\"cpu\"):\n",
        "\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  # Initialize counters\n",
        "  successful_attacks = 0\n",
        "  total_malicious_samples = 0\n",
        "\n",
        "  trials = min(trials, len(ben_x))\n",
        "\n",
        "\n",
        "  if len(malicious_samples) > 0:\n",
        "\n",
        "    # Generate random indices outside the loop\n",
        "    seed += 1\n",
        "    torch.manual_seed(seed)\n",
        "    indices = torch.randperm(len(ben_x), device=device)[:trials]\n",
        "    trial_vectors = ben_x[indices]\n",
        "\n",
        "    # Perform the mimic attack and update counters\n",
        "    modified_x = torch.clamp(malicious_samples + trial_vectors, min=0., max=1.)\n",
        "    _, done = get_loss(modified_x.view(-1, modified_x.shape[-1]), torch.ones(trials * malicious_samples.shape[0], 1, device=device), model)\n",
        "    successful_attacks += (done.view(malicious_samples.shape[0], trials).sum(dim=1) > 0).sum().item()\n",
        "    total_malicious_samples += malicious_samples.shape[0]\n",
        "\n",
        "  # Calculate and print attack effectiveness\n",
        "  attack_effectiveness = (successful_attacks / total_malicious_samples) * 100 if total_malicious_samples > 0 else 0\n",
        "  print(f\"Mimic attack effectiveness: {attack_effectiveness:.3f}%.\")\n",
        "\n",
        "  return attack_effectiveness  # Added return statement for clarity\n"
      ],
      "metadata": {
        "id": "ycRVXx-1YwjL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mimic_attack_effectiveness_optimized(test_loader, model, seed, trials=1000, device=\"cuda:0\"):\n",
        "  \"\"\"\n",
        "  Calculates the effectiveness of the mimic attack on the given model.\n",
        "\n",
        "  Args:\n",
        "      test_loader: A PyTorch dataloader containing the test data.\n",
        "      model: The PyTorch model to be attacked.\n",
        "      seed: The random seed for reproducibility.\n",
        "      trials: The number of random samples to use from the benign class (default: 1000).\n",
        "      device: The device to use for computations (default: \"cuda:0\" if available, otherwise \"cpu\").\n",
        "\n",
        "  Returns:\n",
        "      The effectiveness of the mimic attack as a percentage (float).\n",
        "  \"\"\"\n",
        "\n",
        "  torch.manual_seed(seed)\n",
        "  model.eval()\n",
        "\n",
        "  # Initialize counters\n",
        "  successful_attacks = 0\n",
        "  total_malicious_samples = 0\n",
        "\n",
        "  # Pre-select benign samples for efficiency\n",
        "  benign_samples = []\n",
        "  for x_batch, y_batch in test_loader:\n",
        "    benign_samples.append(x_batch[y_batch.squeeze() == 0])\n",
        "\n",
        "  ben_x = torch.cat(benign_samples, dim=0).to(device)\n",
        "\n",
        "  # Clear unnecessary variables\n",
        "  del benign_samples\n",
        "\n",
        "  trials = min(trials, len(ben_x))\n",
        "\n",
        "\n",
        "  for x_batch, y_batch in test_loader:\n",
        "    x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
        "    malicious_samples = x_batch[y_batch.squeeze() == 1]\n",
        "\n",
        "    if len(malicious_samples) > 0:\n",
        "      # Expand dimensions for efficient broadcasting\n",
        "      malicious_samples_expanded = malicious_samples.unsqueeze(1).expand(-1, trials, -1)\n",
        "\n",
        "      # Generate random indices outside the loop\n",
        "      seed += 1\n",
        "      torch.manual_seed(seed)\n",
        "      indices = torch.randperm(len(ben_x), device=device)[:trials]\n",
        "      trial_vectors_expanded = ben_x[indices].unsqueeze(0)\n",
        "\n",
        "      # Perform the mimic attack and update counters\n",
        "      modified_x = torch.clamp(malicious_samples_expanded + trial_vectors_expanded, min=0., max=1.)\n",
        "      _, done = get_loss(modified_x.view(-1, modified_x.shape[-1]), torch.ones(trials * malicious_samples.shape[0], 1, device=device), model)\n",
        "      successful_attacks += (done.view(malicious_samples.shape[0], trials).sum(dim=1) > 0).sum().item()\n",
        "      total_malicious_samples += malicious_samples.shape[0]\n",
        "      break\n",
        "  # Calculate and print attack effectiveness\n",
        "  attack_effectiveness = (successful_attacks / total_malicious_samples) * 100 if total_malicious_samples > 0 else 0\n",
        "  print(f\"Mimic attack effectiveness: {attack_effectiveness:.3f}%.\")\n",
        "\n",
        "  return attack_effectiveness  # Added return statement for clarity\n"
      ],
      "metadata": {
        "id": "NpnhzTu07Aep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mimic_attack_effectiveness_optimized(test_loader, model_DNN , seed=230, trials=100, device=device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iemV-2EK6wng",
        "outputId": "70f11528-5e96-447d-93ec-979c22740b25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mimic attack effectiveness: 91.667%.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "91.66666666666666"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    }
  ]
}