{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mostafa-ja/mal_adv3/blob/main/malware_cnn3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming binary_vector is your 1D binary vector of length 10000\n",
        "binary_vector = np.random.randint(2, size=9800)\n",
        "\n",
        "# Reshape the vector into a 2D array with each element being an 8-length binary vector\n",
        "image = np.reshape(binary_vector, (35, 35, 8))\n",
        "\n",
        "# Convert binary values to gray-scale intensities\n",
        "gray_image = np.packbits(image, axis=-1)\n",
        "\n",
        "# Display the gray-scale image\n",
        "plt.imshow(gray_image, cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "4ZG8enqYt5ga",
        "outputId": "fec63f08-b513-47c9-fecb-76b8a3047f1e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZfX_N-gQHKp",
        "outputId": "82611be1-04e2-4fc0-81a7-f2aef76011c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv3/raw/main/data/X_redefined_sparse_matrix.npz\n",
            "To: /content/X_redefined_sparse_matrix.npz\n",
            "100%|██████████| 2.31M/2.31M [00:00<00:00, 14.4MB/s]\n",
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv3/raw/main/data/labels.pt\n",
            "To: /content/labels.pt\n",
            "100%|██████████| 517k/517k [00:00<00:00, 8.03MB/s]\n"
          ]
        }
      ],
      "source": [
        "download_links = ['https://github.com/mostafa-ja/mal_adv3/raw/main/data/X_redefined_sparse_matrix.npz',\n",
        "                  'https://github.com/mostafa-ja/mal_adv3/raw/main/data/labels.pt'\n",
        "]\n",
        "\n",
        "\n",
        "import gdown\n",
        "output_filepath = '/content/'\n",
        "for link in download_links:\n",
        "  gdown.download(link, output_filepath)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy import sparse\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "import time\n",
        "\n",
        "\n",
        "torch.manual_seed(0)\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usjRDnBCQK9l",
        "outputId": "c4ad5bde-1bfe-481b-b652-a5b471e0a174"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "X_redefined = sparse.load_npz(\"X_redefined_sparse_matrix.npz\")\n",
        "labels_tensor = torch.load('labels.pt')\n",
        "\n",
        "# Split data into train, validation, and test sets with stratified sampling\n",
        "X_train_val, X_test, labels_train_val, labels_test = train_test_split(X_redefined, labels_tensor, test_size=0.2, stratify=labels_tensor, random_state=42)\n",
        "X_train, X_val, labels_train, labels_val = train_test_split(X_train_val, labels_train_val, test_size=0.2, stratify=labels_train_val, random_state=42)\n",
        "\n",
        "# Combine features and labels into datasets\n",
        "# we use dtype=torch.int8, for Memory-Efficient here, later we will convert to float\n",
        "train_dataset = TensorDataset(torch.tensor(X_train.toarray(), dtype=torch.int8), labels_train)\n",
        "val_dataset = TensorDataset(torch.tensor(X_val.toarray(), dtype=torch.int8), labels_val)\n",
        "test_dataset = TensorDataset(torch.tensor(X_test.toarray(), dtype=torch.int8), labels_test)\n",
        "\n",
        "# Clear unnecessary variables\n",
        "del X_redefined, labels_tensor, X_train_val, X_test, labels_train_val, labels_test, X_train, X_val, labels_train, labels_val"
      ],
      "metadata": {
        "id": "OlfUNSCJQQiN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the DataLoader for training, validation, and test sets\n",
        "batch_size = 256\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "_DeOfARzQRc6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pad_binary_vector(binary_vector, new_size):\n",
        "    batch_size, vector_length = binary_vector.size()\n",
        "\n",
        "    # Calculate the number of zeros to add\n",
        "    num_zeros = new_size - vector_length\n",
        "\n",
        "    # Create a tensor filled with zeros\n",
        "    zeros_tensor = torch.zeros(batch_size, num_zeros, dtype=torch.int)\n",
        "\n",
        "    # Concatenate the binary vector with the zeros tensor along the second dimension\n",
        "    padded_binary_vector = torch.cat([binary_vector, zeros_tensor], dim=1)\n",
        "\n",
        "    return padded_binary_vector"
      ],
      "metadata": {
        "id": "U57qM9nEH6ki"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def batch_binary_vectors_to_gray_images(binary_vectors, image_size=36):\n",
        "    \"\"\"\n",
        "    Convert a batch of binary vectors to gray-scale images.\n",
        "\n",
        "    Parameters:\n",
        "        batch_binary_vectors (numpy.ndarray): Batch of binary vectors with shape (batch_size, vector_length).\n",
        "        image_size (int): Size of the square image (default is 36).\n",
        "\n",
        "    Returns:\n",
        "        gray_images: Batch of gray-scale images with shape (batch_size, image_size, image_size).\n",
        "    \"\"\"\n",
        "    batch_binary_vectors = pad_binary_vector(binary_vectors, 10368)\n",
        "\n",
        "    # Reshape each binary vector in the batch into a 2D array with each element being an 8-length binary vector\n",
        "    batch_images = np.reshape(batch_binary_vectors, (-1, image_size, image_size, 8))\n",
        "\n",
        "    # Convert binary values to gray-scale intensities\n",
        "    gray_images = np.packbits(batch_images, axis=-1)\n",
        "\n",
        "    # Remove the last dimension (single channel) from the gray_images array\n",
        "    gray_images = np.squeeze(gray_images, axis=-1)\n",
        "\n",
        "    return gray_images\n"
      ],
      "metadata": {
        "id": "yo0LOBhSIDd2"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for X,Y in train_loader:\n",
        "  print(X.shape)\n",
        "  print(Y.shape)\n",
        "  break\n",
        "\n",
        "m = batch_binary_vectors_to_gray_images(X, image_size=36)\n",
        "print(m.shape)\n",
        "\n",
        "plt.imshow(m[2], cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "ev4l8hNVIMPA",
        "outputId": "403bf7ac-0cd1-456f-f99e-b985c2179d35"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([256, 10000])\n",
            "torch.Size([256, 1])\n",
            "(256, 36, 36)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.zeros(256, 10368, dtype=torch.int)\n",
        "a[:,:10000] =  X\n",
        "\n",
        "m = batch_binary_vectors_to_gray_images(a, image_size=36)\n",
        "print(m.shape)\n",
        "\n",
        "plt.imshow(m[2], cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "NvbXIKk5I4_7",
        "outputId": "a9d2ff5f-0d69-4f4a-a19c-2934f06b9e79"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(256, 36, 36)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class MalwareDetectorCNN(nn.Module):\n",
        "    def __init__(self, in_channels=1, num_classes=1):\n",
        "        super(MalwareDetectorCNN, self).__init__()\n",
        "        # Convolutional layers with ReLU activation\n",
        "        self.conv1 = nn.Conv2d(in_channels, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "\n",
        "        # Max pooling layers\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # Dropout layer for regularization\n",
        "        self.dropout = nn.Dropout(p=0.2)  # Adjust dropout rate as needed\n",
        "\n",
        "        # Flatten layer\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        # Fully connected layers with ReLU activation\n",
        "        self.fc1 = nn.Linear(2048, 256)  # Input size based on conv layers\n",
        "        self.fc2 = nn.Linear(256, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.unsqueeze(1)\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = self.dropout(x)\n",
        "        x = self.pool(F.relu(self.conv3(x)))\n",
        "        x = self.flatten(x)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)  # Consider adding dropout after fc1 as well\n",
        "        x = torch.sigmoid(self.fc2(x))  # Sigmoid for binary classification (malware or benign)\n",
        "        return x"
      ],
      "metadata": {
        "id": "UlRyfSbTih8E"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor(m)\n",
        "a.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13TqNpBEjY2-",
        "outputId": "159fdbde-3253-4912-9060-3dff07b5ee6d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([256, 36, 36])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "model = MalwareDetectorCNN()\n",
        "\n",
        "model(a/255.)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhsNJxZfixpP",
        "outputId": "8ae652ac-1ae7-4701-d2ab-edf5825d93b4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.5008],\n",
              "        [0.4982],\n",
              "        [0.4989],\n",
              "        [0.4975],\n",
              "        [0.4977],\n",
              "        [0.4987],\n",
              "        [0.4963],\n",
              "        [0.4979],\n",
              "        [0.4969],\n",
              "        [0.4965],\n",
              "        [0.4991],\n",
              "        [0.4985],\n",
              "        [0.4982],\n",
              "        [0.5001],\n",
              "        [0.4968],\n",
              "        [0.4993],\n",
              "        [0.4997],\n",
              "        [0.4991],\n",
              "        [0.4977],\n",
              "        [0.4983],\n",
              "        [0.4990],\n",
              "        [0.4980],\n",
              "        [0.4990],\n",
              "        [0.4987],\n",
              "        [0.4994],\n",
              "        [0.4967],\n",
              "        [0.4967],\n",
              "        [0.4987],\n",
              "        [0.4996],\n",
              "        [0.4986],\n",
              "        [0.4997],\n",
              "        [0.4970],\n",
              "        [0.4975],\n",
              "        [0.5000],\n",
              "        [0.4972],\n",
              "        [0.5001],\n",
              "        [0.4960],\n",
              "        [0.4964],\n",
              "        [0.5002],\n",
              "        [0.4970],\n",
              "        [0.4966],\n",
              "        [0.4993],\n",
              "        [0.4993],\n",
              "        [0.4988],\n",
              "        [0.4980],\n",
              "        [0.4977],\n",
              "        [0.4958],\n",
              "        [0.4992],\n",
              "        [0.4971],\n",
              "        [0.4998],\n",
              "        [0.4985],\n",
              "        [0.4988],\n",
              "        [0.4969],\n",
              "        [0.4998],\n",
              "        [0.4979],\n",
              "        [0.4983],\n",
              "        [0.4987],\n",
              "        [0.4973],\n",
              "        [0.4968],\n",
              "        [0.4959],\n",
              "        [0.4983],\n",
              "        [0.4956],\n",
              "        [0.4987],\n",
              "        [0.4991],\n",
              "        [0.4990],\n",
              "        [0.4975],\n",
              "        [0.4988],\n",
              "        [0.4959],\n",
              "        [0.4977],\n",
              "        [0.4972],\n",
              "        [0.4972],\n",
              "        [0.4965],\n",
              "        [0.4991],\n",
              "        [0.5003],\n",
              "        [0.4974],\n",
              "        [0.4970],\n",
              "        [0.4991],\n",
              "        [0.4991],\n",
              "        [0.4968],\n",
              "        [0.4970],\n",
              "        [0.4972],\n",
              "        [0.5012],\n",
              "        [0.4981],\n",
              "        [0.5016],\n",
              "        [0.4972],\n",
              "        [0.4987],\n",
              "        [0.4963],\n",
              "        [0.4979],\n",
              "        [0.4983],\n",
              "        [0.4979],\n",
              "        [0.4998],\n",
              "        [0.4966],\n",
              "        [0.4957],\n",
              "        [0.4972],\n",
              "        [0.4984],\n",
              "        [0.4979],\n",
              "        [0.4978],\n",
              "        [0.4973],\n",
              "        [0.4983],\n",
              "        [0.4975],\n",
              "        [0.4978],\n",
              "        [0.4979],\n",
              "        [0.4977],\n",
              "        [0.4975],\n",
              "        [0.4988],\n",
              "        [0.4973],\n",
              "        [0.4982],\n",
              "        [0.4989],\n",
              "        [0.4975],\n",
              "        [0.4960],\n",
              "        [0.4986],\n",
              "        [0.4973],\n",
              "        [0.4992],\n",
              "        [0.4963],\n",
              "        [0.4972],\n",
              "        [0.4965],\n",
              "        [0.4984],\n",
              "        [0.4993],\n",
              "        [0.4983],\n",
              "        [0.4972],\n",
              "        [0.4993],\n",
              "        [0.4977],\n",
              "        [0.4971],\n",
              "        [0.4999],\n",
              "        [0.4978],\n",
              "        [0.4993],\n",
              "        [0.4987],\n",
              "        [0.4978],\n",
              "        [0.4993],\n",
              "        [0.5007],\n",
              "        [0.4978],\n",
              "        [0.4978],\n",
              "        [0.4994],\n",
              "        [0.4990],\n",
              "        [0.4991],\n",
              "        [0.4972],\n",
              "        [0.4990],\n",
              "        [0.4982],\n",
              "        [0.4988],\n",
              "        [0.4965],\n",
              "        [0.4987],\n",
              "        [0.5000],\n",
              "        [0.4975],\n",
              "        [0.4983],\n",
              "        [0.4992],\n",
              "        [0.4986],\n",
              "        [0.4943],\n",
              "        [0.4971],\n",
              "        [0.4966],\n",
              "        [0.4977],\n",
              "        [0.4995],\n",
              "        [0.5004],\n",
              "        [0.4971],\n",
              "        [0.4976],\n",
              "        [0.4980],\n",
              "        [0.4969],\n",
              "        [0.4965],\n",
              "        [0.5000],\n",
              "        [0.5005],\n",
              "        [0.4976],\n",
              "        [0.4990],\n",
              "        [0.4967],\n",
              "        [0.5001],\n",
              "        [0.4982],\n",
              "        [0.4982],\n",
              "        [0.5001],\n",
              "        [0.4997],\n",
              "        [0.4989],\n",
              "        [0.4989],\n",
              "        [0.4971],\n",
              "        [0.4958],\n",
              "        [0.5002],\n",
              "        [0.4980],\n",
              "        [0.4930],\n",
              "        [0.4979],\n",
              "        [0.4959],\n",
              "        [0.4998],\n",
              "        [0.4976],\n",
              "        [0.4993],\n",
              "        [0.4985],\n",
              "        [0.4957],\n",
              "        [0.4969],\n",
              "        [0.5013],\n",
              "        [0.4953],\n",
              "        [0.4991],\n",
              "        [0.4968],\n",
              "        [0.4980],\n",
              "        [0.4993],\n",
              "        [0.4988],\n",
              "        [0.5004],\n",
              "        [0.4970],\n",
              "        [0.4974],\n",
              "        [0.5016],\n",
              "        [0.4992],\n",
              "        [0.4968],\n",
              "        [0.4988],\n",
              "        [0.4995],\n",
              "        [0.4988],\n",
              "        [0.4986],\n",
              "        [0.4975],\n",
              "        [0.4991],\n",
              "        [0.4983],\n",
              "        [0.5001],\n",
              "        [0.4982],\n",
              "        [0.4966],\n",
              "        [0.4979],\n",
              "        [0.4982],\n",
              "        [0.4987],\n",
              "        [0.4995],\n",
              "        [0.4993],\n",
              "        [0.4985],\n",
              "        [0.4984],\n",
              "        [0.4971],\n",
              "        [0.4978],\n",
              "        [0.4985],\n",
              "        [0.4974],\n",
              "        [0.5006],\n",
              "        [0.4972],\n",
              "        [0.4980],\n",
              "        [0.4987],\n",
              "        [0.4979],\n",
              "        [0.4996],\n",
              "        [0.4989],\n",
              "        [0.4995],\n",
              "        [0.4976],\n",
              "        [0.4977],\n",
              "        [0.5022],\n",
              "        [0.4995],\n",
              "        [0.4990],\n",
              "        [0.4995],\n",
              "        [0.4993],\n",
              "        [0.4977],\n",
              "        [0.4988],\n",
              "        [0.4976],\n",
              "        [0.4979],\n",
              "        [0.4990],\n",
              "        [0.5013],\n",
              "        [0.4992],\n",
              "        [0.4972],\n",
              "        [0.4985],\n",
              "        [0.4998],\n",
              "        [0.5001],\n",
              "        [0.4978],\n",
              "        [0.5006],\n",
              "        [0.5015],\n",
              "        [0.4980],\n",
              "        [0.4976],\n",
              "        [0.4994],\n",
              "        [0.4955],\n",
              "        [0.4970],\n",
              "        [0.4983],\n",
              "        [0.4975],\n",
              "        [0.4986],\n",
              "        [0.4986],\n",
              "        [0.4977],\n",
              "        [0.4984]], grad_fn=<SigmoidBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "aa - as"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "iYich0jGQuTb",
        "outputId": "0e6634a7-75f9-4db3-ee4f-082275058fdb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-13-b3e4d17bf9c9>, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-13-b3e4d17bf9c9>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    aa - as\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim.lr_scheduler import LambdaLR\n",
        "\n",
        "# Define a learning rate warm-up and decay function\n",
        "def lr_lambda(epoch):\n",
        "    if epoch < warmup_epochs:\n",
        "        return float(epoch+1) / float(max(1, warmup_epochs))\n",
        "    else:\n",
        "        return lr_decay ** (epoch - warmup_epochs)\n",
        "\n",
        "# Define warm-up epochs, learning rate decay factor, and other hyperparameters\n",
        "warmup_epochs = 5\n",
        "lr_decay = 0.97\n",
        "initial_lr = 0.001\n",
        "\n",
        "# Create an instance of the model and move it to the GPU\n",
        "# model = MalwareDetectorCNN().to(device)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=initial_lr)\n",
        "\n",
        "# Create a learning rate scheduler\n",
        "scheduler = LambdaLR(optimizer, lr_lambda=lr_lambda)\n",
        "\n",
        "# Initialize variables to track best F1 score and corresponding model state\n",
        "best_f1_score = 0.0\n",
        "best_model_state = None\n",
        "\n",
        "# Train the model\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct_train = 0\n",
        "    total_train = 0\n",
        "    print(optimizer.param_groups[0]['lr'])\n",
        "\n",
        "    # Step the learning rate scheduler\n",
        "    scheduler.step()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpHsJYhMQqlC",
        "outputId": "b9648777-c371-42da-9d08-2e0b682e614f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0002\n",
            "0.0004\n",
            "0.0006\n",
            "0.0008\n",
            "0.001\n",
            "0.001\n",
            "0.0009699999999999999\n",
            "0.0009408999999999999\n",
            "0.000912673\n",
            "0.00088529281\n",
            "0.0008587340257\n",
            "0.0008329720049289998\n",
            "0.0008079828447811299\n",
            "0.0007837433594376959\n",
            "0.0007602310586545651\n",
            "0.0007374241268949281\n",
            "0.0007153014030880803\n",
            "0.0006938423609954377\n",
            "0.0006730270901655746\n",
            "0.0006528362774606074\n",
            "0.0006332511891367892\n",
            "0.0006142536534626855\n",
            "0.0005958260438588049\n",
            "0.0005779512625430407\n",
            "0.0005606127246667495\n",
            "0.000543794342926747\n",
            "0.0005274805126389446\n",
            "0.0005116560972597763\n",
            "0.0004963064143419829\n",
            "0.00048141722191172336\n",
            "0.0004669747052543717\n",
            "0.0004529654640967405\n",
            "0.0004393765001738383\n",
            "0.0004261952051686231\n",
            "0.0004134093490135644\n",
            "0.00040100706854315747\n",
            "0.00038897685648686274\n",
            "0.00037730755079225687\n",
            "0.00036598832426848916\n",
            "0.00035500867454043444\n",
            "0.0003443584143042214\n",
            "0.00033402766187509475\n",
            "0.0003240068320188419\n",
            "0.00031428662705827666\n",
            "0.0003048580282465283\n",
            "0.0002957122873991325\n",
            "0.00028684091877715853\n",
            "0.00027823569121384375\n",
            "0.0002698886204774284\n",
            "0.00026179196186310554\n",
            "0.0002539382030072124\n",
            "0.000246320056916996\n",
            "0.00023893045520948612\n",
            "0.00023176254155320153\n",
            "0.00022480966530660546\n",
            "0.0002180653753474073\n",
            "0.00021152341408698508\n",
            "0.0002051777116643755\n",
            "0.00019902238031444425\n",
            "0.0001930517089050109\n",
            "0.00018726015763786058\n",
            "0.00018164235290872477\n",
            "0.000176193082321463\n",
            "0.0001709072898518191\n",
            "0.00016578007115626453\n",
            "0.0001608066690215766\n",
            "0.0001559824689509293\n",
            "0.0001513029948824014\n",
            "0.00014676390503592937\n",
            "0.0001423609878848515\n",
            "0.00013809015824830593\n",
            "0.00013394745350085675\n",
            "0.00012992902989583105\n",
            "0.00012603115899895612\n",
            "0.00012225022422898742\n",
            "0.0001185827175021178\n",
            "0.00011502523597705427\n",
            "0.00011157447889774264\n",
            "0.00010822724453081035\n",
            "0.00010498042719488605\n",
            "0.00010183101437903946\n",
            "9.877608394766827e-05\n",
            "9.581280142923822e-05\n",
            "9.293841738636107e-05\n",
            "9.015026486477024e-05\n",
            "8.744575691882712e-05\n",
            "8.48223842112623e-05\n",
            "8.227771268492445e-05\n",
            "7.98093813043767e-05\n",
            "7.741509986524539e-05\n",
            "7.509264686928803e-05\n",
            "7.283986746320939e-05\n",
            "7.06546714393131e-05\n",
            "6.853503129613371e-05\n",
            "6.64789803572497e-05\n",
            "6.44846109465322e-05\n",
            "6.255007261813624e-05\n",
            "6.067357043959214e-05\n",
            "5.8853363326404384e-05\n",
            "5.7087762426612245e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim.lr_scheduler import LambdaLR\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "import numpy as np\n",
        "\n",
        "# Define a learning rate warm-up and decay function\n",
        "def lr_lambda(epoch):\n",
        "    if epoch < warmup_epochs:\n",
        "        return float(epoch+1) / float(max(1, warmup_epochs))\n",
        "    else:\n",
        "        return lr_decay ** (epoch - warmup_epochs)\n",
        "\n",
        "# Define warm-up epochs, learning rate decay factor, and other hyperparameters\n",
        "warmup_epochs = 5\n",
        "lr_decay = 0.97\n",
        "initial_lr = 0.001\n",
        "\n",
        "# Create an instance of the model and move it to the GPU\n",
        "model = MalwareDetectorCNN().to(device)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=initial_lr)\n",
        "\n",
        "# Create a learning rate scheduler\n",
        "scheduler = LambdaLR(optimizer, lr_lambda=lr_lambda)\n",
        "\n",
        "# Initialize variables to track best F1 score and corresponding model state\n",
        "best_f1_score = 0.0\n",
        "best_model_state = None\n",
        "\n",
        "# Train the model\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct_train = 0\n",
        "    total_train = 0\n",
        "    for X_train, labels_train in train_loader:\n",
        "        labels_train = labels_train.to(device)\n",
        "        images_train = torch.tensor(batch_binary_vectors_to_gray_images(X_train, image_size=36), device=device) / 255.0\n",
        "        optimizer.zero_grad()\n",
        "        outputs_train = model(images_train)\n",
        "        loss_train = criterion(outputs_train.squeeze(), labels_train.squeeze())\n",
        "        loss_train.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss_train.item()\n",
        "\n",
        "        # Calculate training accuracy\n",
        "        predicted_train = torch.round(outputs_train.squeeze())\n",
        "        total_train += labels_train.size(0)\n",
        "        correct_train += (predicted_train == labels_train.squeeze()).sum().item()\n",
        "\n",
        "    train_accuracy = 100 * correct_train / total_train\n",
        "    avg_loss = running_loss / len(train_loader)\n",
        "\n",
        "    print('-----------------------------------------------------')\n",
        "    print('Learning raet : ',optimizer.param_groups[0]['lr'])\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%\")\n",
        "\n",
        "    # Step the learning rate scheduler\n",
        "    scheduler.step()\n",
        "\n",
        "    # Evaluate the model on the validation dataset\n",
        "    model.eval()\n",
        "    true_labels_val = []\n",
        "    predicted_labels_val = []\n",
        "    with torch.no_grad():\n",
        "        for X_val, labels_val in val_loader:\n",
        "            labels_val = labels_val.to(device)\n",
        "            val_images = torch.tensor(batch_binary_vectors_to_gray_images(X_val, image_size=36), device=device) / 255.0\n",
        "            val_outputs = model(val_images)\n",
        "            predicted_val = torch.round(val_outputs.squeeze())\n",
        "\n",
        "            # Append true and predicted labels to the lists\n",
        "            true_labels_val.extend(labels_val.squeeze().tolist())\n",
        "            predicted_labels_val.extend(predicted_val.tolist())\n",
        "\n",
        "    # Convert the lists to numpy arrays\n",
        "    true_labels_val = np.array(true_labels_val)\n",
        "    predicted_labels_val = np.array(predicted_labels_val)\n",
        "\n",
        "    # Compute precision, recall, and F1 score for validation set\n",
        "    precision_val = precision_score(true_labels_val, predicted_labels_val)\n",
        "    recall_val = recall_score(true_labels_val, predicted_labels_val)\n",
        "    f1_val = f1_score(true_labels_val, predicted_labels_val)\n",
        "\n",
        "    print(f\"Validation Precision: {precision_val:.4f}, Recall: {recall_val:.4f}, F1 Score: {f1_val:.4f}\")\n",
        "\n",
        "    # Evaluate the model on the test dataset\n",
        "    true_labels_test = []\n",
        "    predicted_labels_test = []\n",
        "    with torch.no_grad():\n",
        "        for X_test, labels_test in test_loader:\n",
        "            labels_test = labels_test.to(device)\n",
        "            test_images = torch.tensor(batch_binary_vectors_to_gray_images(X_test, image_size=36), device=device) / 255.0\n",
        "            test_outputs = model(test_images)\n",
        "            predicted_test = torch.round(test_outputs.squeeze())\n",
        "\n",
        "            # Append true and predicted labels to the lists\n",
        "            true_labels_test.extend(labels_test.squeeze().tolist())\n",
        "            predicted_labels_test.extend(predicted_test.tolist())\n",
        "\n",
        "    # Convert the lists to numpy arrays\n",
        "    true_labels_test = np.array(true_labels_test)\n",
        "    predicted_labels_test = np.array(predicted_labels_test)\n",
        "\n",
        "    # Compute precision, recall, and F1 score for test set\n",
        "    precision_test = precision_score(true_labels_test, predicted_labels_test)\n",
        "    recall_test = recall_score(true_labels_test, predicted_labels_test)\n",
        "    f1_test = f1_score(true_labels_test, predicted_labels_test)\n",
        "\n",
        "    print(f\"Test Precision: {precision_test:.4f}, Recall: {recall_test:.4f}, F1 Score: {f1_test:.4f}\")\n",
        "\n",
        "    # Check if the current model has the best F1 score\n",
        "    if f1_val > best_f1_score:\n",
        "        best_f1_score = f1_val\n",
        "        best_model_state = model.state_dict()\n",
        "\n",
        "# Save the best model based on F1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZWCF0ddP3VW",
        "outputId": "5dc0ca8e-2598-4f89-9cb7-4b7baf3aa922"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------\n",
            "Learning raet :  0.0002\n",
            "Epoch [1/100], Train Loss: 0.1886, Train Accuracy: 95.43%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Precision: 0.0000, Recall: 0.0000, F1 Score: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Precision: 0.0000, Recall: 0.0000, F1 Score: 0.0000\n",
            "-----------------------------------------------------\n",
            "Learning raet :  0.0004\n",
            "Epoch [2/100], Train Loss: 0.1059, Train Accuracy: 96.42%\n",
            "Validation Precision: 0.8373, Recall: 0.4393, F1 Score: 0.5763\n",
            "Test Precision: 0.8393, Recall: 0.4460, F1 Score: 0.5825\n",
            "-----------------------------------------------------\n",
            "Learning raet :  0.0006\n",
            "Epoch [3/100], Train Loss: 0.0847, Train Accuracy: 97.29%\n",
            "Validation Precision: 0.8033, Recall: 0.6101, F1 Score: 0.6935\n",
            "Test Precision: 0.8125, Recall: 0.6196, F1 Score: 0.7031\n",
            "-----------------------------------------------------\n",
            "Learning raet :  0.0008\n",
            "Epoch [4/100], Train Loss: 0.0768, Train Accuracy: 97.47%\n",
            "Validation Precision: 0.8031, Recall: 0.6966, F1 Score: 0.7461\n",
            "Test Precision: 0.8122, Recall: 0.7041, F1 Score: 0.7543\n",
            "-----------------------------------------------------\n",
            "Learning raet :  0.001\n",
            "Epoch [5/100], Train Loss: 0.0693, Train Accuracy: 97.77%\n",
            "Validation Precision: 0.8241, Recall: 0.7213, F1 Score: 0.7693\n",
            "Test Precision: 0.8495, Recall: 0.7311, F1 Score: 0.7859\n",
            "-----------------------------------------------------\n",
            "Learning raet :  0.001\n",
            "Epoch [6/100], Train Loss: 0.0622, Train Accuracy: 98.02%\n",
            "Validation Precision: 0.9009, Recall: 0.6944, F1 Score: 0.7843\n",
            "Test Precision: 0.9019, Recall: 0.6862, F1 Score: 0.7794\n",
            "-----------------------------------------------------\n",
            "Learning raet :  0.0009699999999999999\n",
            "Epoch [7/100], Train Loss: 0.0557, Train Accuracy: 98.21%\n",
            "Validation Precision: 0.9163, Recall: 0.6888, F1 Score: 0.7864\n",
            "Test Precision: 0.9088, Recall: 0.6718, F1 Score: 0.7725\n",
            "-----------------------------------------------------\n",
            "Learning raet :  0.0009408999999999999\n",
            "Epoch [8/100], Train Loss: 0.0519, Train Accuracy: 98.36%\n",
            "Validation Precision: 0.8669, Recall: 0.8124, F1 Score: 0.8387\n",
            "Test Precision: 0.8635, Recall: 0.8022, F1 Score: 0.8317\n",
            "-----------------------------------------------------\n",
            "Learning raet :  0.000912673\n",
            "Epoch [9/100], Train Loss: 0.0461, Train Accuracy: 98.57%\n",
            "Validation Precision: 0.9068, Recall: 0.8090, F1 Score: 0.8551\n",
            "Test Precision: 0.8998, Recall: 0.7914, F1 Score: 0.8421\n",
            "-----------------------------------------------------\n",
            "Learning raet :  0.00088529281\n",
            "Epoch [10/100], Train Loss: 0.0442, Train Accuracy: 98.64%\n",
            "Validation Precision: 0.8531, Recall: 0.8483, F1 Score: 0.8507\n",
            "Test Precision: 0.8544, Recall: 0.8390, F1 Score: 0.8466\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the best model\n",
        "best_model_state = torch.load('best_model.pth')\n",
        "model = MalwareDetectorCNN()\n",
        "model.load_state_dict(best_model_state)\n",
        "model.eval()\n",
        "\n",
        "# Move model to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "# Initialize test metrics\n",
        "true_labels_test = []\n",
        "predicted_labels_test = []\n",
        "\n",
        "# Perform testing\n",
        "with torch.no_grad():\n",
        "    for X_test, labels_test in test_loader:\n",
        "        labels_test = labels_test.to(device)\n",
        "        test_images = torch.tensor(batch_binary_vectors_to_gray_images(X_test, image_size=36),device=device) / 255.0\n",
        "        test_outputs = model(test_images)\n",
        "        predicted_test = torch.round(test_outputs.squeeze())\n",
        "\n",
        "        # Append true and predicted labels to the lists\n",
        "        true_labels_test.extend(labels_test.squeeze().tolist())\n",
        "        predicted_labels_test.extend(predicted_test.tolist())\n",
        "\n",
        "# Convert the lists to numpy arrays\n",
        "true_labels_test = np.array(true_labels_test)\n",
        "predicted_labels_test = np.array(predicted_labels_test)\n",
        "\n",
        "# Compute precision, recall, and F1 score for test set\n",
        "precision_test = precision_score(true_labels_test, predicted_labels_test)\n",
        "recall_test = recall_score(true_labels_test, predicted_labels_test)\n",
        "f1_test = f1_score(true_labels_test, predicted_labels_test)\n",
        "\n",
        "print(f\"Test Precision: {precision_test:.4f}, Recall: {recall_test:.4f}, F1 Score: {f1_test:.4f}\")\n"
      ],
      "metadata": {
        "id": "zsziOGQE3K-k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}