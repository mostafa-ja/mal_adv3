{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mostafa-ja/mal_adv3/blob/main/malware_cnn3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming binary_vector is your 1D binary vector of length 10000\n",
        "binary_vector = np.random.randint(2, size=9800)\n",
        "\n",
        "# Reshape the vector into a 2D array with each element being an 8-length binary vector\n",
        "image = np.reshape(binary_vector, (35, 35, 8))\n",
        "\n",
        "# Convert binary values to gray-scale intensities\n",
        "gray_image = np.packbits(image, axis=-1)\n",
        "\n",
        "# Display the gray-scale image\n",
        "plt.imshow(gray_image, cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "4ZG8enqYt5ga",
        "outputId": "a0088af8-a9ce-42a4-be7d-0fc1529fc8b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZfX_N-gQHKp",
        "outputId": "46e318da-a250-454a-f5d7-e94ab2a944da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv3/raw/main/data/X_redefined_sparse_matrix.npz\n",
            "To: /content/X_redefined_sparse_matrix.npz\n",
            "100%|██████████| 2.31M/2.31M [00:00<00:00, 13.6MB/s]\n",
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv3/raw/main/data/labels.pt\n",
            "To: /content/labels.pt\n",
            "100%|██████████| 517k/517k [00:00<00:00, 7.88MB/s]\n"
          ]
        }
      ],
      "source": [
        "download_links = ['https://github.com/mostafa-ja/mal_adv3/raw/main/data/X_redefined_sparse_matrix.npz',\n",
        "                  'https://github.com/mostafa-ja/mal_adv3/raw/main/data/labels.pt'\n",
        "]\n",
        "\n",
        "\n",
        "import gdown\n",
        "output_filepath = '/content/'\n",
        "for link in download_links:\n",
        "  gdown.download(link, output_filepath)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy import sparse\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "import time\n",
        "\n",
        "\n",
        "torch.manual_seed(0)\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usjRDnBCQK9l",
        "outputId": "d5f56e5f-ad96-44ec-c80a-cf7356a9843f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "X_redefined = sparse.load_npz(\"X_redefined_sparse_matrix.npz\")\n",
        "labels_tensor = torch.load('labels.pt')\n",
        "\n",
        "# Split data into train, validation, and test sets with stratified sampling\n",
        "X_train_val, X_test, labels_train_val, labels_test = train_test_split(X_redefined, labels_tensor, test_size=0.2, stratify=labels_tensor, random_state=42)\n",
        "X_train, X_val, labels_train, labels_val = train_test_split(X_train_val, labels_train_val, test_size=0.2, stratify=labels_train_val, random_state=42)\n",
        "\n",
        "# Combine features and labels into datasets\n",
        "# we use dtype=torch.int8, for Memory-Efficient here, later we will convert to float\n",
        "train_dataset = TensorDataset(torch.tensor(X_train.toarray(), dtype=torch.int8), labels_train)\n",
        "val_dataset = TensorDataset(torch.tensor(X_val.toarray(), dtype=torch.int8), labels_val)\n",
        "test_dataset = TensorDataset(torch.tensor(X_test.toarray(), dtype=torch.int8), labels_test)\n",
        "\n",
        "# Clear unnecessary variables\n",
        "del X_redefined, labels_tensor, X_train_val, X_test, labels_train_val, labels_test, X_train, X_val, labels_train, labels_val"
      ],
      "metadata": {
        "id": "OlfUNSCJQQiN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the DataLoader for training, validation, and test sets\n",
        "batch_size = 256\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "_DeOfARzQRc6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pad_binary_vector(binary_vector, new_size):\n",
        "    batch_size, vector_length = binary_vector.size()\n",
        "\n",
        "    # Calculate the number of zeros to add\n",
        "    num_zeros = new_size - vector_length\n",
        "\n",
        "    # Create a tensor filled with zeros\n",
        "    zeros_tensor = torch.zeros(batch_size, num_zeros, dtype=torch.int)\n",
        "\n",
        "    # Concatenate the binary vector with the zeros tensor along the second dimension\n",
        "    padded_binary_vector = torch.cat([binary_vector, zeros_tensor], dim=1)\n",
        "\n",
        "    return padded_binary_vector"
      ],
      "metadata": {
        "id": "U57qM9nEH6ki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def batch_binary_vectors_to_gray_images(binary_vectors, image_size=36):\n",
        "    \"\"\"\n",
        "    Convert a batch of binary vectors to gray-scale images.\n",
        "\n",
        "    Parameters:\n",
        "        batch_binary_vectors (numpy.ndarray): Batch of binary vectors with shape (batch_size, vector_length).\n",
        "        image_size (int): Size of the square image (default is 36).\n",
        "\n",
        "    Returns:\n",
        "        gray_images: Batch of gray-scale images with shape (batch_size, image_size, image_size).\n",
        "    \"\"\"\n",
        "    batch_binary_vectors = pad_binary_vector(binary_vectors, 10368)\n",
        "\n",
        "    # Reshape each binary vector in the batch into a 2D array with each element being an 8-length binary vector\n",
        "    batch_images = np.reshape(batch_binary_vectors, (-1, image_size, image_size, 8))\n",
        "\n",
        "    # Convert binary values to gray-scale intensities\n",
        "    gray_images = np.packbits(batch_images, axis=-1)\n",
        "\n",
        "    # Remove the last dimension (single channel) from the gray_images array\n",
        "    gray_images = np.squeeze(gray_images, axis=-1)\n",
        "\n",
        "    return gray_images\n"
      ],
      "metadata": {
        "id": "yo0LOBhSIDd2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for X,Y in train_loader:\n",
        "  print(X.shape)\n",
        "  print(Y.shape)\n",
        "  break\n",
        "\n",
        "m = batch_binary_vectors_to_gray_images(X, image_size=36)\n",
        "print(m.shape)\n",
        "\n",
        "plt.imshow(m[2], cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "ev4l8hNVIMPA",
        "outputId": "196392a1-32c9-418a-90a0-344481f10fef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([256, 10000])\n",
            "torch.Size([256, 1])\n",
            "(256, 36, 36)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.zeros(256, 10368, dtype=torch.int)\n",
        "a[:,:10000] =  X\n",
        "\n",
        "m = batch_binary_vectors_to_gray_images(a, image_size=36)\n",
        "print(m.shape)\n",
        "\n",
        "plt.imshow(m[2], cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "NvbXIKk5I4_7",
        "outputId": "6a20fa7d-7087-44b7-cdc5-6e3836c5277e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(256, 36, 36)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class MalwareDetectorCNN(nn.Module):\n",
        "    def __init__(self, in_channels=1, num_classes=1):\n",
        "        super(MalwareDetectorCNN, self).__init__()\n",
        "        # Convolutional layers with ReLU activation\n",
        "        self.conv1 = nn.Conv2d(in_channels, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "\n",
        "        # Max pooling layers\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # Dropout layer for regularization\n",
        "        self.dropout = nn.Dropout(p=0.2)  # Adjust dropout rate as needed\n",
        "\n",
        "        # Flatten layer\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        # Fully connected layers with ReLU activation\n",
        "        self.fc1 = nn.Linear(2048, 256)  # Input size based on conv layers\n",
        "        self.fc2 = nn.Linear(256, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.unsqueeze(1)\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = self.dropout(x)\n",
        "        x = self.pool(F.relu(self.conv3(x)))\n",
        "        x = self.flatten(x)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)  # Consider adding dropout after fc1 as well\n",
        "        x = torch.sigmoid(self.fc2(x))  # Sigmoid for binary classification (malware or benign)\n",
        "        return x"
      ],
      "metadata": {
        "id": "UlRyfSbTih8E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class MalwareDetectorCNN(nn.Module):\n",
        "    def __init__(self, in_channels=1, num_classes=1):\n",
        "        super(MalwareDetectorCNN, self).__init__()\n",
        "        # Convolutional layers with batch normalization and ReLU activation\n",
        "        self.conv1 = nn.Conv2d(in_channels, 32, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "\n",
        "        # Max pooling layers\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # Dropout layer for regularization\n",
        "        self.dropout = nn.Dropout(p=0.2)  # Adjust dropout rate as needed\n",
        "\n",
        "        # Flatten layer\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        # Fully connected layers with ReLU activation\n",
        "        self.fc1 = nn.Linear(2048, 256)  # Input size based on conv layers\n",
        "        self.fc2 = nn.Linear(256, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.unsqueeze(1)\n",
        "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
        "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
        "        x = self.dropout(x)\n",
        "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
        "        x = self.flatten(x)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)  # Consider adding dropout after fc1 as well\n",
        "        x = torch.sigmoid(self.fc2(x))  # Sigmoid for binary classification (malware or benign)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "tf4i5lVcgLmw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim.lr_scheduler import LambdaLR\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "import numpy as np\n",
        "\n",
        "# Define a learning rate warm-up and decay function\n",
        "def lr_lambda(epoch):\n",
        "    if epoch < warmup_epochs:\n",
        "        return float(epoch+1) / float(max(1, warmup_epochs))\n",
        "    else:\n",
        "        return lr_decay ** (epoch - warmup_epochs)\n",
        "\n",
        "# Define warm-up epochs, learning rate decay factor, and other hyperparameters\n",
        "warmup_epochs = 5\n",
        "lr_decay = 0.97\n",
        "initial_lr = 0.001\n",
        "\n",
        "# Create an instance of the model and move it to the GPU\n",
        "model = MalwareDetectorCNN().to(device)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=initial_lr)\n",
        "\n",
        "# Create a learning rate scheduler\n",
        "scheduler = LambdaLR(optimizer, lr_lambda=lr_lambda)\n",
        "\n",
        "# Initialize variables to track best F1 score and corresponding model state\n",
        "best_f1_score = 0.0\n",
        "best_model_state = None\n",
        "\n",
        "# Train the model\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct_train = 0\n",
        "    total_train = 0\n",
        "    for X_train, labels_train in train_loader:\n",
        "        labels_train = labels_train.to(device)\n",
        "        images_train = torch.tensor(batch_binary_vectors_to_gray_images(X_train, image_size=36), device=device) / 255.0\n",
        "        optimizer.zero_grad()\n",
        "        outputs_train = model(images_train)\n",
        "        loss_train = criterion(outputs_train.squeeze(), labels_train.squeeze())\n",
        "        loss_train.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss_train.item()\n",
        "\n",
        "        # Calculate training accuracy\n",
        "        predicted_train = torch.round(outputs_train.squeeze())\n",
        "        total_train += labels_train.size(0)\n",
        "        correct_train += (predicted_train == labels_train.squeeze()).sum().item()\n",
        "\n",
        "    train_accuracy = 100 * correct_train / total_train\n",
        "    avg_loss = running_loss / len(train_loader)\n",
        "\n",
        "    print('-----------------------------------------------------')\n",
        "    print('Learning raet : ',optimizer.param_groups[0]['lr'])\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%\")\n",
        "\n",
        "    # Step the learning rate scheduler\n",
        "    scheduler.step()\n",
        "\n",
        "    # Evaluate the model on the validation dataset\n",
        "    model.eval()\n",
        "    true_labels_val = []\n",
        "    predicted_labels_val = []\n",
        "    with torch.no_grad():\n",
        "        for X_val, labels_val in val_loader:\n",
        "            labels_val = labels_val.to(device)\n",
        "            val_images = torch.tensor(batch_binary_vectors_to_gray_images(X_val, image_size=36), device=device) / 255.0\n",
        "            val_outputs = model(val_images)\n",
        "            predicted_val = torch.round(val_outputs.squeeze())\n",
        "\n",
        "            # Append true and predicted labels to the lists\n",
        "            true_labels_val.extend(labels_val.squeeze().tolist())\n",
        "            predicted_labels_val.extend(predicted_val.tolist())\n",
        "\n",
        "    # Convert the lists to numpy arrays\n",
        "    true_labels_val = np.array(true_labels_val)\n",
        "    predicted_labels_val = np.array(predicted_labels_val)\n",
        "\n",
        "    # Compute precision, recall, and F1 score for validation set\n",
        "    precision_val = precision_score(true_labels_val, predicted_labels_val)\n",
        "    recall_val = recall_score(true_labels_val, predicted_labels_val)\n",
        "    f1_val = f1_score(true_labels_val, predicted_labels_val)\n",
        "\n",
        "    print(f\"Validation Precision: {precision_val:.4f}, Recall: {recall_val:.4f}, F1 Score: {f1_val:.4f}\")\n",
        "\n",
        "    # Evaluate the model on the test dataset\n",
        "    true_labels_test = []\n",
        "    predicted_labels_test = []\n",
        "    with torch.no_grad():\n",
        "        for X_test, labels_test in test_loader:\n",
        "            labels_test = labels_test.to(device)\n",
        "            test_images = torch.tensor(batch_binary_vectors_to_gray_images(X_test, image_size=36), device=device) / 255.0\n",
        "            test_outputs = model(test_images)\n",
        "            predicted_test = torch.round(test_outputs.squeeze())\n",
        "\n",
        "            # Append true and predicted labels to the lists\n",
        "            true_labels_test.extend(labels_test.squeeze().tolist())\n",
        "            predicted_labels_test.extend(predicted_test.tolist())\n",
        "\n",
        "    # Convert the lists to numpy arrays\n",
        "    true_labels_test = np.array(true_labels_test)\n",
        "    predicted_labels_test = np.array(predicted_labels_test)\n",
        "\n",
        "    # Compute precision, recall, and F1 score for test set\n",
        "    precision_test = precision_score(true_labels_test, predicted_labels_test)\n",
        "    recall_test = recall_score(true_labels_test, predicted_labels_test)\n",
        "    f1_test = f1_score(true_labels_test, predicted_labels_test)\n",
        "\n",
        "    print(f\"Test Precision: {precision_test:.4f}, Recall: {recall_test:.4f}, F1 Score: {f1_test:.4f}\")\n",
        "\n",
        "    # Check if the current model has the best F1 score\n",
        "    if f1_val > best_f1_score:\n",
        "        best_f1_score = f1_val\n",
        "        best_model_state = model.state_dict()\n",
        "\n",
        "# Save the best model based on F1\n",
        "torch.save(best_model_state, 'best_model.pth')\n",
        "print(\"Best model saved.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZWCF0ddP3VW",
        "outputId": "08869bcd-b378-4c94-dc39-3f3f90765c8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------\n",
            "Learning raet :  0.0002\n",
            "Epoch [1/100], Train Loss: 0.1157, Train Accuracy: 96.37%\n",
            "Validation Precision: 0.8000, Recall: 0.7056, F1 Score: 0.7499\n",
            "Test Precision: 0.8071, Recall: 0.6960, F1 Score: 0.7475\n",
            "-----------------------------------------------------\n",
            "Learning raet :  0.0004\n",
            "Epoch [2/100], Train Loss: 0.0652, Train Accuracy: 97.92%\n",
            "Validation Precision: 0.8563, Recall: 0.7764, F1 Score: 0.8144\n",
            "Test Precision: 0.8638, Recall: 0.7698, F1 Score: 0.8141\n",
            "-----------------------------------------------------\n",
            "Learning raet :  0.0006\n",
            "Epoch [3/100], Train Loss: 0.0565, Train Accuracy: 98.25%\n",
            "Validation Precision: 0.8674, Recall: 0.8011, F1 Score: 0.8329\n",
            "Test Precision: 0.8744, Recall: 0.8013, F1 Score: 0.8362\n",
            "-----------------------------------------------------\n",
            "Learning raet :  0.0008\n",
            "Epoch [4/100], Train Loss: 0.0492, Train Accuracy: 98.47%\n",
            "Validation Precision: 0.8618, Recall: 0.8056, F1 Score: 0.8328\n",
            "Test Precision: 0.8796, Recall: 0.8210, F1 Score: 0.8493\n",
            "-----------------------------------------------------\n",
            "Learning raet :  0.001\n",
            "Epoch [5/100], Train Loss: 0.0476, Train Accuracy: 98.49%\n",
            "Validation Precision: 0.9110, Recall: 0.7708, F1 Score: 0.8351\n",
            "Test Precision: 0.9209, Recall: 0.7752, F1 Score: 0.8418\n",
            "-----------------------------------------------------\n",
            "Learning raet :  0.001\n",
            "Epoch [6/100], Train Loss: 0.0413, Train Accuracy: 98.68%\n",
            "Validation Precision: 0.8583, Recall: 0.8506, F1 Score: 0.8544\n",
            "Test Precision: 0.8776, Recall: 0.8507, F1 Score: 0.8639\n",
            "-----------------------------------------------------\n",
            "Learning raet :  0.0009699999999999999\n",
            "Epoch [7/100], Train Loss: 0.0386, Train Accuracy: 98.78%\n",
            "Validation Precision: 0.9024, Recall: 0.8416, F1 Score: 0.8709\n",
            "Test Precision: 0.9002, Recall: 0.8435, F1 Score: 0.8709\n",
            "-----------------------------------------------------\n",
            "Learning raet :  0.0009408999999999999\n",
            "Epoch [8/100], Train Loss: 0.0346, Train Accuracy: 98.92%\n",
            "Validation Precision: 0.9543, Recall: 0.7742, F1 Score: 0.8548\n",
            "Test Precision: 0.9480, Recall: 0.7536, F1 Score: 0.8397\n",
            "-----------------------------------------------------\n",
            "Learning raet :  0.000912673\n",
            "Epoch [9/100], Train Loss: 0.0326, Train Accuracy: 98.98%\n",
            "Validation Precision: 0.9444, Recall: 0.8202, F1 Score: 0.8779\n",
            "Test Precision: 0.9394, Recall: 0.8085, F1 Score: 0.8690\n",
            "-----------------------------------------------------\n",
            "Learning raet :  0.00088529281\n",
            "Epoch [10/100], Train Loss: 0.0294, Train Accuracy: 99.09%\n",
            "Validation Precision: 0.9377, Recall: 0.8629, F1 Score: 0.8988\n",
            "Test Precision: 0.9334, Recall: 0.8444, F1 Score: 0.8867\n",
            "-----------------------------------------------------\n",
            "Learning raet :  0.0008587340257\n",
            "Epoch [11/100], Train Loss: 0.0285, Train Accuracy: 99.11%\n",
            "Validation Precision: 0.9211, Recall: 0.8652, F1 Score: 0.8922\n",
            "Test Precision: 0.9174, Recall: 0.8489, F1 Score: 0.8818\n",
            "-----------------------------------------------------\n",
            "Learning raet :  0.0008329720049289998\n",
            "Epoch [12/100], Train Loss: 0.0259, Train Accuracy: 99.20%\n",
            "Validation Precision: 0.9535, Recall: 0.8056, F1 Score: 0.8733\n",
            "Test Precision: 0.9476, Recall: 0.7977, F1 Score: 0.8662\n",
            "-----------------------------------------------------\n",
            "Learning raet :  0.0008079828447811299\n",
            "Epoch [13/100], Train Loss: 0.0248, Train Accuracy: 99.24%\n",
            "Validation Precision: 0.9287, Recall: 0.8787, F1 Score: 0.9030\n",
            "Test Precision: 0.9174, Recall: 0.8588, F1 Score: 0.8871\n",
            "-----------------------------------------------------\n",
            "Learning raet :  0.0007837433594376959\n",
            "Epoch [14/100], Train Loss: 0.0229, Train Accuracy: 99.30%\n",
            "Validation Precision: 0.9316, Recall: 0.8573, F1 Score: 0.8929\n",
            "Test Precision: 0.9407, Recall: 0.8561, F1 Score: 0.8964\n",
            "-----------------------------------------------------\n",
            "Learning raet :  0.0007602310586545651\n",
            "Epoch [15/100], Train Loss: 0.0221, Train Accuracy: 99.32%\n",
            "Validation Precision: 0.9329, Recall: 0.8438, F1 Score: 0.8861\n",
            "Test Precision: 0.9426, Recall: 0.8417, F1 Score: 0.8893\n",
            "-----------------------------------------------------\n",
            "Learning raet :  0.0007374241268949281\n",
            "Epoch [16/100], Train Loss: 0.0215, Train Accuracy: 99.33%\n",
            "Validation Precision: 0.8935, Recall: 0.8865, F1 Score: 0.8900\n",
            "Test Precision: 0.8947, Recall: 0.8867, F1 Score: 0.8907\n",
            "-----------------------------------------------------\n",
            "Learning raet :  0.0007153014030880803\n",
            "Epoch [17/100], Train Loss: 0.0188, Train Accuracy: 99.42%\n",
            "Validation Precision: 0.9270, Recall: 0.8843, F1 Score: 0.9051\n",
            "Test Precision: 0.9263, Recall: 0.8822, F1 Score: 0.9037\n",
            "-----------------------------------------------------\n",
            "Learning raet :  0.0006938423609954377\n",
            "Epoch [18/100], Train Loss: 0.0184, Train Accuracy: 99.41%\n",
            "Validation Precision: 0.9088, Recall: 0.8843, F1 Score: 0.8964\n",
            "Test Precision: 0.9315, Recall: 0.8804, F1 Score: 0.9052\n",
            "-----------------------------------------------------\n",
            "Learning raet :  0.0006730270901655746\n",
            "Epoch [19/100], Train Loss: 0.0178, Train Accuracy: 99.44%\n",
            "Validation Precision: 0.9138, Recall: 0.8809, F1 Score: 0.8970\n",
            "Test Precision: 0.9121, Recall: 0.8867, F1 Score: 0.8992\n",
            "-----------------------------------------------------\n",
            "Learning raet :  0.0006528362774606074\n",
            "Epoch [20/100], Train Loss: 0.0175, Train Accuracy: 99.45%\n",
            "Validation Precision: 0.9276, Recall: 0.8640, F1 Score: 0.8947\n",
            "Test Precision: 0.9293, Recall: 0.8507, F1 Score: 0.8883\n",
            "-----------------------------------------------------\n",
            "Learning raet :  0.0006332511891367892\n",
            "Epoch [21/100], Train Loss: 0.0153, Train Accuracy: 99.53%\n",
            "Validation Precision: 0.9619, Recall: 0.8517, F1 Score: 0.9035\n",
            "Test Precision: 0.9562, Recall: 0.8435, F1 Score: 0.8963\n",
            "-----------------------------------------------------\n",
            "Learning raet :  0.0006142536534626855\n",
            "Epoch [22/100], Train Loss: 0.0152, Train Accuracy: 99.51%\n",
            "Validation Precision: 0.8998, Recall: 0.9079, F1 Score: 0.9038\n",
            "Test Precision: 0.9229, Recall: 0.8939, F1 Score: 0.9082\n",
            "-----------------------------------------------------\n",
            "Learning raet :  0.0005958260438588049\n",
            "Epoch [23/100], Train Loss: 0.0144, Train Accuracy: 99.56%\n",
            "Validation Precision: 0.9712, Recall: 0.8348, F1 Score: 0.8979\n",
            "Test Precision: 0.9624, Recall: 0.8282, F1 Score: 0.8903\n",
            "-----------------------------------------------------\n",
            "Learning raet :  0.0005779512625430407\n",
            "Epoch [24/100], Train Loss: 0.0139, Train Accuracy: 99.54%\n",
            "Validation Precision: 0.9575, Recall: 0.8360, F1 Score: 0.8926\n",
            "Test Precision: 0.9544, Recall: 0.8282, F1 Score: 0.8869\n",
            "-----------------------------------------------------\n",
            "Learning raet :  0.0005606127246667495\n",
            "Epoch [25/100], Train Loss: 0.0135, Train Accuracy: 99.56%\n",
            "Validation Precision: 0.9316, Recall: 0.9034, F1 Score: 0.9173\n",
            "Test Precision: 0.9289, Recall: 0.8813, F1 Score: 0.9045\n",
            "-----------------------------------------------------\n",
            "Learning raet :  0.000543794342926747\n",
            "Epoch [26/100], Train Loss: 0.0128, Train Accuracy: 99.57%\n",
            "Validation Precision: 0.9065, Recall: 0.9045, F1 Score: 0.9055\n",
            "Test Precision: 0.9070, Recall: 0.9029, F1 Score: 0.9049\n",
            "-----------------------------------------------------\n",
            "Learning raet :  0.0005274805126389446\n",
            "Epoch [27/100], Train Loss: 0.0117, Train Accuracy: 99.61%\n",
            "Validation Precision: 0.9012, Recall: 0.9124, F1 Score: 0.9068\n",
            "Test Precision: 0.9065, Recall: 0.9065, F1 Score: 0.9065\n",
            "-----------------------------------------------------\n",
            "Learning raet :  0.0005116560972597763\n",
            "Epoch [28/100], Train Loss: 0.0110, Train Accuracy: 99.64%\n",
            "Validation Precision: 0.9198, Recall: 0.9022, F1 Score: 0.9109\n",
            "Test Precision: 0.9221, Recall: 0.8939, F1 Score: 0.9078\n",
            "-----------------------------------------------------\n",
            "Learning raet :  0.0004963064143419829\n",
            "Epoch [29/100], Train Loss: 0.0115, Train Accuracy: 99.63%\n",
            "Validation Precision: 0.9410, Recall: 0.8787, F1 Score: 0.9088\n",
            "Test Precision: 0.9488, Recall: 0.8660, F1 Score: 0.9055\n",
            "-----------------------------------------------------\n",
            "Learning raet :  0.00048141722191172336\n",
            "Epoch [30/100], Train Loss: 0.0107, Train Accuracy: 99.64%\n",
            "Validation Precision: 0.9174, Recall: 0.8989, F1 Score: 0.9081\n",
            "Test Precision: 0.9257, Recall: 0.8849, F1 Score: 0.9048\n",
            "-----------------------------------------------------\n",
            "Learning raet :  0.0004669747052543717\n",
            "Epoch [31/100], Train Loss: 0.0107, Train Accuracy: 99.66%\n",
            "Validation Precision: 0.9304, Recall: 0.9011, F1 Score: 0.9155\n",
            "Test Precision: 0.9262, Recall: 0.8912, F1 Score: 0.9083\n",
            "-----------------------------------------------------\n",
            "Learning raet :  0.0004529654640967405\n",
            "Epoch [32/100], Train Loss: 0.0095, Train Accuracy: 99.69%\n",
            "Validation Precision: 0.9326, Recall: 0.8865, F1 Score: 0.9090\n",
            "Test Precision: 0.9345, Recall: 0.8849, F1 Score: 0.9090\n",
            "-----------------------------------------------------\n",
            "Learning raet :  0.0004393765001738383\n",
            "Epoch [33/100], Train Loss: 0.0096, Train Accuracy: 99.67%\n",
            "Validation Precision: 0.9299, Recall: 0.9090, F1 Score: 0.9193\n",
            "Test Precision: 0.9312, Recall: 0.8885, F1 Score: 0.9093\n",
            "-----------------------------------------------------\n",
            "Learning raet :  0.0004261952051686231\n",
            "Epoch [34/100], Train Loss: 0.0090, Train Accuracy: 99.71%\n",
            "Validation Precision: 0.9555, Recall: 0.8685, F1 Score: 0.9099\n",
            "Test Precision: 0.9570, Recall: 0.8615, F1 Score: 0.9068\n",
            "-----------------------------------------------------\n",
            "Learning raet :  0.0004134093490135644\n",
            "Epoch [35/100], Train Loss: 0.0096, Train Accuracy: 99.69%\n",
            "Validation Precision: 0.9432, Recall: 0.8955, F1 Score: 0.9187\n",
            "Test Precision: 0.9487, Recall: 0.8813, F1 Score: 0.9138\n",
            "-----------------------------------------------------\n",
            "Learning raet :  0.00040100706854315747\n",
            "Epoch [36/100], Train Loss: 0.0080, Train Accuracy: 99.72%\n",
            "Validation Precision: 0.9185, Recall: 0.8989, F1 Score: 0.9086\n",
            "Test Precision: 0.9298, Recall: 0.9056, F1 Score: 0.9175\n",
            "-----------------------------------------------------\n",
            "Learning raet :  0.00038897685648686274\n",
            "Epoch [37/100], Train Loss: 0.0086, Train Accuracy: 99.71%\n",
            "Validation Precision: 0.9515, Recall: 0.8809, F1 Score: 0.9148\n",
            "Test Precision: 0.9493, Recall: 0.8759, F1 Score: 0.9111\n",
            "-----------------------------------------------------\n",
            "Learning raet :  0.00037730755079225687\n",
            "Epoch [38/100], Train Loss: 0.0082, Train Accuracy: 99.73%\n",
            "Validation Precision: 0.9506, Recall: 0.8652, F1 Score: 0.9059\n",
            "Test Precision: 0.9597, Recall: 0.8561, F1 Score: 0.9049\n",
            "-----------------------------------------------------\n",
            "Learning raet :  0.00036598832426848916\n",
            "Epoch [39/100], Train Loss: 0.0080, Train Accuracy: 99.73%\n",
            "Validation Precision: 0.9332, Recall: 0.8944, F1 Score: 0.9134\n",
            "Test Precision: 0.9413, Recall: 0.8948, F1 Score: 0.9175\n",
            "-----------------------------------------------------\n",
            "Learning raet :  0.00035500867454043444\n",
            "Epoch [40/100], Train Loss: 0.0073, Train Accuracy: 99.73%\n",
            "Validation Precision: 0.9147, Recall: 0.9157, F1 Score: 0.9152\n",
            "Test Precision: 0.9219, Recall: 0.9128, F1 Score: 0.9173\n",
            "-----------------------------------------------------\n",
            "Learning raet :  0.0003443584143042214\n",
            "Epoch [41/100], Train Loss: 0.0074, Train Accuracy: 99.74%\n",
            "Validation Precision: 0.9223, Recall: 0.9067, F1 Score: 0.9144\n",
            "Test Precision: 0.9267, Recall: 0.9092, F1 Score: 0.9178\n",
            "-----------------------------------------------------\n",
            "Learning raet :  0.00033402766187509475\n",
            "Epoch [42/100], Train Loss: 0.0077, Train Accuracy: 99.73%\n",
            "Validation Precision: 0.9418, Recall: 0.8910, F1 Score: 0.9157\n",
            "Test Precision: 0.9455, Recall: 0.8885, F1 Score: 0.9161\n",
            "-----------------------------------------------------\n",
            "Learning raet :  0.0003240068320188419\n",
            "Epoch [43/100], Train Loss: 0.0071, Train Accuracy: 99.77%\n",
            "Validation Precision: 0.9341, Recall: 0.9079, F1 Score: 0.9208\n",
            "Test Precision: 0.9306, Recall: 0.9038, F1 Score: 0.9170\n",
            "-----------------------------------------------------\n",
            "Learning raet :  0.00031428662705827666\n",
            "Epoch [44/100], Train Loss: 0.0068, Train Accuracy: 99.77%\n",
            "Validation Precision: 0.9486, Recall: 0.8921, F1 Score: 0.9195\n",
            "Test Precision: 0.9517, Recall: 0.8867, F1 Score: 0.9181\n",
            "-----------------------------------------------------\n",
            "Learning raet :  0.0003048580282465283\n",
            "Epoch [45/100], Train Loss: 0.0063, Train Accuracy: 99.77%\n",
            "Validation Precision: 0.9507, Recall: 0.8888, F1 Score: 0.9187\n",
            "Test Precision: 0.9516, Recall: 0.8849, F1 Score: 0.9171\n",
            "-----------------------------------------------------\n",
            "Learning raet :  0.0002957122873991325\n",
            "Epoch [46/100], Train Loss: 0.0065, Train Accuracy: 99.78%\n",
            "Validation Precision: 0.9233, Recall: 0.9056, F1 Score: 0.9144\n",
            "Test Precision: 0.9304, Recall: 0.9020, F1 Score: 0.9160\n",
            "-----------------------------------------------------\n",
            "Learning raet :  0.00028684091877715853\n",
            "Epoch [47/100], Train Loss: 0.0066, Train Accuracy: 99.77%\n",
            "Validation Precision: 0.9181, Recall: 0.9191, F1 Score: 0.9186\n",
            "Test Precision: 0.9273, Recall: 0.9173, F1 Score: 0.9222\n",
            "-----------------------------------------------------\n",
            "Learning raet :  0.00027823569121384375\n",
            "Epoch [48/100], Train Loss: 0.0059, Train Accuracy: 99.79%\n",
            "Validation Precision: 0.9274, Recall: 0.9045, F1 Score: 0.9158\n",
            "Test Precision: 0.9413, Recall: 0.8948, F1 Score: 0.9175\n",
            "-----------------------------------------------------\n",
            "Learning raet :  0.0002698886204774284\n",
            "Epoch [49/100], Train Loss: 0.0058, Train Accuracy: 99.79%\n",
            "Validation Precision: 0.9264, Recall: 0.9056, F1 Score: 0.9159\n",
            "Test Precision: 0.9392, Recall: 0.9029, F1 Score: 0.9207\n",
            "-----------------------------------------------------\n",
            "Learning raet :  0.00026179196186310554\n",
            "Epoch [50/100], Train Loss: 0.0055, Train Accuracy: 99.80%\n",
            "Validation Precision: 0.9382, Recall: 0.9034, F1 Score: 0.9204\n",
            "Test Precision: 0.9415, Recall: 0.8975, F1 Score: 0.9190\n",
            "-----------------------------------------------------\n",
            "Learning raet :  0.0002539382030072124\n",
            "Epoch [51/100], Train Loss: 0.0055, Train Accuracy: 99.80%\n",
            "Validation Precision: 0.9388, Recall: 0.8966, F1 Score: 0.9172\n",
            "Test Precision: 0.9443, Recall: 0.8993, F1 Score: 0.9212\n",
            "-----------------------------------------------------\n",
            "Learning raet :  0.000246320056916996\n",
            "Epoch [52/100], Train Loss: 0.0053, Train Accuracy: 99.81%\n",
            "Validation Precision: 0.9389, Recall: 0.8978, F1 Score: 0.9179\n",
            "Test Precision: 0.9405, Recall: 0.8957, F1 Score: 0.9175\n",
            "-----------------------------------------------------\n",
            "Learning raet :  0.00023893045520948612\n",
            "Epoch [53/100], Train Loss: 0.0055, Train Accuracy: 99.80%\n",
            "Validation Precision: 0.9523, Recall: 0.8753, F1 Score: 0.9122\n",
            "Test Precision: 0.9567, Recall: 0.8750, F1 Score: 0.9140\n",
            "-----------------------------------------------------\n",
            "Learning raet :  0.00023176254155320153\n",
            "Epoch [54/100], Train Loss: 0.0056, Train Accuracy: 99.80%\n",
            "Validation Precision: 0.9373, Recall: 0.8899, F1 Score: 0.9130\n",
            "Test Precision: 0.9458, Recall: 0.8939, F1 Score: 0.9191\n",
            "-----------------------------------------------------\n",
            "Learning raet :  0.00022480966530660546\n",
            "Epoch [55/100], Train Loss: 0.0054, Train Accuracy: 99.82%\n",
            "Validation Precision: 0.9240, Recall: 0.9011, F1 Score: 0.9124\n",
            "Test Precision: 0.9368, Recall: 0.9065, F1 Score: 0.9214\n",
            "-----------------------------------------------------\n",
            "Learning raet :  0.0002180653753474073\n",
            "Epoch [56/100], Train Loss: 0.0050, Train Accuracy: 99.81%\n",
            "Validation Precision: 0.9253, Recall: 0.9045, F1 Score: 0.9148\n",
            "Test Precision: 0.9335, Recall: 0.9092, F1 Score: 0.9212\n",
            "-----------------------------------------------------\n",
            "Learning raet :  0.00021152341408698508\n",
            "Epoch [57/100], Train Loss: 0.0051, Train Accuracy: 99.81%\n",
            "Validation Precision: 0.9230, Recall: 0.9022, F1 Score: 0.9125\n",
            "Test Precision: 0.9236, Recall: 0.9137, F1 Score: 0.9186\n",
            "-----------------------------------------------------\n",
            "Learning raet :  0.0002051777116643755\n",
            "Epoch [58/100], Train Loss: 0.0051, Train Accuracy: 99.81%\n",
            "Validation Precision: 0.9559, Recall: 0.8775, F1 Score: 0.9151\n",
            "Test Precision: 0.9552, Recall: 0.8813, F1 Score: 0.9167\n",
            "-----------------------------------------------------\n",
            "Learning raet :  0.00019902238031444425\n",
            "Epoch [59/100], Train Loss: 0.0050, Train Accuracy: 99.80%\n",
            "Validation Precision: 0.9450, Recall: 0.8888, F1 Score: 0.9160\n",
            "Test Precision: 0.9458, Recall: 0.8939, F1 Score: 0.9191\n",
            "-----------------------------------------------------\n",
            "Learning raet :  0.0001930517089050109\n",
            "Epoch [60/100], Train Loss: 0.0044, Train Accuracy: 99.83%\n",
            "Validation Precision: 0.9377, Recall: 0.8966, F1 Score: 0.9167\n",
            "Test Precision: 0.9487, Recall: 0.8975, F1 Score: 0.9224\n",
            "-----------------------------------------------------\n",
            "Learning raet :  0.00018726015763786058\n",
            "Epoch [61/100], Train Loss: 0.0050, Train Accuracy: 99.81%\n",
            "Validation Precision: 0.9407, Recall: 0.8910, F1 Score: 0.9152\n",
            "Test Precision: 0.9475, Recall: 0.8921, F1 Score: 0.9189\n",
            "-----------------------------------------------------\n",
            "Learning raet :  0.00018164235290872477\n",
            "Epoch [62/100], Train Loss: 0.0047, Train Accuracy: 99.83%\n",
            "Validation Precision: 0.9305, Recall: 0.9022, F1 Score: 0.9161\n",
            "Test Precision: 0.9358, Recall: 0.9038, F1 Score: 0.9195\n",
            "-----------------------------------------------------\n",
            "Learning raet :  0.000176193082321463\n",
            "Epoch [63/100], Train Loss: 0.0044, Train Accuracy: 99.84%\n",
            "Validation Precision: 0.9324, Recall: 0.8989, F1 Score: 0.9153\n",
            "Test Precision: 0.9356, Recall: 0.9011, F1 Score: 0.9180\n",
            "-----------------------------------------------------\n",
            "Learning raet :  0.0001709072898518191\n",
            "Epoch [64/100], Train Loss: 0.0048, Train Accuracy: 99.84%\n",
            "Validation Precision: 0.9385, Recall: 0.8910, F1 Score: 0.9141\n",
            "Test Precision: 0.9474, Recall: 0.8903, F1 Score: 0.9179\n",
            "-----------------------------------------------------\n",
            "Learning raet :  0.00016578007115626453\n",
            "Epoch [65/100], Train Loss: 0.0044, Train Accuracy: 99.83%\n",
            "Validation Precision: 0.9365, Recall: 0.8955, F1 Score: 0.9156\n",
            "Test Precision: 0.9494, Recall: 0.8948, F1 Score: 0.9213\n",
            "-----------------------------------------------------\n",
            "Learning raet :  0.0001608066690215766\n",
            "Epoch [66/100], Train Loss: 0.0043, Train Accuracy: 99.83%\n",
            "Validation Precision: 0.9309, Recall: 0.9079, F1 Score: 0.9192\n",
            "Test Precision: 0.9375, Recall: 0.9038, F1 Score: 0.9203\n",
            "-----------------------------------------------------\n",
            "Learning raet :  0.0001559824689509293\n",
            "Epoch [67/100], Train Loss: 0.0045, Train Accuracy: 99.83%\n",
            "Validation Precision: 0.9342, Recall: 0.8933, F1 Score: 0.9133\n",
            "Test Precision: 0.9379, Recall: 0.8957, F1 Score: 0.9163\n",
            "-----------------------------------------------------\n",
            "Learning raet :  0.0001513029948824014\n",
            "Epoch [68/100], Train Loss: 0.0041, Train Accuracy: 99.85%\n",
            "Validation Precision: 0.9354, Recall: 0.8955, F1 Score: 0.9150\n",
            "Test Precision: 0.9397, Recall: 0.8975, F1 Score: 0.9181\n",
            "-----------------------------------------------------\n",
            "Learning raet :  0.00014676390503592937\n",
            "Epoch [69/100], Train Loss: 0.0040, Train Accuracy: 99.85%\n",
            "Validation Precision: 0.9269, Recall: 0.8978, F1 Score: 0.9121\n",
            "Test Precision: 0.9348, Recall: 0.9020, F1 Score: 0.9181\n",
            "-----------------------------------------------------\n",
            "Learning raet :  0.0001423609878848515\n",
            "Epoch [70/100], Train Loss: 0.0039, Train Accuracy: 99.85%\n",
            "Validation Precision: 0.9340, Recall: 0.8899, F1 Score: 0.9114\n",
            "Test Precision: 0.9483, Recall: 0.8912, F1 Score: 0.9189\n",
            "-----------------------------------------------------\n",
            "Learning raet :  0.00013809015824830593\n",
            "Epoch [71/100], Train Loss: 0.0040, Train Accuracy: 99.84%\n",
            "Validation Precision: 0.9360, Recall: 0.8876, F1 Score: 0.9112\n",
            "Test Precision: 0.9465, Recall: 0.8903, F1 Score: 0.9175\n",
            "-----------------------------------------------------\n",
            "Learning raet :  0.00013394745350085675\n",
            "Epoch [72/100], Train Loss: 0.0041, Train Accuracy: 99.85%\n",
            "Validation Precision: 0.9433, Recall: 0.8966, F1 Score: 0.9194\n",
            "Test Precision: 0.9445, Recall: 0.9029, F1 Score: 0.9232\n",
            "-----------------------------------------------------\n",
            "Learning raet :  0.00012992902989583105\n",
            "Epoch [73/100], Train Loss: 0.0037, Train Accuracy: 99.86%\n",
            "Validation Precision: 0.9429, Recall: 0.8910, F1 Score: 0.9162\n",
            "Test Precision: 0.9476, Recall: 0.8948, F1 Score: 0.9204\n",
            "-----------------------------------------------------\n",
            "Learning raet :  0.00012603115899895612\n",
            "Epoch [74/100], Train Loss: 0.0042, Train Accuracy: 99.84%\n",
            "Validation Precision: 0.9471, Recall: 0.8843, F1 Score: 0.9146\n",
            "Test Precision: 0.9450, Recall: 0.8804, F1 Score: 0.9115\n",
            "-----------------------------------------------------\n",
            "Learning raet :  0.00012225022422898742\n",
            "Epoch [75/100], Train Loss: 0.0039, Train Accuracy: 99.85%\n",
            "Validation Precision: 0.9329, Recall: 0.8910, F1 Score: 0.9115\n",
            "Test Precision: 0.9405, Recall: 0.8948, F1 Score: 0.9171\n",
            "-----------------------------------------------------\n",
            "Learning raet :  0.0001185827175021178\n",
            "Epoch [76/100], Train Loss: 0.0040, Train Accuracy: 99.84%\n",
            "Validation Precision: 0.9462, Recall: 0.8888, F1 Score: 0.9166\n",
            "Test Precision: 0.9446, Recall: 0.8885, F1 Score: 0.9157\n",
            "-----------------------------------------------------\n",
            "Learning raet :  0.00011502523597705427\n",
            "Epoch [77/100], Train Loss: 0.0037, Train Accuracy: 99.85%\n",
            "Validation Precision: 0.9409, Recall: 0.8944, F1 Score: 0.9171\n",
            "Test Precision: 0.9451, Recall: 0.8984, F1 Score: 0.9212\n",
            "-----------------------------------------------------\n",
            "Learning raet :  0.00011157447889774264\n",
            "Epoch [78/100], Train Loss: 0.0038, Train Accuracy: 99.84%\n",
            "Validation Precision: 0.9336, Recall: 0.9011, F1 Score: 0.9171\n",
            "Test Precision: 0.9468, Recall: 0.8966, F1 Score: 0.9210\n",
            "-----------------------------------------------------\n",
            "Learning raet :  0.00010822724453081035\n",
            "Epoch [79/100], Train Loss: 0.0037, Train Accuracy: 99.85%\n",
            "Validation Precision: 0.9336, Recall: 0.9000, F1 Score: 0.9165\n",
            "Test Precision: 0.9363, Recall: 0.8984, F1 Score: 0.9169\n",
            "-----------------------------------------------------\n",
            "Learning raet :  0.00010498042719488605\n",
            "Epoch [80/100], Train Loss: 0.0035, Train Accuracy: 99.87%\n",
            "Validation Precision: 0.9320, Recall: 0.8933, F1 Score: 0.9122\n",
            "Test Precision: 0.9384, Recall: 0.9047, F1 Score: 0.9212\n",
            "-----------------------------------------------------\n",
            "Learning raet :  0.00010183101437903946\n",
            "Epoch [81/100], Train Loss: 0.0035, Train Accuracy: 99.86%\n",
            "Validation Precision: 0.9327, Recall: 0.9034, F1 Score: 0.9178\n",
            "Test Precision: 0.9313, Recall: 0.9020, F1 Score: 0.9164\n",
            "-----------------------------------------------------\n",
            "Learning raet :  9.877608394766827e-05\n",
            "Epoch [82/100], Train Loss: 0.0036, Train Accuracy: 99.87%\n",
            "Validation Precision: 0.9274, Recall: 0.9045, F1 Score: 0.9158\n",
            "Test Precision: 0.9316, Recall: 0.9065, F1 Score: 0.9189\n",
            "-----------------------------------------------------\n",
            "Learning raet :  9.581280142923822e-05\n",
            "Epoch [83/100], Train Loss: 0.0037, Train Accuracy: 99.85%\n",
            "Validation Precision: 0.9408, Recall: 0.8921, F1 Score: 0.9158\n",
            "Test Precision: 0.9475, Recall: 0.8921, F1 Score: 0.9189\n",
            "-----------------------------------------------------\n",
            "Learning raet :  9.293841738636107e-05\n",
            "Epoch [84/100], Train Loss: 0.0037, Train Accuracy: 99.85%\n",
            "Validation Precision: 0.9316, Recall: 0.9022, F1 Score: 0.9167\n",
            "Test Precision: 0.9383, Recall: 0.9029, F1 Score: 0.9203\n",
            "-----------------------------------------------------\n",
            "Learning raet :  9.015026486477024e-05\n",
            "Epoch [85/100], Train Loss: 0.0035, Train Accuracy: 99.85%\n",
            "Validation Precision: 0.9351, Recall: 0.8899, F1 Score: 0.9119\n",
            "Test Precision: 0.9328, Recall: 0.8984, F1 Score: 0.9153\n",
            "-----------------------------------------------------\n",
            "Learning raet :  8.744575691882712e-05\n",
            "Epoch [86/100], Train Loss: 0.0036, Train Accuracy: 99.85%\n",
            "Validation Precision: 0.9405, Recall: 0.8888, F1 Score: 0.9139\n",
            "Test Precision: 0.9465, Recall: 0.8912, F1 Score: 0.9180\n",
            "-----------------------------------------------------\n",
            "Learning raet :  8.48223842112623e-05\n",
            "Epoch [87/100], Train Loss: 0.0035, Train Accuracy: 99.87%\n",
            "Validation Precision: 0.9367, Recall: 0.8978, F1 Score: 0.9168\n",
            "Test Precision: 0.9391, Recall: 0.9011, F1 Score: 0.9197\n",
            "-----------------------------------------------------\n",
            "Learning raet :  8.227771268492445e-05\n",
            "Epoch [88/100], Train Loss: 0.0036, Train Accuracy: 99.85%\n",
            "Validation Precision: 0.9408, Recall: 0.8921, F1 Score: 0.9158\n",
            "Test Precision: 0.9422, Recall: 0.8948, F1 Score: 0.9179\n",
            "-----------------------------------------------------\n",
            "Learning raet :  7.98093813043767e-05\n",
            "Epoch [89/100], Train Loss: 0.0035, Train Accuracy: 99.86%\n",
            "Validation Precision: 0.9385, Recall: 0.8921, F1 Score: 0.9147\n",
            "Test Precision: 0.9414, Recall: 0.8957, F1 Score: 0.9180\n",
            "-----------------------------------------------------\n",
            "Learning raet :  7.741509986524539e-05\n",
            "Epoch [90/100], Train Loss: 0.0035, Train Accuracy: 99.87%\n",
            "Validation Precision: 0.9333, Recall: 0.8955, F1 Score: 0.9140\n",
            "Test Precision: 0.9418, Recall: 0.9020, F1 Score: 0.9215\n",
            "-----------------------------------------------------\n",
            "Learning raet :  7.509264686928803e-05\n",
            "Epoch [91/100], Train Loss: 0.0036, Train Accuracy: 99.85%\n",
            "Validation Precision: 0.9362, Recall: 0.8910, F1 Score: 0.9131\n",
            "Test Precision: 0.9485, Recall: 0.8939, F1 Score: 0.9204\n",
            "-----------------------------------------------------\n",
            "Learning raet :  7.283986746320939e-05\n",
            "Epoch [92/100], Train Loss: 0.0036, Train Accuracy: 99.86%\n",
            "Validation Precision: 0.9364, Recall: 0.8933, F1 Score: 0.9143\n",
            "Test Precision: 0.9450, Recall: 0.8966, F1 Score: 0.9202\n",
            "-----------------------------------------------------\n",
            "Learning raet :  7.06546714393131e-05\n",
            "Epoch [93/100], Train Loss: 0.0033, Train Accuracy: 99.86%\n",
            "Validation Precision: 0.9384, Recall: 0.8899, F1 Score: 0.9135\n",
            "Test Precision: 0.9448, Recall: 0.8930, F1 Score: 0.9182\n",
            "-----------------------------------------------------\n",
            "Learning raet :  6.853503129613371e-05\n",
            "Epoch [94/100], Train Loss: 0.0035, Train Accuracy: 99.85%\n",
            "Validation Precision: 0.9355, Recall: 0.8966, F1 Score: 0.9157\n",
            "Test Precision: 0.9408, Recall: 0.9002, F1 Score: 0.9200\n",
            "-----------------------------------------------------\n",
            "Learning raet :  6.64789803572497e-05\n",
            "Epoch [95/100], Train Loss: 0.0033, Train Accuracy: 99.88%\n",
            "Validation Precision: 0.9406, Recall: 0.8899, F1 Score: 0.9145\n",
            "Test Precision: 0.9502, Recall: 0.8921, F1 Score: 0.9202\n",
            "-----------------------------------------------------\n",
            "Learning raet :  6.44846109465322e-05\n",
            "Epoch [96/100], Train Loss: 0.0032, Train Accuracy: 99.88%\n",
            "Validation Precision: 0.9431, Recall: 0.8933, F1 Score: 0.9175\n",
            "Test Precision: 0.9493, Recall: 0.8930, F1 Score: 0.9203\n",
            "-----------------------------------------------------\n",
            "Learning raet :  6.255007261813624e-05\n",
            "Epoch [97/100], Train Loss: 0.0033, Train Accuracy: 99.87%\n",
            "Validation Precision: 0.9343, Recall: 0.8944, F1 Score: 0.9139\n",
            "Test Precision: 0.9443, Recall: 0.9002, F1 Score: 0.9217\n",
            "-----------------------------------------------------\n",
            "Learning raet :  6.067357043959214e-05\n",
            "Epoch [98/100], Train Loss: 0.0033, Train Accuracy: 99.87%\n",
            "Validation Precision: 0.9408, Recall: 0.8921, F1 Score: 0.9158\n",
            "Test Precision: 0.9422, Recall: 0.8939, F1 Score: 0.9174\n",
            "-----------------------------------------------------\n",
            "Learning raet :  5.8853363326404384e-05\n",
            "Epoch [99/100], Train Loss: 0.0034, Train Accuracy: 99.87%\n",
            "Validation Precision: 0.9396, Recall: 0.8921, F1 Score: 0.9153\n",
            "Test Precision: 0.9421, Recall: 0.8921, F1 Score: 0.9164\n",
            "-----------------------------------------------------\n",
            "Learning raet :  5.7087762426612245e-05\n",
            "Epoch [100/100], Train Loss: 0.0031, Train Accuracy: 99.87%\n",
            "Validation Precision: 0.9421, Recall: 0.8955, F1 Score: 0.9182\n",
            "Test Precision: 0.9479, Recall: 0.9002, F1 Score: 0.9234\n",
            "Best model saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the best model\n",
        "best_model_state = torch.load('best_model.pth')\n",
        "model = MalwareDetectorCNN()\n",
        "model.load_state_dict(best_model_state)\n",
        "model.eval()\n",
        "\n",
        "# Move model to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "# Initialize test metrics\n",
        "true_labels_test = []\n",
        "predicted_labels_test = []\n",
        "\n",
        "# Perform testing\n",
        "with torch.no_grad():\n",
        "    for X_test, labels_test in test_loader:\n",
        "        labels_test = labels_test.to(device)\n",
        "        test_images = torch.tensor(batch_binary_vectors_to_gray_images(X_test, image_size=36),device=device) / 255.0\n",
        "        test_outputs = model(test_images)\n",
        "        predicted_test = torch.round(test_outputs.squeeze())\n",
        "\n",
        "        # Append true and predicted labels to the lists\n",
        "        true_labels_test.extend(labels_test.squeeze().tolist())\n",
        "        predicted_labels_test.extend(predicted_test.tolist())\n",
        "\n",
        "# Convert the lists to numpy arrays\n",
        "true_labels_test = np.array(true_labels_test)\n",
        "predicted_labels_test = np.array(predicted_labels_test)\n",
        "\n",
        "# Compute precision, recall, and F1 score for test set\n",
        "precision_test = precision_score(true_labels_test, predicted_labels_test)\n",
        "recall_test = recall_score(true_labels_test, predicted_labels_test)\n",
        "f1_test = f1_score(true_labels_test, predicted_labels_test)\n",
        "\n",
        "print(f\"Test Precision: {precision_test:.4f}, Recall: {recall_test:.4f}, F1 Score: {f1_test:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zsziOGQE3K-k",
        "outputId": "f1bef7db-d362-40fb-fff1-5a86d2cf2306"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Precision: 0.9479, Recall: 0.9002, F1 Score: 0.9234\n"
          ]
        }
      ]
    }
  ]
}