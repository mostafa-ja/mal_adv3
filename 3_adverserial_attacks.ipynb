{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMr+DPMusEHRluVccEXyMYS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mostafa-ja/mal_adv3/blob/main/3_adverserial_attacks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy import sparse\n",
        "import gdown\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import torch.nn.functional as F\n",
        "import random\n"
      ],
      "metadata": {
        "id": "JKDdI3K9LrlF"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "download_link = 'https://drive.google.com/uc?id=12iud4h19CZst4exbr3U2A9iDxBYvZ5U_'\n",
        "output_filepath = '/content/'\n",
        "gdown.download(download_link, output_filepath)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "0C770BMnLop2",
        "outputId": "2d8e04f9-219c-4216-88ea-b05bb179a80b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=12iud4h19CZst4exbr3U2A9iDxBYvZ5U_\n",
            "To: /content/X_redefined_sparse_matrix.npz\n",
            "100%|██████████| 2.31M/2.31M [00:00<00:00, 53.4MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/X_redefined_sparse_matrix.npz'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "download_link = 'https://drive.google.com/uc?id=1IhrcT3jHqlPrw2KvQ5vJkBgozxcJ1cJm'\n",
        "output_filepath = '/content/'\n",
        "gdown.download(download_link, output_filepath)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "y3O3o6ZHLpI8",
        "outputId": "046147e7-88ef-460e-af49-4483009c1173"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1IhrcT3jHqlPrw2KvQ5vJkBgozxcJ1cJm\n",
            "To: /content/labels.pt\n",
            "100%|██████████| 517k/517k [00:00<00:00, 24.7MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/labels.pt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "download_link = 'https://drive.google.com/uc?id=13o5n06UpMDOhtk4u7B_RBSWa3kiiGXFs'\n",
        "output_filepath = '/content/'\n",
        "gdown.download(download_link, output_filepath)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "secibICoPRke",
        "outputId": "aa6c0597-55c2-4cdd-fdea-e49f769cc6ad"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=13o5n06UpMDOhtk4u7B_RBSWa3kiiGXFs\n",
            "To: /content/DNN_params.pth\n",
            "100%|██████████| 8.17M/8.17M [00:00<00:00, 112MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/DNN_params.pth'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "download_link = 'https://drive.google.com/uc?id=1PxFOLBnQAlX-EOsqkhGCSd1T3ykAD0-4'\n",
        "output_filepath = '/content/'\n",
        "gdown.download(download_link, output_filepath)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "3kpiyKpDG3Fm",
        "outputId": "92020e01-1f6a-4ab9-de5f-682f87c7a45c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1PxFOLBnQAlX-EOsqkhGCSd1T3ykAD0-4\n",
            "To: /content/vocab.pkl\n",
            "100%|██████████| 9.18M/9.18M [00:00<00:00, 85.2MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/vocab.pkl'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dictionary from the file\n",
        "with open('vocab.pkl', 'rb') as f:\n",
        "    vocab = pickle.load(f)\n",
        "\n",
        "for i, (key, value) in enumerate(vocab.items()):\n",
        "    print((key, value))\n",
        "    if i >= 5:\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0rDH5Q6HOmd",
        "outputId": "a99f0195-a64a-414d-97c5-5f3ade8df553"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('android/media/mediaplayer->start', 141045)\n",
            "('android/app/activity->setcontentview', 140900)\n",
            "('android/os/vibrator->cancel', 141093)\n",
            "('android.permission.vibrate', 140720)\n",
            "('android.hardware.touchscreen', 137091)\n",
            "('android.intent.action.main', 138335)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "X_redefined = sparse.load_npz(\"X_redefined_sparse_matrix.npz\")\n",
        "labels_tensor = torch.load('labels.pt')"
      ],
      "metadata": {
        "id": "qHe1GZxX-ET4"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into train, validation, and test sets with stratified sampling\n",
        "X_train_val, X_test, labels_train_val, labels_test = train_test_split(X_redefined, labels_tensor, test_size=0.2, stratify=labels_tensor, random_state=42)\n",
        "X_train, X_val, labels_train, labels_val = train_test_split(X_train_val, labels_train_val, test_size=0.2, stratify=labels_train_val, random_state=42)\n",
        "\n",
        "# Combine features and labels into datasets\n",
        "train_dataset = TensorDataset(torch.tensor(X_train.toarray(), dtype=torch.float32), labels_train)\n",
        "val_dataset = TensorDataset(torch.tensor(X_val.toarray(), dtype=torch.float32), labels_val)\n",
        "test_dataset = TensorDataset(torch.tensor(X_test.toarray(), dtype=torch.float32), labels_test)\n"
      ],
      "metadata": {
        "id": "V8SALqiV-zFj"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the DataLoader for training, validation, and test sets\n",
        "batch_size = 256\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "g3BUXjXdZ9wq"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class MalwareDetectionModel(nn.Module):\n",
        "    def __init__(self, input_size=10000, hidden_1_size=200, hidden_2_size=200, num_labels=2, dropout_prob=0.6):\n",
        "        super(MalwareDetectionModel, self).__init__()\n",
        "\n",
        "        self.input_size = input_size\n",
        "        self.hidden_1_size = hidden_1_size\n",
        "        self.hidden_2_size = hidden_2_size\n",
        "        self.num_labels = num_labels\n",
        "        self.dropout_prob = dropout_prob\n",
        "\n",
        "        self.fc1 = nn.Linear(input_size, hidden_1_size)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.dropout1 = nn.Dropout(dropout_prob)\n",
        "        self.fc2 = nn.Linear(hidden_1_size, hidden_2_size)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.dropout2 = nn.Dropout(dropout_prob)\n",
        "        self.fc3 = nn.Linear(hidden_2_size, num_labels)\n",
        "        self.log_softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.dropout1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc3(x)\n",
        "        x = self.log_softmax(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "xdNbTvxTTqyw"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of your model\n",
        "model = MalwareDetectionModel()\n",
        "\n",
        "# Load model parameters\n",
        "model.load_state_dict(torch.load('DNN_params.pth'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZs3fmmZ-4PM",
        "outputId": "549381b3-5bb4-41f6-d284-b9cc501ccc44"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X,y = next(iter(test_loader))\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91tjptrSb5qi",
        "outputId": "f0b00d49-7fef-484e-ae92-614208199110"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([256, 10000])\n",
            "torch.Size([256, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "delta = torch.zeros_like(X, requires_grad=True)\n",
        "for t in range(25):\n",
        "    loss = nn.CrossEntropyLoss()(model(X + delta), y.view(-1).long())\n",
        "    loss.backward()\n",
        "    gradients = delta.grad.detach().sign() * (X < 0.5)\n",
        "    delta.data = (delta + 0.02*delta.grad.detach().sign()).clamp(0.,1.)\n",
        "    print(delta.data[0])\n",
        "    delta.grad.zero_()\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "pP6ugpgGJaCp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def round_x(x, round_threshold=0.5):\n",
        "    \"\"\"\n",
        "    Rounds x by thresholding it according to round_threshold.\n",
        "    :param x: input tensor\n",
        "    :param round_threshold: threshold parameter\n",
        "    :return: a tensor of 0s and 1s\n",
        "    \"\"\"\n",
        "    return (x >= round_threshold).float()\n",
        "\n",
        "def get_x0(x, initial_rounding_threshold=0.5, is_sample=False):\n",
        "    \"\"\"\n",
        "    Helper function to randomly initialize the inner maximizer algorithm.\n",
        "    Randomizes the input tensor while preserving its functionality.\n",
        "    :param x: input tensor\n",
        "    :param rounding_threshold: threshold for rounding\n",
        "    :param is_sample: flag to sample randomly from feasible area\n",
        "    :return: randomly sampled feasible version of x\n",
        "    \"\"\"\n",
        "    if is_sample:\n",
        "        rand_x = round_x(torch.rand(x.size()), initial_rounding_threshold=initial_rounding_threshold)\n",
        "        return (rand_x.byte() | x.byte()).float()\n",
        "    else:\n",
        "        return x\n",
        "\n",
        "def or_float_tensors(x_1, x_2):\n",
        "    \"\"\"\n",
        "    ORs two float tensors by converting them to byte and back.\n",
        "    :param x_1: tensor one\n",
        "    :param x_2: tensor two\n",
        "    :return: float tensor of 0s and 1s\n",
        "    \"\"\"\n",
        "    return (x_1.byte() | x_2.byte()).float()\n",
        "\n",
        "\n",
        "def xor_float_tensors(x_1, x_2):\n",
        "    \"\"\"\n",
        "    XORs two float tensors by converting them to byte and back\n",
        "    Note that byte() takes the first 8 bit after the decimal point of the float\n",
        "    e.g., 0.0 ==> 0\n",
        "          0.1 ==> 0\n",
        "          1.1 ==> 1\n",
        "        255.1 ==> 255\n",
        "        256.1 ==> 0\n",
        "    Subsequently the purpose of this function is to map 1s float tensors to 1\n",
        "    and those of 0s to 0. I.e., it is meant to be used on tensors of 0s and 1s.\n",
        "\n",
        "    :param x_1: tensor one\n",
        "    :param x_2: tensor two\n",
        "    :return: float tensor of 0s and 1s.\n",
        "    \"\"\"\n",
        "    return (x_1.byte() ^ x_2.byte()).float()\n",
        "\n",
        "def get_loss(x,y,model):\n",
        "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "    outputs = model(x)\n",
        "    loss = criterion(outputs, y.view(-1).long())\n",
        "    _, predicted = torch.topk(outputs, k=1)\n",
        "    done = (predicted != y).squeeze()\n",
        "\n",
        "    return loss, done\n",
        "\n"
      ],
      "metadata": {
        "id": "XCbqeJ84gfDD"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "x_1 = torch.tensor([1.0, 1.0,  1.0, 1.0, 1.0, 0.0,  0.0, 0.2])\n",
        "x_2 = torch.tensor([0.0, 0.6, -0.2, 0.9, 1.9, 1.0, -0.2, 0.3])\n",
        "result = or_float_tensors(x_1, x_2)\n",
        "             tensor([1., 1., 1., 1., 1., 1., 0., 0.])\n",
        "\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "w1QRWuCbdFqD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dfgsm_k(x, y, model, k=25, epsilon=0.02, alpha=1., initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False):\n",
        "    \"\"\"\n",
        "    FGSM^k with deterministic rounding\n",
        "    :param y: ground truth labels\n",
        "    :param x: feature vector\n",
        "    :param model: neural network model\n",
        "    :param k: number of steps\n",
        "    :param epsilon: update value in each direction\n",
        "    :param alpha: hyperparameter for controlling the portionate of rounding\n",
        "    :param initial_rounding_threshold: threshold parameter for rounding the initial x_next\n",
        "    :param round_threshold: threshold parameter for rounding\n",
        "    :param is_report_loss_diff: flag to report loss difference\n",
        "    :param is_sample: flag to sample randomly from the feasible area\n",
        "    :return: the adversarial version of x according to dfgsm_k (tensor)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Compute natural loss\n",
        "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "    loss_natural = criterion(model(x), y.view(-1).long())\n",
        "\n",
        "    # Initialize starting point\n",
        "    x_next = x.clone()\n",
        "    x_next = get_x0(x_next, initial_rounding_threshold, is_sample)\n",
        "\n",
        "    # Multi-step\n",
        "    for t in range(k):\n",
        "        # Forward pass\n",
        "        x_var = x_next.clone().detach().requires_grad_(True)\n",
        "        y_model = model(x_var)\n",
        "        loss = criterion(y_model, y.view(-1).long())\n",
        "\n",
        "        # Compute gradient\n",
        "        grad_vars = torch.autograd.grad(loss.mean(), x_var)\n",
        "        # Find the next sample\n",
        "        x_next = x_next + epsilon * torch.sign(grad_vars[0].data)\n",
        "\n",
        "        # Projection\n",
        "        x_next = torch.clamp(x_next, min=0., max=1.)\n",
        "\n",
        "    # Rounding step\n",
        "    if random:\n",
        "       round_threshold = torch.rand(x_next.size()) * alpha\n",
        "    x_next = round_x(x_next, round_threshold=round_threshold)\n",
        "\n",
        "    # Feasible projection\n",
        "    x_next = or_float_tensors(x_next, x)\n",
        "\n",
        "    # Compute adversarial loss\n",
        "    loss_adv = criterion(model(x_next), y.view(-1).long()).data\n",
        "\n",
        "    if is_report_loss_diff:\n",
        "        #print(f\"Natural loss: {loss_natural.mean():.4f}, Adversarial loss: {loss_adv.mean():.4f}, Difference: {(loss_adv.mean() - loss_natural.mean()):.4f}\")\n",
        "        outputs = model(x_next)\n",
        "        _, predicted = torch.topk(outputs, k=1)\n",
        "        done = (predicted != y).squeeze()\n",
        "        print(f\"rFGSM: attack effectiveness {done.sum().item() / x.size()[0] * 100:.3f}%.\")\n",
        "\n",
        "    # Replace with natural if adversarial loss is higher\n",
        "    replace_flag = (loss_adv < loss_natural).squeeze()\n",
        "    x_next[replace_flag] = x[replace_flag]\n",
        "\n",
        "    return x_next\n"
      ],
      "metadata": {
        "id": "H6BiF-vCHLlH"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_adv = dfgsm_k(X,y,model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTlgFwyKr3ex",
        "outputId": "a6222aeb-bc95-4c76-c992-02f1a85e6552"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rFGSM: attack effectiveness 100.000%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_adv = dfgsm_k(X,y,model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X10_IhqiAZSB",
        "outputId": "e6315ef3-8c0f-4331-bdb7-0e788ad18d3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Natural loss: 0.0060, Adversarial loss: 2221.2881, Difference: 2221.2820\n",
            "rFGSM: attack effectiveness 100.000%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.sum()/batch_size)\n",
        "print(x_adv.sum()/batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GafR_uFI7_l",
        "outputId": "3917d133-5f53-4eb3-c117-35b756c92b09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(26.6289)\n",
            "tensor(3986.6562)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_adv = dfgsm_k(X,y,model,random=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4xLg9HYZ9s7",
        "outputId": "d32bb793-7d39-4f67-d414-4cb1ce14adf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Natural loss: 0.0060, Adversarial loss: 1290.9233, Difference: 1290.9174\n",
            "rFGSM: attack effectiveness 100.000%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.sum()/batch_size)\n",
        "print(x_adv.sum()/batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmZlatNbaN8G",
        "outputId": "aea07910-0b65-4707-b22b-7cada23fc851"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(26.6289)\n",
            "tensor(2741.3125)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_adv = dfgsm_k(X,y,model,k=1,random=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KayY50GaVVB",
        "outputId": "04ff7813-9251-4157-e8da-f50dbe8cba7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Natural loss: 0.0060, Adversarial loss: 38.6829, Difference: 38.6769\n",
            "rFGSM: attack effectiveness 100.000%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.sum()/batch_size)\n",
        "print(x_adv.sum()/batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bx3Eyhemae7F",
        "outputId": "f34d260a-58c1-4d69-d0af-b4a48cc00a49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(26.6289)\n",
            "tensor(120.8047)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for alpha in range(1, 52, 10):\n",
        "  print('alpha = ',alpha)\n",
        "  x_adv = dfgsm_k(X, y, model, k=20, epsilon=0.02, alpha=alpha,random=True)\n",
        "  print(X.sum()/batch_size)\n",
        "  print(x_adv.sum()/batch_size)\n",
        "  print('***************************')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ue3RTg7WVOvD",
        "outputId": "dc2aa351-fea9-4389-9fc0-d4c79bfac7ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "alpha =  1\n",
            "rFGSM: attack effectiveness 100.000%.\n",
            "tensor(28.0148)\n",
            "tensor(2189.4138)\n",
            "***************************\n",
            "alpha =  11\n",
            "rFGSM: attack effectiveness 100.000%.\n",
            "tensor(28.0148)\n",
            "tensor(222.7241)\n",
            "***************************\n",
            "alpha =  21\n",
            "rFGSM: attack effectiveness 100.000%.\n",
            "tensor(28.0148)\n",
            "tensor(132.2562)\n",
            "***************************\n",
            "alpha =  31\n",
            "rFGSM: attack effectiveness 99.507%.\n",
            "tensor(28.0148)\n",
            "tensor(98.3202)\n",
            "***************************\n",
            "alpha =  41\n",
            "rFGSM: attack effectiveness 94.581%.\n",
            "tensor(28.0148)\n",
            "tensor(80.3054)\n",
            "***************************\n",
            "alpha =  51\n",
            "rFGSM: attack effectiveness 91.626%.\n",
            "tensor(28.0148)\n",
            "tensor(70.1970)\n",
            "***************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_samples = 0\n",
        "total_attack_success = 0\n",
        "total_features_x = 0\n",
        "total_features_x_adv = 0\n",
        "\n",
        "for X, y in test_loader:\n",
        "    batch_size = X.size(0)\n",
        "    x_adv = dfgsm_k(X, y, model, k=20, epsilon=0.0005, random=True,is_report_loss_diff=False)\n",
        "\n",
        "    # Compute mean number of features\n",
        "    total_features_x += X.sum().item()\n",
        "    total_features_x_adv += x_adv.sum().item()\n",
        "\n",
        "    # Compute attack effectiveness for this batch\n",
        "    outputs_adv = model(x_adv)\n",
        "    _, predicted_adv = torch.topk(outputs_adv, k=1)\n",
        "    total_attack_success += torch.sum(predicted_adv != y).item()\n",
        "    total_samples += batch_size\n",
        "\n",
        "# Compute mean number of features\n",
        "mean_features_x = total_features_x / total_samples\n",
        "mean_features_x_adv = total_features_x_adv / total_samples\n",
        "\n",
        "# Compute mean attack effectiveness\n",
        "mean_attack_effectiveness = (total_attack_success / total_samples) * 100\n",
        "\n",
        "# Print results\n",
        "print('Mean number of features (X):', mean_features_x)\n",
        "print('Mean number of features (X_adv):', mean_features_x_adv)\n",
        "print('Mean attack effectiveness:', mean_attack_effectiveness)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qI8_L180z03g",
        "outputId": "65020b0e-05f6-40a8-936b-3bfbd451c886"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean number of features (X): 27.5364492500872\n",
            "Mean number of features (X_adv): 76.25450529008255\n",
            "Mean attack effectiveness: 98.64356857729722\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_samples = 0\n",
        "total_attack_success = 0\n",
        "total_features_x = 0\n",
        "total_features_x_adv = 0\n",
        "\n",
        "for X, y in test_loader:\n",
        "    batch_size = X.size(0)\n",
        "    x_adv = dfgsm_k(X, y, model, k=20, epsilon=0.02, alpha=40,random=True,is_report_loss_diff=False)\n",
        "\n",
        "    # Compute mean number of features\n",
        "    total_features_x += X.sum().item()\n",
        "    total_features_x_adv += x_adv.sum().item()\n",
        "\n",
        "    # Compute attack effectiveness for this batch\n",
        "    outputs_adv = model(x_adv)\n",
        "    _, predicted_adv = torch.topk(outputs_adv, k=1)\n",
        "    total_attack_success += torch.sum(predicted_adv != y).item()\n",
        "    total_samples += batch_size\n",
        "\n",
        "# Compute mean number of features\n",
        "mean_features_x = total_features_x / total_samples\n",
        "mean_features_x_adv = total_features_x_adv / total_samples\n",
        "\n",
        "# Compute mean attack effectiveness\n",
        "mean_attack_effectiveness = (total_attack_success / total_samples) * 100\n",
        "\n",
        "# Print results\n",
        "print('Mean number of features (X):', mean_features_x)\n",
        "print('Mean number of features (X_adv):', mean_features_x_adv)\n",
        "print('Mean attack effectiveness:', mean_attack_effectiveness)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-c7gxOHmXqv",
        "outputId": "29185cf1-413e-48ec-c2e2-91994ee67ee6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean number of features (X): 27.5364492500872\n",
            "Mean number of features (X_adv): 81.65845056776344\n",
            "Mean attack effectiveness: 96.50428244777738\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def dfgsm_k2(x, y, model, k=25, epsilon=0.02, alpha=1., initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False):\n",
        "    \"\"\"\n",
        "    FGSM^k with deterministic rounding\n",
        "    :param y: ground truth labels\n",
        "    :param x: feature vector\n",
        "    :param model: neural network model\n",
        "    :param k: number of steps\n",
        "    :param epsilon: update value in each direction\n",
        "    :param alpha: hyperparameter for controlling the portionate of rounding\n",
        "    :param initial_rounding_threshold: threshold parameter for rounding the initial x_next\n",
        "    :param round_threshold: threshold parameter for rounding\n",
        "    :param is_report_loss_diff: flag to report loss difference\n",
        "    :param is_sample: flag to sample randomly from the feasible area\n",
        "    :return: the adversarial version of x according to dfgsm_k (tensor)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Compute natural loss\n",
        "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "    loss_natural = criterion(model(x), y.view(-1).long())\n",
        "\n",
        "    # Initialize starting point\n",
        "    x_next = x.clone()\n",
        "    x_next = get_x0(x_next, initial_rounding_threshold, is_sample)\n",
        "\n",
        "    # Multi-step\n",
        "    for t in range(k):\n",
        "        # Forward pass\n",
        "        x_var = x_next.clone().detach().requires_grad_(True)\n",
        "        y_model = model(x_var)\n",
        "        loss = criterion(y_model, y.view(-1).long())\n",
        "\n",
        "        # Compute gradient\n",
        "        grad_vars = torch.autograd.grad(loss.mean(), x_var)\n",
        "        #print(torch.sign(grad_vars[0].data).clamp(min=0))\n",
        "        # Find the next sample\n",
        "        x_next = x_next + epsilon * (torch.sign(grad_vars[0].data).clamp(min=0))\n",
        "\n",
        "        # Projection\n",
        "        x_next = torch.clamp(x_next, min=0., max=1.)\n",
        "\n",
        "    # Rounding step\n",
        "    if random:\n",
        "       round_threshold = torch.rand(x_next.size()) * alpha\n",
        "    x_next = round_x(x_next, round_threshold=round_threshold)\n",
        "\n",
        "    # Feasible projection\n",
        "    x_next = or_float_tensors(x_next, x)\n",
        "\n",
        "    # Compute adversarial loss\n",
        "    loss_adv = criterion(model(x_next), y.view(-1).long()).data\n",
        "\n",
        "    if is_report_loss_diff:\n",
        "        #print(f\"Natural loss: {loss_natural.mean():.4f}, Adversarial loss: {loss_adv.mean():.4f}, Difference: {(loss_adv.mean() - loss_natural.mean()):.4f}\")\n",
        "        outputs = model(x_next)\n",
        "        _, predicted = torch.topk(outputs, k=1)\n",
        "        done = (predicted != y).squeeze()\n",
        "        print(f\"rFGSM: attack effectiveness {done.sum().item() / x.size()[0] * 100:.3f}%.\")\n",
        "\n",
        "    # Replace with natural if adversarial loss is higher\n",
        "    replace_flag = (loss_adv < loss_natural).squeeze()\n",
        "    x_next[replace_flag] = x[replace_flag]\n",
        "\n",
        "    return x_next"
      ],
      "metadata": {
        "id": "jJHs7RsgsHMS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_adv = dfgsm_k2(X[:1],y[:1],model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GfFMDVbEsJzQ",
        "outputId": "eb00fd42-fc84-4c02-d9bd-d389aee31d88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rFGSM: attack effectiveness 100.000%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for alpha in range(1, 52, 10):\n",
        "  print('alpha = ',alpha)\n",
        "  x_adv = dfgsm_k2(X, y, model, k=20, epsilon=0.02, alpha=alpha,random=True)\n",
        "  print(X.sum()/batch_size)\n",
        "  print(x_adv.sum()/batch_size)\n",
        "  print('***************************')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5povafNsuLV",
        "outputId": "15d13143-21aa-4028-f107-5814f26b046c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "alpha =  1\n",
            "rFGSM: attack effectiveness 100.000%.\n",
            "tensor(28.0148)\n",
            "tensor(2246.3103)\n",
            "***************************\n",
            "alpha =  11\n",
            "rFGSM: attack effectiveness 100.000%.\n",
            "tensor(28.0148)\n",
            "tensor(228.2020)\n",
            "***************************\n",
            "alpha =  21\n",
            "rFGSM: attack effectiveness 100.000%.\n",
            "tensor(28.0148)\n",
            "tensor(132.3547)\n",
            "***************************\n",
            "alpha =  31\n",
            "rFGSM: attack effectiveness 99.507%.\n",
            "tensor(28.0148)\n",
            "tensor(98.7537)\n",
            "***************************\n",
            "alpha =  41\n",
            "rFGSM: attack effectiveness 98.030%.\n",
            "tensor(28.0148)\n",
            "tensor(82.3054)\n",
            "***************************\n",
            "alpha =  51\n",
            "rFGSM: attack effectiveness 88.177%.\n",
            "tensor(28.0148)\n",
            "tensor(71.4335)\n",
            "***************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_samples = 0\n",
        "total_attack_success = 0\n",
        "total_features_x = 0\n",
        "total_features_x_adv = 0\n",
        "\n",
        "for X, y in test_loader:\n",
        "    batch_size = X.size(0)\n",
        "    x_adv = dfgsm_k2(X, y, model, k=20, epsilon=0.02, alpha=40,random=True,is_report_loss_diff=False)\n",
        "\n",
        "    # Compute mean number of features\n",
        "    total_features_x += X.sum().item()\n",
        "    total_features_x_adv += x_adv.sum().item()\n",
        "\n",
        "    # Compute attack effectiveness for this batch\n",
        "    outputs_adv = model(x_adv)\n",
        "    _, predicted_adv = torch.topk(outputs_adv, k=1)\n",
        "    total_attack_success += torch.sum(predicted_adv != y).item()\n",
        "    total_samples += batch_size\n",
        "\n",
        "# Compute mean number of features\n",
        "mean_features_x = total_features_x / total_samples\n",
        "mean_features_x_adv = total_features_x_adv / total_samples\n",
        "\n",
        "# Compute mean attack effectiveness\n",
        "mean_attack_effectiveness = (total_attack_success / total_samples) * 100\n",
        "\n",
        "# Print results\n",
        "print('Mean number of features (X):', mean_features_x)\n",
        "print('Mean number of features (X_adv):', mean_features_x_adv)\n",
        "print('Mean attack effectiveness:', mean_attack_effectiveness)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJDq5_oZtPSW",
        "outputId": "7391b1a7-40a1-464c-a934-fdd4c21b118f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean number of features (X): 27.5364492500872\n",
            "Mean number of features (X_adv): 82.96155485796226\n",
            "Mean attack effectiveness: 96.48878037437507\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ".clone(): This method creates a deep copy of the tensor, including its data and gradients (if any). It essentially creates a new tensor with the same data and properties as the original tensor. If the original tensor is part of a computation graph and requires gradients, the cloned tensor will also be part of the same computation graph and will require gradients. Any changes made to the cloned tensor will not affect the original tensor, and vice versa.\n",
        "\n",
        ".copy(): This method creates a shallow copy of the tensor. It only copies the data, not the computational graph or gradients. Therefore, the copied tensor will be detached from any computation graph and will not require gradients, even if the original tensor did. Changes made to the copied tensor will not affect the original tensor, but changes in the original tensor's data will be reflected in the copied tensor.\n",
        "\n"
      ],
      "metadata": {
        "id": "DxHlKdaVI5bQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def bga_k(x, y, model, k=25, alpha=1., is_report_loss_diff=True, use_sample=False):\n",
        "    \"\"\"\n",
        "    Multi-step bit gradient ascent\n",
        "    :param x: feature vector\n",
        "    :param y: ground truth labels\n",
        "    :param model: neural network model\n",
        "    :param k: number of steps\n",
        "    :param alpha: hyperparameter for controlling updates\n",
        "    :param is_report_loss_diff: flag to report loss difference\n",
        "    :param use_sample: flag to sample randomly from the feasible area\n",
        "    :return: the adversarial version of x according to bga_k (tensor)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Compute natural loss\n",
        "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "    loss_natural = criterion(model(x), y.view(-1).long())\n",
        "\n",
        "    # Initialize worst loss and corresponding adversarial samples\n",
        "    loss_worst = loss_natural.clone()\n",
        "    x_worst = x.clone()\n",
        "\n",
        "    # Book-keeping\n",
        "    sqrt_m = torch.sqrt(torch.tensor([x.size()[1]], dtype=torch.float))\n",
        "\n",
        "    # Multi-step with gradients\n",
        "    for t in range(k):\n",
        "        if t == 0:\n",
        "            # Initialize starting point\n",
        "            x_next = get_x0(x, use_sample)\n",
        "        else:\n",
        "            # Compute gradient\n",
        "            grad_vars = torch.autograd.grad(loss.mean(), x_var)\n",
        "            grad_data = grad_vars[0].data\n",
        "\n",
        "            # Compute the updates\n",
        "            # torch.norm(grad_data, 2, 1), 2:the L2-norm , 1:the norm along dimension 1\n",
        "            x_update = (sqrt_m * (1. - 2. * x_next) * grad_data >= (alpha * torch.norm(grad_data, 2, 1).unsqueeze(1))).float()\n",
        "\n",
        "            # Find the next sample with projection to the feasible set\n",
        "            x_next = xor_float_tensors(x_update, x_next)\n",
        "            x_next = or_float_tensors(x_next, x)\n",
        "\n",
        "        # Forward pass\n",
        "        x_var = x_next.clone().detach().requires_grad_(True)\n",
        "        y_model = model(x_var)\n",
        "        loss = criterion(y_model, y.view(-1).long())\n",
        "\n",
        "        # Update worst loss and adversarial samples\n",
        "        replace_flag = (loss.data > loss_worst)\n",
        "        loss_worst[replace_flag] = loss.data[replace_flag]\n",
        "        x_worst[replace_flag] = x_next[replace_flag]\n",
        "\n",
        "    if is_report_loss_diff:\n",
        "        #print(f\"Natural loss: {loss_natural.mean():.4f}, Adversarial loss: {loss_worst.mean():.4f}, Difference: {(loss_worst.mean() - loss_natural.mean()):.4f}\")\n",
        "        outputs = model(x_worst)\n",
        "        _, predicted = torch.topk(outputs, k=1)\n",
        "        done = (predicted != y).squeeze()\n",
        "        print(f\"bga_k: attack effectiveness {done.sum().item() / x.size()[0] * 100:.3f}%.\")\n",
        "\n",
        "    return x_worst\n"
      ],
      "metadata": {
        "id": "V_1x56e5UYFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_adv = bga_k(X, y, model, k=25, is_report_loss_diff=True, use_sample=False)\n",
        "print(X.sum()/batch_size)\n",
        "print(x_adv.sum()/batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trFNZQ0HLMZ8",
        "outputId": "8921d8d7-7c8a-4ea0-eac6-2d8d34cda80f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bga_k: attack effectiveness 100.000%.\n",
            "tensor(26.6289)\n",
            "tensor(2297.2891)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for alpha in range(1,6):\n",
        "  print('alpha = ',alpha)\n",
        "  x_adv = bga_k(X, y, model, k=25, alpha=alpha, is_report_loss_diff=True, use_sample=False)\n",
        "  print(X.sum()/batch_size)\n",
        "  print(x_adv.sum()/batch_size)\n",
        "  print('***************************')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0MiPWLHR2th",
        "outputId": "293c61a8-4984-499f-ba34-322d6e3dd5b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "alpha =  1\n",
            "rFGSM: attack effectiveness 100.000%.\n",
            "tensor(28.0148)\n",
            "tensor(2289.4089)\n",
            "***************************\n",
            "alpha =  2\n",
            "rFGSM: attack effectiveness 100.000%.\n",
            "tensor(28.0148)\n",
            "tensor(577.0690)\n",
            "***************************\n",
            "alpha =  3\n",
            "rFGSM: attack effectiveness 100.000%.\n",
            "tensor(28.0148)\n",
            "tensor(185.2315)\n",
            "***************************\n",
            "alpha =  4\n",
            "rFGSM: attack effectiveness 95.567%.\n",
            "tensor(28.0148)\n",
            "tensor(71.5714)\n",
            "***************************\n",
            "alpha =  5\n",
            "rFGSM: attack effectiveness 1.478%.\n",
            "tensor(28.0148)\n",
            "tensor(28.0887)\n",
            "***************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def bca_k(x, y, model, k=25, is_report_loss_diff=True, use_sample=False):\n",
        "    \"\"\"\n",
        "    Multi-step bit coordinate ascent\n",
        "    :param use_sample:\n",
        "    :param is_report_loss_diff:\n",
        "    :param y:\n",
        "    :param x: (tensor) feature vector\n",
        "    :param model: nn model\n",
        "    :param k: num of steps\n",
        "    :return: the adversarial version of x according to bca_k (tensor)\n",
        "    \"\"\"\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    # Compute natural loss\n",
        "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "    loss_natural = criterion(model(x), y.view(-1).long())\n",
        "\n",
        "    # keeping worst loss\n",
        "    loss_worst = loss_natural.clone()\n",
        "    x_worst = x.clone()\n",
        "\n",
        "    # multi-step with gradients\n",
        "    loss = None\n",
        "    x_var = None\n",
        "    x_next = None\n",
        "    for t in range(k):\n",
        "        if t == 0:\n",
        "            # initialize starting point\n",
        "            x_next = get_x0(x, use_sample)\n",
        "        else:\n",
        "            # compute gradient\n",
        "            grad_vars = torch.autograd.grad(loss.mean(), x_var)\n",
        "            grad_data = grad_vars[0].data\n",
        "\n",
        "            # compute the updates (can be made more efficient than this)\n",
        "            aug_grad = (1. - 2. * x_next) * grad_data\n",
        "            val, _ = torch.topk(aug_grad, 1)\n",
        "            x_update = (aug_grad >= val.expand_as(aug_grad)).float()\n",
        "\n",
        "            # find the next sample with projection to the feasible set\n",
        "            x_next = xor_float_tensors(x_update, x_next)\n",
        "            x_next = or_float_tensors(x_next, x)\n",
        "\n",
        "        # forward pass\n",
        "        x_var = x_next.clone().detach().requires_grad_(True)\n",
        "        y_model = model(x_var)\n",
        "        loss = criterion(y_model, y.view(-1).long())\n",
        "\n",
        "        # update worst loss and adversarial samples\n",
        "        replace_flag = (loss.data > loss_worst)\n",
        "        loss_worst[replace_flag] = loss.data[replace_flag]\n",
        "        x_worst[replace_flag] = x_next[replace_flag]\n",
        "\n",
        "    if is_report_loss_diff:\n",
        "        #print(\"Natural loss (%.4f) vs Adversarial loss (%.4f), Difference: (%.4f)\" %(loss_natural.mean(), loss_worst.mean(), loss_worst.mean() - loss_natural.mean()))\n",
        "        outputs = model(x_worst)\n",
        "        _, predicted = torch.topk(outputs, k=1)\n",
        "        done = (predicted != y).squeeze()\n",
        "        print(f\"bca_k: attack effectiveness {done.sum().item() / x.size()[0] * 100:.3f}%.\")\n",
        "\n",
        "\n",
        "\n",
        "    return x_worst"
      ],
      "metadata": {
        "id": "l5w-UPPVeDe5"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XcHWWydFh1n0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_adv = bca_k(X, y, model, k=3, is_report_loss_diff=True, use_sample=False)\n",
        "print(X.sum()/batch_size)\n",
        "print(x_adv.sum()/batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZKn-cfefC4m",
        "outputId": "72215200-69ed-42d2-fafa-674a9d65cc0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bca_k: attack effectiveness 44.922%.\n",
            "tensor(26.6289)\n",
            "tensor(28.5430)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for k in range(5, 55, 5):\n",
        "  print('k = ',k)\n",
        "  x_adv = bca_k(X, y, model, k=k, is_report_loss_diff=True, use_sample=False)\n",
        "  print(X.sum()/batch_size)\n",
        "  print(x_adv.sum()/batch_size)\n",
        "  print('***************************')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knqrt4j9fcBp",
        "outputId": "44c53b1c-67e3-4af8-9de2-cd493ea83963"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "k =  5\n",
            "bca_k: attack effectiveness 91.406%.\n",
            "tensor(26.6289)\n",
            "tensor(30.5039)\n",
            "***************************\n",
            "k =  10\n",
            "bca_k: attack effectiveness 97.266%.\n",
            "tensor(26.6289)\n",
            "tensor(35.3906)\n",
            "***************************\n",
            "k =  15\n",
            "bca_k: attack effectiveness 97.266%.\n",
            "tensor(26.6289)\n",
            "tensor(40.2031)\n",
            "***************************\n",
            "k =  20\n",
            "bca_k: attack effectiveness 97.266%.\n",
            "tensor(26.6289)\n",
            "tensor(45.0078)\n",
            "***************************\n",
            "k =  25\n",
            "bca_k: attack effectiveness 97.266%.\n",
            "tensor(26.6289)\n",
            "tensor(49.8125)\n",
            "***************************\n",
            "k =  30\n",
            "bca_k: attack effectiveness 97.266%.\n",
            "tensor(26.6289)\n",
            "tensor(54.6172)\n",
            "***************************\n",
            "k =  35\n",
            "bca_k: attack effectiveness 97.266%.\n",
            "tensor(26.6289)\n",
            "tensor(59.4219)\n",
            "***************************\n",
            "k =  40\n",
            "bca_k: attack effectiveness 97.266%.\n",
            "tensor(26.6289)\n",
            "tensor(64.2266)\n",
            "***************************\n",
            "k =  45\n",
            "bca_k: attack effectiveness 97.266%.\n",
            "tensor(26.6289)\n",
            "tensor(69.0312)\n",
            "***************************\n",
            "k =  50\n",
            "bca_k: attack effectiveness 97.266%.\n",
            "tensor(26.6289)\n",
            "tensor(73.8359)\n",
            "***************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.rand((10,10000))\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HjDiJdVfjyL8",
        "outputId": "15778f2a-0553-4db1-82ee-3a7b46b0dc72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2620, 0.9656, 0.6516,  ..., 0.0038, 0.3084, 0.7131],\n",
              "        [0.5588, 0.2493, 0.0950,  ..., 0.9978, 0.9718, 0.1974],\n",
              "        [0.7188, 0.9575, 0.2771,  ..., 0.1128, 0.0172, 0.7418],\n",
              "        ...,\n",
              "        [0.0582, 0.2115, 0.6837,  ..., 0.8870, 0.7203, 0.6274],\n",
              "        [0.7887, 0.0591, 0.3733,  ..., 0.8148, 0.6377, 0.2545],\n",
              "        [0.6163, 0.1027, 0.4877,  ..., 0.8024, 0.8279, 0.1123]])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val, index = torch.topk(a, 10)"
      ],
      "metadata": {
        "id": "Yhh5P37vi8JE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val[:,-1:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4qsw0r3xjEXz",
        "outputId": "577b20d0-c66f-4a6b-936c-a26fc195c43f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.9994],\n",
              "        [0.9992],\n",
              "        [0.9989],\n",
              "        [0.9990],\n",
              "        [0.9992],\n",
              "        [0.9993],\n",
              "        [0.9993],\n",
              "        [0.9988],\n",
              "        [0.9993],\n",
              "        [0.9990]])"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def bca_k2(x, y, model, k=25, alpha=1, is_report_loss_diff=True, use_sample=False):\n",
        "    \"\"\"\n",
        "    Multi-step bit coordinate ascent\n",
        "    :param use_sample:\n",
        "    :param is_report_loss_diff:\n",
        "    :param y:\n",
        "    :param x: (tensor) feature vector\n",
        "    :param model: nn model\n",
        "    :param k: num of steps\n",
        "    :param alpha: top k gradients\n",
        "    :return: the adversarial version of x according to bca_k (tensor)\n",
        "    \"\"\"\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    # Compute natural loss\n",
        "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "    loss_natural = criterion(model(x), y.view(-1).long())\n",
        "\n",
        "    # keeping worst loss\n",
        "    loss_worst = loss_natural.clone()\n",
        "    x_worst = x.clone()\n",
        "\n",
        "    # multi-step with gradients\n",
        "    loss = None\n",
        "    x_var = None\n",
        "    x_next = None\n",
        "    for t in range(k):\n",
        "        if t == 0:\n",
        "            # initialize starting point\n",
        "            x_next = get_x0(x, use_sample)\n",
        "        else:\n",
        "            # compute gradient\n",
        "            grad_vars = torch.autograd.grad(loss.mean(), x_var)\n",
        "            grad_data = grad_vars[0].data\n",
        "\n",
        "            # compute the updates (can be made more efficient than this)\n",
        "            aug_grad = (1. - 2. * x_next) * grad_data\n",
        "            val, _ = torch.topk(aug_grad, alpha)\n",
        "            x_update = (aug_grad >= val[:,-1:].expand_as(aug_grad)).float()\n",
        "\n",
        "            # find the next sample with projection to the feasible set\n",
        "            x_next = xor_float_tensors(x_update, x_next)\n",
        "            x_next = or_float_tensors(x_next, x)\n",
        "\n",
        "        # forward pass\n",
        "        x_var = x_next.clone().detach().requires_grad_(True)\n",
        "        y_model = model(x_var)\n",
        "        loss = criterion(y_model, y.view(-1).long())\n",
        "\n",
        "        # update worst loss and adversarial samples\n",
        "        replace_flag = (loss.data > loss_worst)\n",
        "        loss_worst[replace_flag] = loss.data[replace_flag]\n",
        "        x_worst[replace_flag] = x_next[replace_flag]\n",
        "\n",
        "    if is_report_loss_diff:\n",
        "        #print(\"Natural loss (%.4f) vs Adversarial loss (%.4f), Difference: (%.4f)\" %(loss_natural.mean(), loss_worst.mean(), loss_worst.mean() - loss_natural.mean()))\n",
        "        outputs = model(x_worst)\n",
        "        _, predicted = torch.topk(outputs, k=1)\n",
        "        done = (predicted != y).squeeze()\n",
        "        print(f\"bca_k: attack effectiveness {done.sum().item() / x.size()[0] * 100:.3f}%.\")\n",
        "\n",
        "\n",
        "\n",
        "    return x_worst"
      ],
      "metadata": {
        "id": "ONJMTgcojcB1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for k in range(2, 9):\n",
        "  print('k = ',k)\n",
        "  x_adv = bca_k2(X, y, model, k=k, alpha=5, is_report_loss_diff=True, use_sample=False)\n",
        "  print(X.sum()/batch_size)\n",
        "  print(x_adv.sum()/batch_size)\n",
        "  print('***************************')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dP95NXQHkbLu",
        "outputId": "91c580de-01cb-4574-e75a-baefe2b6d9ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "k =  2\n",
            "bca_k: attack effectiveness 94.922%.\n",
            "tensor(26.6289)\n",
            "tensor(31.5430)\n",
            "***************************\n",
            "k =  3\n",
            "bca_k: attack effectiveness 99.609%.\n",
            "tensor(26.6289)\n",
            "tensor(36.5195)\n",
            "***************************\n",
            "k =  4\n",
            "bca_k: attack effectiveness 99.609%.\n",
            "tensor(26.6289)\n",
            "tensor(41.4805)\n",
            "***************************\n",
            "k =  5\n",
            "bca_k: attack effectiveness 99.609%.\n",
            "tensor(26.6289)\n",
            "tensor(46.4453)\n",
            "***************************\n",
            "k =  6\n",
            "bca_k: attack effectiveness 99.609%.\n",
            "tensor(26.6289)\n",
            "tensor(51.4102)\n",
            "***************************\n",
            "k =  7\n",
            "bca_k: attack effectiveness 99.609%.\n",
            "tensor(26.6289)\n",
            "tensor(56.3750)\n",
            "***************************\n",
            "k =  8\n",
            "bca_k: attack effectiveness 100.000%.\n",
            "tensor(26.6289)\n",
            "tensor(61.3477)\n",
            "***************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1, 12):\n",
        "  print('top k = ',i)\n",
        "  x_adv = bca_k2(X, y, model, k=2, alpha=i, is_report_loss_diff=True, use_sample=False)\n",
        "  print(X.sum()/batch_size)\n",
        "  print(x_adv.sum()/batch_size)\n",
        "  print('***************************')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7de41H0mq5B",
        "outputId": "277ee99e-b4a3-4fe6-c61f-bdaeae92d582"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "top k =  1\n",
            "bca_k: attack effectiveness 4.688%.\n",
            "tensor(26.6289)\n",
            "tensor(27.5664)\n",
            "***************************\n",
            "top k =  2\n",
            "bca_k: attack effectiveness 37.500%.\n",
            "tensor(26.6289)\n",
            "tensor(28.5508)\n",
            "***************************\n",
            "top k =  3\n",
            "bca_k: attack effectiveness 75.391%.\n",
            "tensor(26.6289)\n",
            "tensor(29.5352)\n",
            "***************************\n",
            "top k =  4\n",
            "bca_k: attack effectiveness 91.016%.\n",
            "tensor(26.6289)\n",
            "tensor(30.5430)\n",
            "***************************\n",
            "top k =  5\n",
            "bca_k: attack effectiveness 94.922%.\n",
            "tensor(26.6289)\n",
            "tensor(31.5430)\n",
            "***************************\n",
            "top k =  6\n",
            "bca_k: attack effectiveness 96.094%.\n",
            "tensor(26.6289)\n",
            "tensor(32.5391)\n",
            "***************************\n",
            "top k =  7\n",
            "bca_k: attack effectiveness 97.266%.\n",
            "tensor(26.6289)\n",
            "tensor(33.5234)\n",
            "***************************\n",
            "top k =  8\n",
            "bca_k: attack effectiveness 98.828%.\n",
            "tensor(26.6289)\n",
            "tensor(34.5195)\n",
            "***************************\n",
            "top k =  9\n",
            "bca_k: attack effectiveness 99.219%.\n",
            "tensor(26.6289)\n",
            "tensor(35.5078)\n",
            "***************************\n",
            "top k =  10\n",
            "bca_k: attack effectiveness 99.609%.\n",
            "tensor(26.6289)\n",
            "tensor(36.5039)\n",
            "***************************\n",
            "top k =  11\n",
            "bca_k: attack effectiveness 99.609%.\n",
            "tensor(26.6289)\n",
            "tensor(37.4961)\n",
            "***************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def grosse_k(x, y, model, k=25, is_report_loss_diff=True, use_sample=False):\n",
        "    \"\"\"\n",
        "    Multi-step bit coordinate ascent\n",
        "    :param use_sample:\n",
        "    :param is_report_loss_diff:\n",
        "    :param y:\n",
        "    :param x: (tensor) feature vector\n",
        "    :param model: nn model\n",
        "    :param k: num of steps\n",
        "    :return: the adversarial version of x according to bca_k (tensor)\n",
        "    \"\"\"\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    # Compute natural loss\n",
        "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "    loss_natural = criterion(model(x), y.view(-1).long())\n",
        "\n",
        "    # keeping worst loss\n",
        "    loss_worst = loss_natural.clone()\n",
        "    x_worst = x.clone()\n",
        "\n",
        "    # multi-step with gradients\n",
        "    output = None\n",
        "    x_var = None\n",
        "    x_next = None\n",
        "    for t in range(k):\n",
        "        if t == 0:\n",
        "            # initialize starting point\n",
        "            x_next = get_x0(x, use_sample)\n",
        "        else:\n",
        "            # compute gradient\n",
        "            # ouput.shape=([batch_size, 2]) because of 2 neoruns, so we just use the output of the first neorun(benign)\n",
        "            grad_vars = torch.autograd.grad(output[:, 0].mean(), x_var)\n",
        "            grad_data = grad_vars[0].data\n",
        "\n",
        "            # compute the updates (can be made more efficient than this)\n",
        "            aug_grad = (1. - x_next) * grad_data\n",
        "            val, _ = torch.topk(aug_grad, 1)\n",
        "            x_update = (aug_grad >= val.expand_as(aug_grad)).float()\n",
        "\n",
        "            # find the next sample with projection to the feasible set\n",
        "            x_next = xor_float_tensors(x_update, x_next)\n",
        "            x_next = or_float_tensors(x_next, x)\n",
        "\n",
        "        # forward pass\n",
        "        x_var = x_next.clone().detach().requires_grad_(True)\n",
        "        output = model(x_var)\n",
        "        loss = criterion(output, y.view(-1).long())\n",
        "\n",
        "        # update worst loss and adversarial samples\n",
        "        replace_flag = (loss.data > loss_worst)\n",
        "        loss_worst[replace_flag] = loss.data[replace_flag]\n",
        "        x_worst[replace_flag] = x_next[replace_flag]\n",
        "\n",
        "    if is_report_loss_diff:\n",
        "        #print(\"Natural loss (%.4f) vs Adversarial loss (%.4f), Difference: (%.4f)\" %(loss_natural.mean(), loss_worst.mean(), loss_worst.mean() - loss_natural.mean()))\n",
        "        outputs = model(x_worst)\n",
        "        _, predicted = torch.topk(outputs, k=1)\n",
        "        done = (predicted != y).squeeze()\n",
        "        print(f\"grosse_k: attack effectiveness {done.sum().item() / x.size()[0] * 100:.3f}%.\")\n",
        "\n",
        "\n",
        "\n",
        "    return x_worst"
      ],
      "metadata": {
        "id": "2jjbi-wHwYKz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grosse_k(X, y, model, k=25, is_report_loss_diff=True, use_sample=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "de8dsYkvxLz2",
        "outputId": "c82a724f-4476-45b7-8b5c-3d203d2a788b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "grosse_k: attack effectiveness 5.078%.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [1., 1., 1.,  ..., 1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pgd(x, y, model, k=25, step_length=0.02, norm='linf', initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False):\n",
        "    \"\"\"\n",
        "    Projected Gradient Descent (PGD) adversarial attack.\n",
        "    :param y: Ground truth labels\n",
        "    :param x: Feature vector\n",
        "    :param model: Neural network model\n",
        "    :param k: Number of steps\n",
        "    :param step_length: Step size for each iteration\n",
        "    :param norm: Norm used for perturbation ('linf' or 'l2')\n",
        "    :param initial_rounding_threshold: Threshold parameter for rounding the initial x_next\n",
        "    :param round_threshold: Threshold parameter for rounding\n",
        "    :param random: Flag to generate random thresholds\n",
        "    :param is_report_loss_diff: Flag to report loss difference\n",
        "    :param is_sample: Flag to sample randomly from the feasible area\n",
        "    :return: The adversarial version of x (tensor)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Compute natural loss\n",
        "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "    loss_natural = criterion(model(x), y.view(-1).long())\n",
        "\n",
        "    # Initialize starting point\n",
        "    x_next = x.clone()\n",
        "    x_next = get_x0(x_next, initial_rounding_threshold, is_sample)\n",
        "\n",
        "    # Multi-step PGD\n",
        "    for t in range(k):\n",
        "        # Forward pass\n",
        "        x_var = x_next.clone().detach().requires_grad_(True)\n",
        "        y_model = model(x_var)\n",
        "        loss = criterion(y_model, y.view(-1).long())\n",
        "\n",
        "        # Compute gradient\n",
        "        grad_vars = torch.autograd.grad(loss.mean(), x_var)\n",
        "        grad_data = grad_vars[0].data\n",
        "        gradients = grad_data * (x < 0.5)\n",
        "\n",
        "        # Norm\n",
        "        if norm == 'linf':\n",
        "            perturbation = torch.sign(gradients)\n",
        "        elif norm == 'l2':\n",
        "            l2norm = torch.linalg.norm(gradients, dim=-1, keepdim=True)\n",
        "            perturbation = torch.minimum(torch.tensor(1., dtype=x.dtype, device=x.device), gradients / l2norm)\n",
        "            perturbation[torch.isnan(perturbation)] = 0.\n",
        "            perturbation[torch.isinf(perturbation)] = 1.\n",
        "        elif norm == 'l1':\n",
        "            #ignore the gradient of indice which is updated\n",
        "            gradients = gradients * (x_next < 0.5)\n",
        "            val, _ = torch.topk(gradients, 1)\n",
        "            perturbation = torch.sign(gradients >= val.expand_as(gradients))\n",
        "            # stop perturbing the examples that are successful to evade the victim\n",
        "            outputs = model(x_next)\n",
        "            _, predicted = torch.topk(outputs, k=1)\n",
        "            done = (predicted != y).squeeze()\n",
        "            if torch.all(done):\n",
        "                break\n",
        "            perturbation[done] = 0.\n",
        "        else:\n",
        "            raise ValueError(\"Expect 'l1' or 'l2' or 'linf' norm.\")\n",
        "\n",
        "        # Update x_next\n",
        "        x_next = torch.clamp(x_next + perturbation * step_length, min=0., max=1.)\n",
        "\n",
        "    # Rounding step\n",
        "    if random:\n",
        "       round_threshold = torch.rand(x_next.size())\n",
        "    x_next = round_x(x_next, round_threshold=round_threshold)\n",
        "\n",
        "    # Feasible projection\n",
        "    x_next = or_float_tensors(x_next, x)\n",
        "\n",
        "    # Compute adversarial loss\n",
        "    loss_adv = criterion(model(x_next), y.view(-1).long()).data\n",
        "\n",
        "    if is_report_loss_diff:\n",
        "        outputs = model(x_next)\n",
        "        _, predicted = torch.topk(outputs, k=1)\n",
        "        done = (predicted != y).squeeze()\n",
        "        print(f\"PGD {norm}: Attack effectiveness {done.sum().item() / x.size()[0] * 100:.3f}%.\")\n",
        "\n",
        "    # Replace with natural if adversarial loss is higher\n",
        "    replace_flag = (loss_adv < loss_natural).squeeze()\n",
        "    x_next[replace_flag] = x[replace_flag]\n",
        "\n",
        "    return x_next\n"
      ],
      "metadata": {
        "id": "j0HTVirP5Gtq"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_adv = pgd(X, y, model, k=250, step_length=0.002, norm='linf', initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False)\n",
        "print(X.sum()/batch_size)\n",
        "print(x_adv.sum()/batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1vtfW4C-sXq",
        "outputId": "6cf2b900-8bad-4937-a88e-35a0723c0fa6"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PGD: Attack effectiveness 100.000%.\n",
            "tensor(26.6289)\n",
            "tensor(3903.8359)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_adv = pgd(X, y, model, k=200, step_length=0.05, norm='l2', initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False)\n",
        "print(X.sum()/batch_size)\n",
        "print(x_adv.sum()/batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMf1VtXg0nmP",
        "outputId": "3055332e-975e-40e3-9a21-1fa027d2fc13"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PGD l2: Attack effectiveness 93.359%.\n",
            "tensor(26.6289)\n",
            "tensor(35.3633)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_adv = pgd(X, y, model, k=227, step_length=0.05, norm='l2', initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False)\n",
        "print(X.sum()/batch_size)\n",
        "print(x_adv.sum()/batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cP1lR7xHCGbC",
        "outputId": "d0f03a73-0f15-47c0-92d7-74469f378ce4"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PGD: Attack effectiveness 98.438%.\n",
            "tensor(26.6289)\n",
            "tensor(44.4180)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_adv = pgd(X, y, model, k=50, step_length=1., norm='l1', initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False)\n",
        "print(X.sum()/batch_size)\n",
        "print(x_adv.sum()/batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nK611ZO4973",
        "outputId": "06bbc711-ef8f-4880-97a2-6067606f1264"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PGD: Attack effectiveness 100.000%.\n",
            "tensor(26.6289)\n",
            "tensor(29.4453)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_adv = bca_k(X, y, model, k=53, is_report_loss_diff=True, use_sample=False)\n",
        "print(X.sum()/batch_size)\n",
        "print(x_adv.sum()/batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2xuFvYHAI08",
        "outputId": "d3e1266f-4a76-42b7-f525-24569adf1069"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bca_k: attack effectiveness 97.266%.\n",
            "tensor(26.6289)\n",
            "tensor(76.7188)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = X\n",
        "steps_max=5\n",
        "attack_list = ['linf', 'l2', 'l1']\n",
        "is_sample = False\n",
        "varepsilon = 1e-20\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    loss, done = get_loss(x,y,model) #shape:[samples],[samples]\n",
        "pre_loss = loss\n",
        "n, red_n = x.shape[0], x.shape[1]\n",
        "adv_x = x.detach().clone()\n",
        "stop_flag = torch.zeros(n, dtype=torch.bool) #[samples]\n",
        "\n",
        "for t in range(steps_max):\n",
        "  num_sample_red = n - torch.sum(stop_flag)\n",
        "  print('num_sample_red : ',num_sample_red)\n",
        "  if num_sample_red <= 0:\n",
        "      break\n",
        "\n",
        "  red_label = y[~stop_flag]\n",
        "  pertbx = []\n",
        "\n",
        "\n",
        "  for norm in attack_list:\n",
        "      if norm=='l1':\n",
        "        l1 = pgd(adv_x[~stop_flag], red_label, model, k=50, step_length=1., norm='l1', is_sample=is_sample)\n",
        "        pertbx.append(l1)\n",
        "      elif norm=='l2':\n",
        "        l2 = pgd(adv_x[~stop_flag], red_label, model, k=200, step_length=0.05, norm='l2', is_sample=is_sample)\n",
        "        pertbx.append(l2)\n",
        "      elif norm=='linf':\n",
        "        linf = pgd(adv_x[~stop_flag], red_label, model, k=500, step_length=0.002, norm='linf', is_sample=is_sample)\n",
        "        pertbx.append(linf)\n",
        "      else :\n",
        "        raise ValueError(\"Expect 'l1' or 'l2' or 'linf' norm.\")\n",
        "\n",
        "  # here pertbx.shape = a list of (number of attacks  ,(num_sample_red,features))\n",
        "  pertbx = torch.vstack(pertbx)\n",
        "  # here pertbx.shape = a tensor (num_sample_red*number of attacks samples, features)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    red_label_ext = torch.cat([red_label] * len(attack_list)) #(labels*number of attacks )\n",
        "    loss, done = get_loss(pertbx, red_label_ext,model) #(labels*number of attacks )\n",
        "    loss = loss.reshape(len(attack_list), num_sample_red).permute(1, 0) #(num_sample_red,number of attacks)\n",
        "    done = done.reshape(len(attack_list), num_sample_red).permute(1, 0) #(num_sample_red,number of attacks)\n",
        "\n",
        "    success_flag = torch.any(done, dim=-1) #(num_sample_red)\n",
        "    # for a sample, if there is at least one successful attack, we will select the one with maximum loss;\n",
        "    # while if no attacks evade the victim successful, all perturbed examples are reminded for selection\n",
        "\n",
        "    done[~torch.any(done, dim=-1)] = 1 #loss.shape=done.shape=(samples,number of attacks)\n",
        "    loss = (loss * done.to(torch.float)) + torch.min(loss) * (~done).to(torch.float) #(num_sample_red,number of attacks)\n",
        "    pertbx = pertbx.reshape(len(attack_list), num_sample_red, red_n).permute([1, 0, 2])#(num_sample_red,attacks,features)\n",
        "    _, indices = loss.max(dim=-1) # ans:(samples), max loss among attacks which worked, and max loss among all attacks for sample , none of them worked\n",
        "    adv_x[~stop_flag] = pertbx[torch.arange(num_sample_red), indices]\n",
        "    a_loss = loss[torch.arange(num_sample_red), indices]\n",
        "    pre_stop_flag = stop_flag.clone()\n",
        "    stop_flag[~stop_flag] = (torch.abs(pre_loss[~stop_flag] - a_loss) < varepsilon) | success_flag\n",
        "    pre_loss[~pre_stop_flag] = a_loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGJYJzXD4k9T",
        "outputId": "3c5080ab-2d25-4af9-c420-ab9f0dd56ee5"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_sample_red :  tensor(256)\n",
            "PGD linf: Attack effectiveness 100.000%.\n",
            "PGD l2: Attack effectiveness 93.359%.\n",
            "PGD l1: Attack effectiveness 100.000%.\n",
            "num_sample_red :  tensor(0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.sum()/batch_size)\n",
        "print(adv_x.sum()/batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUdsQu-Swk3X",
        "outputId": "8ca09483-46c8-47c4-eb6a-fa51fd5eae3a"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(26.6289)\n",
            "tensor(5542.4414)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def PGD_Max(x,y, model, attack_list = ['linf', 'l2', 'l1'],steps_max=5, is_sample = False, varepsilon = 1e-20):\n",
        "    \"\"\"\n",
        "    PGD_Max adversarial attack.\n",
        "\n",
        "    Args:\n",
        "        x: Input data tensor (shape: [samples, features])\n",
        "        y: Ground truth labels tensor (shape: [samples])\n",
        "        model: Neural network model\n",
        "        attack_list: List of norms for attacks (default: ['linf', 'l2', 'l1'])\n",
        "        steps_max: Maximum number of steps (default: 5)\n",
        "        is_sample: Flag to sample randomly from the feasible area (default: False)\n",
        "        vaρεpsilon: Tolerance for stopping condition (default: 1e-20)\n",
        "\n",
        "    Returns:\n",
        "        Adversarial version of input data (tensor)\n",
        "    \"\"\"\n",
        "\n",
        "    norm_params = {\n",
        "        'l1': {'k': 50, 'step_length': 1.0},\n",
        "        'l2': {'k': 200, 'step_length': 0.05},\n",
        "        'linf': {'k': 500, 'step_length': 0.002}\n",
        "    }\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        loss, done = get_loss(x,y,model) #shape:[samples],[samples]\n",
        "\n",
        "    pre_loss = loss\n",
        "    n = x.shape[0]\n",
        "    adv_x = x.detach().clone()\n",
        "    stop_flag = torch.zeros(n, dtype=torch.bool) #[samples]\n",
        "\n",
        "    for t in range(steps_max):\n",
        "      num_remaining  = (~stop_flag).sum().item()\n",
        "      print('number of remaining samples : ',num_remaining )\n",
        "      if num_remaining  <= 0:\n",
        "          break\n",
        "\n",
        "      remaining_label = y[~stop_flag]\n",
        "      pertbx = []\n",
        "\n",
        "      for norm in attack_list:\n",
        "          if norm in norm_params:\n",
        "              params = norm_params[norm]\n",
        "              perturbation = pgd(adv_x[~stop_flag], remaining_label, model, norm=norm, is_sample=is_sample, **params)\n",
        "              print(\"the number of added features : \", perturbation.sum()/batch_size - adv_x[~stop_flag].sum()/batch_size)\n",
        "              pertbx.append(perturbation)\n",
        "          else:\n",
        "              raise ValueError(\"Expected 'l1' or 'l2' or 'linf' norm.\")\n",
        "\n",
        "\n",
        "      # here pertbx.shape = a list of (number of attacks  ,(num_remaining ,features))\n",
        "      pertbx = torch.vstack(pertbx)\n",
        "      # here pertbx.shape = a tensor (num_remaining *number of attacks samples, features)\n",
        "\n",
        "      with torch.no_grad():\n",
        "        remaining_label_ext = torch.cat([remaining_label] * len(attack_list)) #(labels*number of attacks )\n",
        "        loss, done = get_loss(pertbx, remaining_label_ext,model) #(labels*number of attacks )\n",
        "        loss = loss.reshape(len(attack_list), num_remaining ).permute(1, 0) #(num_remaining ,number of attacks)\n",
        "        done = done.reshape(len(attack_list), num_remaining ).permute(1, 0) #(num_remaining ,number of attacks)\n",
        "\n",
        "        success_flag = torch.any(done, dim=-1) #(num_remaining )\n",
        "        # for a sample, if there is at least one successful attack, we will select the one with maximum loss;\n",
        "        # while if no attacks evade the victim successful, all perturbed examples are reminded for selection\n",
        "\n",
        "        done[~torch.any(done, dim=-1)] = 1 #loss.shape=done.shape=(samples,number of attacks)\n",
        "        loss = (loss * done.to(torch.float)) + torch.min(loss) * (~done).to(torch.float) #(num_remaining ,number of attacks)\n",
        "        pertbx = pertbx.reshape(len(attack_list), num_remaining , x.shape[1]).permute([1, 0, 2])#(num_remaining ,attacks,features)\n",
        "        _, indices = loss.max(dim=-1) # ans:(samples), max loss among attacks which worked, and max loss among all attacks for sample , none of them worked\n",
        "        adv_x[~stop_flag] = pertbx[torch.arange(num_remaining ), indices]\n",
        "        a_loss = loss[torch.arange(num_remaining ), indices]\n",
        "        pre_stop_flag = stop_flag.clone()\n",
        "        stop_flag[~stop_flag] = (torch.abs(pre_loss[~stop_flag] - a_loss) < varepsilon) | success_flag\n",
        "        pre_loss[~pre_stop_flag] = a_loss\n",
        "\n",
        "    return adv_x"
      ],
      "metadata": {
        "id": "c589J_H1GcGf"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adv_x = PGD_Max(X,y, model)\n",
        "print(X.sum()/batch_size)\n",
        "print(adv_x.sum()/batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51E-dmFQ8QSa",
        "outputId": "9376079e-0dcc-437c-cb1a-081fc7aa7699"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of remaining samples :  256\n",
            "PGD linf: Attack effectiveness 100.000%.\n",
            "the number of added features :  tensor(5515.8125)\n",
            "PGD l2: Attack effectiveness 93.359%.\n",
            "the number of added features :  tensor(8.7344)\n",
            "PGD l1: Attack effectiveness 100.000%.\n",
            "the number of added features :  tensor(2.8164)\n",
            "number of remaining samples :  0\n",
            "tensor(26.6289)\n",
            "tensor(5542.4414)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pgd_step(x, y, model, norm, k, step_length):\n",
        "    \"\"\"\n",
        "    Projected Gradient Descent (PGD) adversarial attack for stepwise.\n",
        "    :param y: Ground truth labels\n",
        "    :param x: Feature vector\n",
        "    :param model: Neural network model\n",
        "    :param k: Number of steps\n",
        "    :param step_length: Step size for each iteration\n",
        "    :param norm: Norm used for perturbation ('linf' or 'l2')\n",
        "    :return: The adversarial version of x (tensor)(not rounded)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "\n",
        "    # Initialize starting point\n",
        "    x_next = x.clone()\n",
        "\n",
        "    # Multi-step PGD\n",
        "    for t in range(k):\n",
        "        # Forward pass\n",
        "        x_var = x_next.clone().detach().requires_grad_(True)\n",
        "        y_model = model(x_var)\n",
        "        loss = criterion(y_model, y.view(-1).long())\n",
        "\n",
        "        # Compute gradient\n",
        "        grad_vars = torch.autograd.grad(loss.mean(), x_var)\n",
        "        grad_data = grad_vars[0].data\n",
        "        gradients = grad_data * (x < 0.5)\n",
        "\n",
        "        # Norm\n",
        "        if norm == 'linf':\n",
        "            perturbation = torch.sign(gradients)\n",
        "        elif norm == 'l2':\n",
        "            l2norm = torch.linalg.norm(gradients, dim=-1, keepdim=True)\n",
        "            perturbation = torch.minimum(torch.tensor(1., dtype=x.dtype, device=x.device), gradients / l2norm)\n",
        "            perturbation[torch.isnan(perturbation)] = 0.\n",
        "            perturbation[torch.isinf(perturbation)] = 1.\n",
        "        elif norm == 'l1':\n",
        "            #ignore the gradient of indice which is updated\n",
        "            gradients = gradients * (x_next < 0.5)\n",
        "            val, _ = torch.topk(gradients, 1)\n",
        "            perturbation = torch.sign(gradients >= val.expand_as(gradients))\n",
        "            # stop perturbing the examples that are successful to evade the victim\n",
        "            outputs = model(x_next)\n",
        "            _, predicted = torch.topk(outputs, k=1)\n",
        "            done = (predicted != y).squeeze()\n",
        "            if torch.all(done):\n",
        "                break\n",
        "            perturbation[done] = 0.\n",
        "        else:\n",
        "            raise ValueError(\"Expect 'l1' or 'l2' or 'linf' norm.\")\n",
        "\n",
        "        # Update x_next\n",
        "        x_next = torch.clamp(x_next + perturbation * step_length, min=0., max=1.)\n",
        "\n",
        "    return x_next"
      ],
      "metadata": {
        "id": "GP2Fx9BOd-zx"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "step_checks = 1\n",
        "steps = 100\n",
        "is_attacker = False\n",
        "is_score_round = False\n",
        "use_random = False\n",
        "round_threshold = 0.5\n",
        "x = X\n",
        "label = y\n",
        "attack_list = ['linf', 'l2', 'l1']\n",
        "norm_params = {\n",
        "    'l1': {'step_length': 1.0},\n",
        "    'l2': {'step_length': 0.05},\n",
        "    'linf': {'step_length': 0.002}\n",
        "}\n",
        "\n",
        "model.eval()\n",
        "if not is_attacker:\n",
        "    step_checks = [1, 10, 25, 50]\n",
        "    step_check = random.choice(step_checks)\n",
        "mini_steps = [step_check] * (steps // step_check)\n",
        "mini_steps = mini_steps + [steps % step_check] if steps % step_check != 0 else mini_steps\n",
        "\n",
        "print('mini steps = ', mini_steps)\n",
        "\n",
        "n, red_n = x.size()[0], x.size()[1]\n",
        "adv_x = x.detach().clone()\n",
        "pert_x_cont = None\n",
        "prev_done = None\n",
        "for i, mini_step in enumerate(mini_steps):\n",
        "    with torch.no_grad():\n",
        "        if i == 0 :\n",
        "            adv_x = get_x0(adv_x, initial_rounding_threshold=round_threshold, is_sample=use_random)\n",
        "\n",
        "        _, done = get_loss(adv_x, label, model)\n",
        "    if torch.all(done):\n",
        "        break\n",
        "    if i == 0:\n",
        "        adv_x[~done] = x[~done]  # recompute the perturbation under other penalty factors\n",
        "        prev_done = done\n",
        "    else:\n",
        "        adv_x[~done] = pert_x_cont[~done[~prev_done]]\n",
        "        prev_done = done\n",
        "\n",
        "    num_sample_red = torch.sum(~done).item()\n",
        "    pertbx = []\n",
        "    for norm in attack_list:\n",
        "        params = norm_params[norm]\n",
        "        perturbation = pgd_step(adv_x[~done], label[~done], model, norm=norm, k=mini_step, **params)\n",
        "        print(\"the number of added features(not rounded) \", norm,\": \", perturbation.sum()/len(adv_x[~done]) - adv_x[~done].sum()/len(adv_x[~done]))\n",
        "        pertbx.append(perturbation)\n",
        "    with torch.no_grad():\n",
        "        n_attacks = len(pertbx)\n",
        "        pertbx = torch.vstack(pertbx)\n",
        "        label_ext = torch.cat([label[~done]] * n_attacks)\n",
        "        if (not is_attacker) and (not is_score_round):\n",
        "            scores, _done = get_loss(pertbx, label_ext,model)\n",
        "        else:\n",
        "            scores, _done = get_loss(round_x(pertbx, round_threshold), label_ext, model)\n",
        "        max_v = scores.amax() if scores.amax() > 0 else 0.\n",
        "        scores[_done] += max_v\n",
        "        pertbx = pertbx.reshape(n_attacks, num_sample_red, red_n).permute([1, 0, 2])\n",
        "        scores = scores.reshape(n_attacks, num_sample_red).permute(1, 0)\n",
        "        _2, s_idx = scores.max(dim=-1)\n",
        "        pert_x_cont = pertbx[torch.arange(num_sample_red), s_idx]\n",
        "        adv_x[~done] = pert_x_cont if not is_attacker else round_x(pert_x_cont, round_threshold)\n",
        "\n",
        "\n",
        "if is_attacker:\n",
        "    adv_x = round_x(adv_x, round_threshold)\n",
        "with torch.no_grad():\n",
        "    _, done = get_loss(adv_x, label, model)\n",
        "    print(f\"step-wise max: attack effectiveness {done.sum().item() / done.size()[0] * 100:.3f}%.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73VMOF6xUqji",
        "outputId": "659f1dd7-abf5-4b25-9b72-c4e6c8f50db5"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mini steps =  [50, 50]\n",
            "the number of added features(not rounded)  linf :  tensor(539.6423)\n",
            "the number of added features(not rounded)  l2 :  tensor(116.0846)\n",
            "the number of added features(not rounded)  l1 :  tensor(2.8275)\n",
            "step-wise max: attack effectiveness 100.000%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def StepwiseMax(\n",
        "    x,\n",
        "    label,\n",
        "    model,\n",
        "    attack_list=[\"linf\", \"l2\", \"l1\"],\n",
        "    step_lengths={\"l1\": 1.0, \"l2\": 0.05, \"linf\": 0.002},\n",
        "    steps=100,\n",
        "    random_start=False,\n",
        "    round_threshold=0.5,\n",
        "    is_attacker=False,\n",
        "):\n",
        "  \"\"\"\n",
        "    Stepwise max attack (mixture of pgd-l1, pgd-l2, pgd-linf).\n",
        "\n",
        "    Args:\n",
        "        x: Input data tensor (shape: [batch_size, feature_dim])\n",
        "        label: Ground truth labels tensor (shape: [batch_size])\n",
        "        model: Victim model\n",
        "        attack_list: List of attack norms (default: [\"linf\", \"l2\", \"l1\"])\n",
        "        step_lengths: Dictionary mapping norm to its step length (default: {\"l1\": 1.0, \"l2\": 0.05, \"linf\": 0.002})\n",
        "        steps: Maximum number of iterations (default: 100)\n",
        "        random_start: Use random starting point (default: False)\n",
        "        round_threshold: Threshold for rounding real scalars (default: 0.5)\n",
        "        is_attacker: Play the role of attacker (default: False)\n",
        "\n",
        "    Returns:\n",
        "        Adversarial examples tensor (same shape as x)\n",
        "  \"\"\"\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  step_check = 1\n",
        "  if not is_attacker:\n",
        "      step_checks = [1, 10, 25, 50]\n",
        "      step_check = random.choice(step_checks)\n",
        "      print(f\"Step check: {step_check}\")\n",
        "\n",
        "  mini_steps = [step_check] * (steps // step_check)\n",
        "  if steps % step_check != 0:\n",
        "      mini_steps.append(steps % step_check)\n",
        "\n",
        "  n, red_n = x.shape\n",
        "  adv_x = x.detach().clone()\n",
        "  pert_x_cont = None\n",
        "  prev_done = None\n",
        "  for i, mini_step in enumerate(mini_steps):\n",
        "      with torch.no_grad():\n",
        "          if i == 0 :\n",
        "              adv_x = get_x0(adv_x, initial_rounding_threshold=round_threshold, is_sample=random_start)\n",
        "\n",
        "          _, done = get_loss(adv_x, label, model)\n",
        "      if torch.all(done):\n",
        "          break\n",
        "      if i == 0:\n",
        "          adv_x[~done] = x[~done]  # recompute the perturbation under other penalty factors\n",
        "          prev_done = done\n",
        "      else:\n",
        "          adv_x[~done] = pert_x_cont[~done[~prev_done]]\n",
        "          prev_done = done\n",
        "\n",
        "      num_sample_red = torch.sum(~done).item()\n",
        "      pertbx = []\n",
        "      for norm in attack_list:\n",
        "          step_length = step_lengths.get(norm, step_lengths[\"l1\"])\n",
        "          perturbation = pgd_step(adv_x[~done], label[~done], model, norm, mini_step, step_length)\n",
        "          pertbx.append(perturbation)\n",
        "      with torch.no_grad():\n",
        "          pertbx = torch.vstack(pertbx)\n",
        "\n",
        "          n_attacks = len(attack_list)\n",
        "          label_ext = torch.cat([label[~done]] * n_attacks)\n",
        "\n",
        "          if (not is_attacker) and (not is_score_round):\n",
        "              scores, _done = get_loss(pertbx, label_ext,model)\n",
        "          else:\n",
        "              scores, _done = get_loss(round_x(pertbx, round_threshold), label_ext, model)\n",
        "          max_v = scores.amax() if scores.amax() > 0 else 0.\n",
        "          scores[_done] += max_v\n",
        "\n",
        "          pertbx = pertbx.reshape(n_attacks, num_sample_red, red_n).permute([1, 0, 2])\n",
        "          scores = scores.reshape(n_attacks, num_sample_red).permute(1, 0)\n",
        "          _2, s_idx = scores.max(dim=-1)\n",
        "          pert_x_cont = pertbx[torch.arange(num_sample_red), s_idx]\n",
        "          adv_x[~done] = pert_x_cont if not is_attacker else round_x(pert_x_cont, round_threshold)\n",
        "\n",
        "\n",
        "  if is_attacker:\n",
        "      adv_x = round_x(adv_x, round_threshold)\n",
        "  with torch.no_grad():\n",
        "      _, done = get_loss(adv_x, label, model)\n",
        "      print(f\"step-wise max: attack effectiveness {done.sum().item() / done.size()[0] * 100:.3f}%.\")\n",
        "\n",
        "  return adv_x"
      ],
      "metadata": {
        "id": "1x4bXgnCqSxz"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adv_x = StepwiseMax(X, y, model)\n",
        "print(X.sum()/batch_size)\n",
        "print(adv_x.sum()/batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exsYBHXXBm7k",
        "outputId": "014038aa-cf5a-4929-d57f-661ae34925fb"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step check: 1\n",
            "step-wise max: attack effectiveness 100.000%.\n",
            "tensor(26.6289)\n",
            "tensor(46.9497)\n"
          ]
        }
      ]
    }
  ]
}