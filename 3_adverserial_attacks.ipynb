{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMUYUp6nhdT6lZOipktOq5C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mostafa-ja/mal_adv3/blob/main/3_adverserial_attacks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy import sparse\n",
        "import gdown\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "JKDdI3K9LrlF"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "download_link = 'https://drive.google.com/uc?id=12iud4h19CZst4exbr3U2A9iDxBYvZ5U_'\n",
        "output_filepath = '/content/'\n",
        "gdown.download(download_link, output_filepath)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "0C770BMnLop2",
        "outputId": "58bb1666-ae23-4496-ab8b-9fba02d701b5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=12iud4h19CZst4exbr3U2A9iDxBYvZ5U_\n",
            "From (redirected): https://drive.google.com/uc?id=12iud4h19CZst4exbr3U2A9iDxBYvZ5U_&confirm=t&uuid=2cb9bb58-3da5-4697-ba66-610e9a01509b\n",
            "To: /content/X_redefined_sparse_matrix.npz\n",
            "100%|██████████| 2.31M/2.31M [00:00<00:00, 110MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/X_redefined_sparse_matrix.npz'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "download_link = 'https://drive.google.com/uc?id=1IhrcT3jHqlPrw2KvQ5vJkBgozxcJ1cJm'\n",
        "output_filepath = '/content/'\n",
        "gdown.download(download_link, output_filepath)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "y3O3o6ZHLpI8",
        "outputId": "50f3e15b-95a0-40b4-9b71-1143fbcad97d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1IhrcT3jHqlPrw2KvQ5vJkBgozxcJ1cJm\n",
            "To: /content/labels.pt\n",
            "100%|██████████| 517k/517k [00:00<00:00, 87.8MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/labels.pt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "download_link = 'https://drive.google.com/uc?id=13o5n06UpMDOhtk4u7B_RBSWa3kiiGXFs'\n",
        "output_filepath = '/content/'\n",
        "gdown.download(download_link, output_filepath)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "secibICoPRke",
        "outputId": "1d9577e6-3f7a-49e4-ea76-13d940747987"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=13o5n06UpMDOhtk4u7B_RBSWa3kiiGXFs\n",
            "To: /content/DNN_params.pth\n",
            "100%|██████████| 8.17M/8.17M [00:00<00:00, 109MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/DNN_params.pth'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "download_link = 'https://drive.google.com/uc?id=1PxFOLBnQAlX-EOsqkhGCSd1T3ykAD0-4'\n",
        "output_filepath = '/content/'\n",
        "gdown.download(download_link, output_filepath)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "3kpiyKpDG3Fm",
        "outputId": "a41a2e59-8c40-405f-dbe6-7c2faddc5cd4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1PxFOLBnQAlX-EOsqkhGCSd1T3ykAD0-4\n",
            "To: /content/vocab.pkl\n",
            "100%|██████████| 9.18M/9.18M [00:00<00:00, 92.6MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/vocab.pkl'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dictionary from the file\n",
        "with open('vocab.pkl', 'rb') as f:\n",
        "    vocab = pickle.load(f)\n",
        "\n",
        "for i, (key, value) in enumerate(vocab.items()):\n",
        "    print((key, value))\n",
        "    if i >= 5:\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0rDH5Q6HOmd",
        "outputId": "dd74079e-96a6-4c85-a8c3-a4ac10d471ed"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('android/media/mediaplayer->start', 141045)\n",
            "('android/app/activity->setcontentview', 140900)\n",
            "('android/os/vibrator->cancel', 141093)\n",
            "('android.permission.vibrate', 140720)\n",
            "('android.hardware.touchscreen', 137091)\n",
            "('android.intent.action.main', 138335)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "X_redefined = sparse.load_npz(\"X_redefined_sparse_matrix.npz\")\n",
        "labels_tensor = torch.load('labels.pt')"
      ],
      "metadata": {
        "id": "qHe1GZxX-ET4"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into train, validation, and test sets with stratified sampling\n",
        "X_train_val, X_test, labels_train_val, labels_test = train_test_split(X_redefined, labels_tensor, test_size=0.2, stratify=labels_tensor, random_state=42)\n",
        "X_train, X_val, labels_train, labels_val = train_test_split(X_train_val, labels_train_val, test_size=0.2, stratify=labels_train_val, random_state=42)\n",
        "\n",
        "# Combine features and labels into datasets\n",
        "train_dataset = TensorDataset(torch.tensor(X_train.toarray(), dtype=torch.float32), labels_train)\n",
        "val_dataset = TensorDataset(torch.tensor(X_val.toarray(), dtype=torch.float32), labels_val)\n",
        "test_dataset = TensorDataset(torch.tensor(X_test.toarray(), dtype=torch.float32), labels_test)\n"
      ],
      "metadata": {
        "id": "V8SALqiV-zFj"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the DataLoader for training, validation, and test sets\n",
        "batch_size = 256\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "g3BUXjXdZ9wq"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class MalwareDetectionModel(nn.Module):\n",
        "    def __init__(self, input_size=10000, hidden_1_size=200, hidden_2_size=200, num_labels=2, dropout_prob=0.6):\n",
        "        super(MalwareDetectionModel, self).__init__()\n",
        "\n",
        "        self.input_size = input_size\n",
        "        self.hidden_1_size = hidden_1_size\n",
        "        self.hidden_2_size = hidden_2_size\n",
        "        self.num_labels = num_labels\n",
        "        self.dropout_prob = dropout_prob\n",
        "\n",
        "        self.fc1 = nn.Linear(input_size, hidden_1_size)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.dropout1 = nn.Dropout(dropout_prob)\n",
        "        self.fc2 = nn.Linear(hidden_1_size, hidden_2_size)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.dropout2 = nn.Dropout(dropout_prob)\n",
        "        self.fc3 = nn.Linear(hidden_2_size, num_labels)\n",
        "        self.log_softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.dropout1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc3(x)\n",
        "        x = self.log_softmax(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "xdNbTvxTTqyw"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of your model\n",
        "model = MalwareDetectionModel()\n",
        "\n",
        "# Load model parameters\n",
        "model.load_state_dict(torch.load('DNN_params.pth'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZs3fmmZ-4PM",
        "outputId": "93eb4a52-aae6-45c6-f102-be7d9df61372"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X,y = next(iter(test_loader))\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91tjptrSb5qi",
        "outputId": "0b48569e-f1f7-4d10-9e05-194526408497"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([256, 10000])\n",
            "torch.Size([256, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "delta = torch.zeros_like(X, requires_grad=True)\n",
        "for t in range(25):\n",
        "    loss = nn.CrossEntropyLoss()(model(X + delta), y.view(-1).long())\n",
        "    loss.backward()\n",
        "    gradients = delta.grad.detach().sign() * (X < 0.5)\n",
        "    delta.data = (delta + 0.02*delta.grad.detach().sign()).clamp(0.,1.)\n",
        "    print(delta.data[0])\n",
        "    delta.grad.zero_()"
      ],
      "metadata": {
        "id": "zm0rMEm2BdZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def round_x(x, alpha=0.5):\n",
        "    \"\"\"\n",
        "    rounds x by thresholding it according to alpha which can be a scalar or vector\n",
        "    :param x:\n",
        "    :param alpha: threshold parameter\n",
        "    :return: a double tensor of 0s and 1s.\n",
        "    \"\"\"\n",
        "    return (x >= alpha).float()\n",
        "\n",
        "\n",
        "def get_x0(x, rounding_threshold=0.5, is_sample=False):\n",
        "    \"\"\"\n",
        "    Helper function to randomly initialize the the inner maximizer algos\n",
        "    randomize such that the functionality is preserved.\n",
        "    Functionality is preserved by maintaining the features present in x\n",
        "\n",
        "    https://github.com/ALFA-group/robust-adv-malware-detection/\n",
        "\n",
        "    :param x: training sample\n",
        "    :param is_sample: flag to sample randomly from feasible area or return just x\n",
        "    :return: randomly sampled feasible version of x\n",
        "    \"\"\"\n",
        "    if is_sample:\n",
        "        rand_x = round_x(torch.rand(x.size()), alpha=rounding_threshold)\n",
        "        if x.is_cuda:\n",
        "            rand_x = rand_x.cuda()\n",
        "        return (rand_x.byte() | x.byte()).float()\n",
        "    else:\n",
        "        return x\n",
        "\n",
        "\n",
        "def or_float_tensors(x_1, x_2):\n",
        "    \"\"\"\n",
        "    ORs two float tensors by converting them to byte and back\n",
        "    Note that byte() takes the first 8 bit after the decimal point of the float\n",
        "    e.g., 0.0 ==> 0\n",
        "          0.1 ==> 0\n",
        "          1.1 ==> 1\n",
        "        255.1 ==> 255\n",
        "        256.1 ==> 0\n",
        "    Subsequently the purpose of this function is to map 1s float tensors to 1\n",
        "    and those of 0s to 0. I.e., it is meant to be used on tensors of 0s and 1s.\n",
        "\n",
        "    :param x_1: tensor one\n",
        "    :param x_2: tensor two\n",
        "    :return: float tensor of 0s and 1s.\n",
        "    \"\"\"\n",
        "    return (x_1.byte() | x_2.byte()).float()\n",
        "\n",
        "\n",
        "def xor_float_tensors(x_1, x_2):\n",
        "    \"\"\"\n",
        "    XORs two float tensors by converting them to byte and back\n",
        "    Note that byte() takes the first 8 bit after the decimal point of the float\n",
        "    e.g., 0.0 ==> 0\n",
        "          0.1 ==> 0\n",
        "          1.1 ==> 1\n",
        "        255.1 ==> 255\n",
        "        256.1 ==> 0\n",
        "    Subsequently the purpose of this function is to map 1s float tensors to 1\n",
        "    and those of 0s to 0. I.e., it is meant to be used on tensors of 0s and 1s.\n",
        "\n",
        "    :param x_1: tensor one\n",
        "    :param x_2: tensor two\n",
        "    :return: float tensor of 0s and 1s.\n",
        "    \"\"\"\n",
        "    return (x_1.byte() ^ x_2.byte()).float()\n",
        "\n",
        "def get_loss(model, adv_x, label):\n",
        "    \"\"\"\n",
        "    Compute the loss and prediction correctness.\n",
        "\n",
        "    Parameters:\n",
        "    - model: torch.nn.Module, a victim model\n",
        "    - adv_x: torch.FloatTensor, the adversarially perturbed input samples\n",
        "    - label: torch.LongTensor, ground truth labels\n",
        "\n",
        "    Returns:\n",
        "    - loss_no_reduction: torch.FloatTensor, the computed loss without reduction\n",
        "    - done: torch.BoolTensor, a tensor indicating if the prediction is incorrect\n",
        "    \"\"\"\n",
        "    y_prob = model(adv_x)\n",
        "    loss_no_reduction = nn.BCELoss(reduction='none')(y_prob, label)\n",
        "    y_pred = (y_prob >= 0.5).float()  # Threshold at 0.5\n",
        "    done = (y_pred != label).squeeze()\n",
        "\n",
        "    return loss_no_reduction, done"
      ],
      "metadata": {
        "id": "XCbqeJ84gfDD"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epsilon = 0.02\n",
        "k = 25\n",
        "alpha = 0.5\n",
        "\n",
        "model.eval()\n",
        "# compute natural loss\n",
        "loss_natural = nn.CrossEntropyLoss(reduction='none')(model(X), y.view(-1).long())\n",
        "\n",
        "# initialize starting point\n",
        "x_next = X.clone()\n",
        "x_next = get_x0(x_next)\n",
        "\n",
        "# multi-step\n",
        "for t in range(k):\n",
        "    # forward pass\n",
        "    x_var = torch.tensor(x_next, requires_grad=True)\n",
        "    y_model = model(x_var)\n",
        "    loss = nn.CrossEntropyLoss()(y_model, y.view(-1).long())\n",
        "\n",
        "    # compute gradient\n",
        "    grad_vars = torch.autograd.grad(loss.mean(), x_var)\n",
        "\n",
        "    # find the next sample\n",
        "    x_next = x_next + epsilon * torch.sign(grad_vars[0].data)\n",
        "\n",
        "    # projection\n",
        "    x_next = torch.clamp(x_next, min=0., max=1.)\n",
        "\n",
        "# rounding step\n",
        "x_next = round_x(x_next, alpha=alpha)\n",
        "\n",
        "# feasible projection\n",
        "x_next = or_float_tensors(x_next, X)\n",
        "\n",
        "# compute adversarial loss\n",
        "loss_adv = nn.CrossEntropyLoss(reduction='none')(model(x_next), y.view(-1).long()).data\n",
        "\n",
        "\n",
        "print(\"Natural loss (%.4f) vs Adversarial loss (%.4f), Difference: (%.4f)\" %(loss_natural.mean(), loss_adv.mean(), loss_adv.mean() - loss_natural.mean()))\n",
        "\n",
        "replace_flag = (loss_adv < loss_natural).squeeze()\n",
        "x_next[replace_flag] = X[replace_flag]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgruUyrLDNmT",
        "outputId": "d2ddd018-feb9-4d5a-987e-24ddde75db28"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-32-e777b9fae05e>:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x_var = torch.tensor(x_next, requires_grad=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Natural loss (0.0060) vs Adversarial loss (2221.2881), Difference: (2221.2820)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model(x_next)\n",
        "_, predicted = torch.topk(outputs, k=1)"
      ],
      "metadata": {
        "id": "xEwDi86zGhCQ"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(predicted != y).squeeze()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBo0yRqjGjsC",
        "outputId": "eb88604d-7713-45ee-a84e-a2e3e0b2060f"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
              "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
              "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
              "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
              "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
              "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
              "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
              "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
              "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
              "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
              "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
              "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
              "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
              "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
              "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
              "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
              "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
              "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
              "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
              "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
              "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
              "        True, True, True, True])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "def dfgsm_k(x, y, model, k=25, epsilon=0.02, alpha=0.5, is_report_loss_diff=True, is_sample=False):\n",
        "    \"\"\"\n",
        "    FGSM^k with deterministic rounding\n",
        "    :param y: ground truth labels\n",
        "    :param x: feature vector\n",
        "    :param model: neural network model\n",
        "    :param k: number of steps\n",
        "    :param epsilon: update value in each direction\n",
        "    :param alpha: threshold parameter for rounding\n",
        "    :param is_report_loss_diff: flag to report loss difference\n",
        "    :param is_sample: flag to sample randomly from the feasible area\n",
        "    :return: the adversarial version of x according to dfgsm_k (tensor)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Compute natural loss\n",
        "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "    loss_natural = criterion(model(x), y.view(-1).long())\n",
        "\n",
        "    # Initialize starting point\n",
        "    x_next = x.clone()\n",
        "    x_next = get_x0(x_next, is_sample)\n",
        "\n",
        "    # Multi-step\n",
        "    for t in range(k):\n",
        "        # Forward pass\n",
        "        x_var = x_next.clone().detach().requires_grad_(True)\n",
        "        y_model = model(x_var)\n",
        "        loss = criterion(y_model, y.view(-1).long())\n",
        "\n",
        "        # Compute gradient\n",
        "        grad_vars = torch.autograd.grad(loss.mean(), x_var)\n",
        "\n",
        "        # Find the next sample\n",
        "        x_next = x_next + epsilon * torch.sign(grad_vars[0].data)\n",
        "\n",
        "        # Projection\n",
        "        x_next = torch.clamp(x_next, min=0., max=1.)\n",
        "\n",
        "    # Rounding step\n",
        "    x_next = round_x(x_next, alpha=alpha)\n",
        "\n",
        "    # Feasible projection\n",
        "    x_next = or_float_tensors(x_next, x)\n",
        "\n",
        "    # Compute adversarial loss\n",
        "    loss_adv = criterion(model(x_next), y.view(-1).long()).data\n",
        "\n",
        "    if is_report_loss_diff:\n",
        "        print(f\"Natural loss: {loss_natural.mean():.4f}, Adversarial loss: {loss_adv.mean():.4f}, Difference: {(loss_adv.mean() - loss_natural.mean()):.4f}\")\n",
        "        outputs = model(x_next)\n",
        "        _, predicted = torch.topk(outputs, k=1)\n",
        "        done = (predicted != y).squeeze()\n",
        "        print(f\"rFGSM: attack effectiveness {done.sum().item() / x.size()[0] * 100:.3f}%.\")\n",
        "\n",
        "    # Replace with natural if adversarial loss is higher\n",
        "    replace_flag = (loss_adv < loss_natural).squeeze()\n",
        "    x_next[replace_flag] = x[replace_flag]\n",
        "\n",
        "    return x_next\n"
      ],
      "metadata": {
        "id": "H6BiF-vCHLlH"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfgsm_k(X,y,model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X10_IhqiAZSB",
        "outputId": "6c867b1d-74b5-4b32-8b84-a3b717c3d380"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Natural loss: 0.0060, Adversarial loss: 2221.2881, Difference: 2221.2820\n",
            "rFGSM: attack effectiveness 100.000%.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 1., 1.,  ..., 0., 0., 0.],\n",
              "        [0., 1., 1.,  ..., 0., 0., 0.],\n",
              "        [0., 1., 1.,  ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
              "        [0., 1., 1.,  ..., 0., 0., 0.],\n",
              "        [1., 1., 1.,  ..., 0., 1., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class RFGSM():\n",
        "    \"\"\"\n",
        "    FGSM^k with randomized rounding\n",
        "\n",
        "    Parameters\n",
        "    ---------\n",
        "    @param is_attacker, Boolean, if ture means the role is the attacker\n",
        "    @param oblivion, Boolean, whether know the adversary indicator or not\n",
        "    @param kappa, attack confidence on adversary indicator\n",
        "    @param manipulation_x, manipulations\n",
        "    @param omega, the indices of interdependent apis corresponding to each api\n",
        "    @param device, 'cpu' or 'cuda'\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, random=False, device=None):\n",
        "        super(RFGSM, self).__init__()\n",
        "        self.device = device\n",
        "        self.random = random\n",
        "\n",
        "    def _perturb(self, model, x, label=None,\n",
        "                 steps=10,\n",
        "                 step_length=0.02,\n",
        "                 lmda=1.,\n",
        "                 use_sample=False):\n",
        "        \"\"\"\n",
        "        perturb node feature vectors\n",
        "\n",
        "        Parameters\n",
        "        -----------\n",
        "        @param model, a victim model\n",
        "        @param x: torch.FloatTensor, feature vectors with shape [batch_size, vocab_dim]\n",
        "        @param label: torch.LongTensor, ground truth labels\n",
        "        @param steps: Integer, maximum number of iterations\n",
        "        @param step_length: Integer, update value in each direction\n",
        "        @param lmda, float, penalty factor for balancing the importance of adversary detector\n",
        "        @param use_sample, Boolean, whether use random start point\n",
        "        \"\"\"\n",
        "\n",
        "        adv_x = x.clone()\n",
        "        model.eval()\n",
        "        adv_x = get_x0(adv_x, rounding_threshold=0.5, is_sample=use_sample)\n",
        "        loss_natural = 0.\n",
        "        for t in range(steps):\n",
        "            var_adv_x = torch.autograd.Variable(adv_x, requires_grad=True)\n",
        "            loss, done = get_loss(model, var_adv_x, label)\n",
        "            print(loss)\n",
        "            if t == 0:\n",
        "                loss_natural = loss\n",
        "            print(torch.autograd.grad(loss.mean(), var_adv_x)[0].shape)\n",
        "            grad = torch.autograd.grad(loss.mean(), var_adv_x)[0].data\n",
        "\n",
        "            # filtering un-considered graphs & positions\n",
        "            grad4insertion = (grad > 0) * grad * (adv_x <= 0.5)\n",
        "            grad4ins_ = grad4insertion.reshape(x.shape[0], -1)\n",
        "            print(torch.sign(grad4ins_)[0])\n",
        "            # find the next sample\n",
        "            adv_x = torch.clamp(adv_x + step_length * torch.sign(grad4ins_), min=0., max=1.)\n",
        "        print(adv_x[0])\n",
        "        # select adv x\n",
        "        if self.random:\n",
        "            round_threshold = torch.rand(adv_x.size()).to(self.device)\n",
        "        else:\n",
        "            round_threshold = 0.5\n",
        "\n",
        "        adv_x = (adv_x >= round_threshold).float()\n",
        "        # feasible projection\n",
        "        adv_x = or_tensors(adv_x, x)\n",
        "        # The below line is different from official codes because it is challenging to design a proper score measurement\n",
        "        loss_adv, _1 = get_loss(model, adv_x, label)\n",
        "        replace_flag = (loss_adv < loss_natural).squeeze()\n",
        "        adv_x[replace_flag] = x[replace_flag]\n",
        "        return adv_x\n",
        "\n",
        "    def perturb(self, model, x, label=None,\n",
        "                steps=10,\n",
        "                step_length=0.02,\n",
        "                min_lambda_=1e-5,\n",
        "                max_lambda_=1e5,\n",
        "                base=10.,\n",
        "                verbose=False,\n",
        "                use_sample=False):\n",
        "        \"\"\"\n",
        "        enhance attack\n",
        "        \"\"\"\n",
        "        assert 0 < min_lambda_ <= max_lambda_\n",
        "        model.eval()\n",
        "        if hasattr(model, 'is_detector_enabled'):\n",
        "            self.lmba = min_lambda_\n",
        "        else:\n",
        "            self.lmba = max_lambda_\n",
        "        adv_x = x.detach().clone().to(torch.float)\n",
        "        while self.lmba <= max_lambda_:\n",
        "            with torch.no_grad():\n",
        "                _, done = get_loss(model, adv_x, label)\n",
        "            if torch.all(done):\n",
        "                break\n",
        "            pert_x = self._perturb(model, adv_x[~done], label[~done],\n",
        "                                   steps,\n",
        "                                   step_length,\n",
        "                                   lmda=self.lmba,\n",
        "                                   use_sample=use_sample\n",
        "                                   )\n",
        "            adv_x[~done] = pert_x\n",
        "            self.lmba *= base\n",
        "        with torch.no_grad():\n",
        "            _, done = get_loss(model, adv_x, label)\n",
        "            if verbose:\n",
        "                print(f\"rFGSM: attack effectiveness {done.sum().item() / x.size()[0] * 100:.3f}%.\")\n",
        "        return adv_x"
      ],
      "metadata": {
        "id": "Og4o9WsofNlB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fgsm = RFGSM()\n",
        "adv_x = fgsm.perturb(model, X, label=y,steps=10,step_length=0.02,min_lambda_=1e-5,max_lambda_=1e5,base=10.,verbose=True,use_sample=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HrCxBoGYhZa0",
        "outputId": "a2b8a8a1-6885-4534-a31c-2867c2e309bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[2.2557e-06],\n",
            "        [7.2600e-08],\n",
            "        [1.7080e-06],\n",
            "        [7.4513e-05],\n",
            "        [1.1064e-05],\n",
            "        [1.4349e-04],\n",
            "        [9.3200e-06],\n",
            "        [4.1878e-05],\n",
            "        [6.0749e-04],\n",
            "        [3.6286e-04],\n",
            "        [7.0824e-05],\n",
            "        [2.7942e-06],\n",
            "        [3.2759e-05],\n",
            "        [3.5169e-06],\n",
            "        [4.1276e-05],\n",
            "        [8.0765e-02],\n",
            "        [5.5046e-03],\n",
            "        [1.2815e-07],\n",
            "        [1.2229e-07],\n",
            "        [1.7493e-05],\n",
            "        [6.3212e-04],\n",
            "        [4.8597e-05],\n",
            "        [1.2368e-06],\n",
            "        [1.5681e-05],\n",
            "        [7.3820e-09],\n",
            "        [1.1757e-08],\n",
            "        [1.3994e-05],\n",
            "        [3.1428e-06],\n",
            "        [8.1003e-06],\n",
            "        [4.3486e-08],\n",
            "        [5.4574e-07],\n",
            "        [2.4140e-06],\n",
            "        [4.1427e-07],\n",
            "        [3.3714e-06],\n",
            "        [9.4361e-06],\n",
            "        [7.7223e-08],\n",
            "        [2.5965e-13],\n",
            "        [5.0702e-09],\n",
            "        [9.6958e-06],\n",
            "        [1.1246e-07],\n",
            "        [1.2015e-04],\n",
            "        [2.8377e-06],\n",
            "        [8.8125e-06],\n",
            "        [7.3981e-13],\n",
            "        [9.6761e-06],\n",
            "        [3.3138e-03],\n",
            "        [9.7163e-09],\n",
            "        [1.8480e-05],\n",
            "        [1.4100e-08],\n",
            "        [1.5162e-07],\n",
            "        [7.5150e-06],\n",
            "        [4.5662e-18],\n",
            "        [3.7537e-06],\n",
            "        [9.0142e-08],\n",
            "        [2.5354e-06],\n",
            "        [3.2612e-08],\n",
            "        [2.2189e-04],\n",
            "        [5.2671e-05],\n",
            "        [2.2231e-24],\n",
            "        [7.8668e-08],\n",
            "        [6.3521e-08],\n",
            "        [2.5324e-06],\n",
            "        [8.0183e-08],\n",
            "        [3.7711e-05],\n",
            "        [8.8444e-08],\n",
            "        [1.6847e-08],\n",
            "        [1.6414e-05],\n",
            "        [2.0360e-04],\n",
            "        [1.8975e-06],\n",
            "        [1.2071e-03],\n",
            "        [1.4192e-03],\n",
            "        [4.1427e-07],\n",
            "        [4.4802e-04],\n",
            "        [5.0987e-08],\n",
            "        [1.1644e-07],\n",
            "        [2.4121e-07],\n",
            "        [1.7915e-05],\n",
            "        [7.3728e-04],\n",
            "        [2.2750e-04],\n",
            "        [3.3650e-02],\n",
            "        [2.1615e-08],\n",
            "        [5.6034e-07],\n",
            "        [4.9414e-04],\n",
            "        [2.6641e-07],\n",
            "        [4.3771e-03],\n",
            "        [2.0723e-08],\n",
            "        [2.6625e-06],\n",
            "        [1.7715e-08],\n",
            "        [3.2909e-10],\n",
            "        [2.2795e-10],\n",
            "        [7.9134e-04],\n",
            "        [2.8588e-07],\n",
            "        [9.9434e-06],\n",
            "        [5.3957e-07],\n",
            "        [5.1868e-08],\n",
            "        [2.2944e-04],\n",
            "        [4.8839e-05],\n",
            "        [1.2901e-06],\n",
            "        [6.2685e-07],\n",
            "        [4.6533e-04],\n",
            "        [4.1194e-06],\n",
            "        [9.4594e-05],\n",
            "        [2.8904e-16],\n",
            "        [5.3800e-07],\n",
            "        [7.3235e-19],\n",
            "        [3.7039e-05],\n",
            "        [2.2231e-05],\n",
            "        [1.0570e-06],\n",
            "        [1.8846e-05],\n",
            "        [2.2502e-05],\n",
            "        [1.1643e-03],\n",
            "        [4.9234e-04],\n",
            "        [3.1879e-08],\n",
            "        [8.8540e-07],\n",
            "        [9.4361e-06],\n",
            "        [2.6630e-08],\n",
            "        [1.1369e-09],\n",
            "        [7.1493e-05],\n",
            "        [4.0218e-08],\n",
            "        [4.7074e-04],\n",
            "        [7.5966e-06],\n",
            "        [2.3730e-06],\n",
            "        [7.4867e-05],\n",
            "        [3.9816e-05],\n",
            "        [5.4624e-05],\n",
            "        [2.1169e-05],\n",
            "        [1.1896e-08],\n",
            "        [1.2405e-05],\n",
            "        [7.1100e-09],\n",
            "        [9.0904e-06],\n",
            "        [3.9339e-06],\n",
            "        [1.9576e-05],\n",
            "        [6.1510e-07],\n",
            "        [4.9167e-05],\n",
            "        [7.6081e-06],\n",
            "        [6.3407e-10],\n",
            "        [6.9219e-06],\n",
            "        [2.6641e-07],\n",
            "        [1.3858e-04],\n",
            "        [6.1540e-07],\n",
            "        [8.2377e-05],\n",
            "        [5.2819e-04],\n",
            "        [1.9665e-06],\n",
            "        [4.5866e-04],\n",
            "        [3.9556e-10],\n",
            "        [1.7561e-11],\n",
            "        [1.2078e-07],\n",
            "        [3.1965e-08],\n",
            "        [3.7971e-06],\n",
            "        [4.4899e-04],\n",
            "        [1.3119e-21],\n",
            "        [9.4361e-06],\n",
            "        [1.8846e-05],\n",
            "        [1.3463e-09],\n",
            "        [2.6088e-06],\n",
            "        [1.5887e-08],\n",
            "        [1.5221e-04],\n",
            "        [1.7032e-08],\n",
            "        [3.3583e-08],\n",
            "        [1.6338e-07],\n",
            "        [1.8846e-05],\n",
            "        [9.6761e-06],\n",
            "        [3.0248e-08],\n",
            "        [4.5047e-05],\n",
            "        [1.1865e-04],\n",
            "        [6.3723e-07],\n",
            "        [1.1970e-05],\n",
            "        [9.8339e-09],\n",
            "        [1.4566e-06],\n",
            "        [4.9124e-08],\n",
            "        [6.4920e-06],\n",
            "        [1.8794e-05],\n",
            "        [5.2046e-11],\n",
            "        [2.1025e-06],\n",
            "        [3.7471e-07],\n",
            "        [1.3795e-06],\n",
            "        [3.0526e-04],\n",
            "        [1.3837e-04],\n",
            "        [1.7665e-11],\n",
            "        [1.9442e-04],\n",
            "        [3.2615e-05],\n",
            "        [9.2630e-06],\n",
            "        [2.3842e-07],\n",
            "        [2.8482e-06],\n",
            "        [2.2231e-05],\n",
            "        [3.9539e-08],\n",
            "        [9.0725e-11],\n",
            "        [4.1162e-03],\n",
            "        [5.2934e-07],\n",
            "        [2.5852e-03],\n",
            "        [6.3284e-06],\n",
            "        [3.7901e-07],\n",
            "        [1.5083e-05],\n",
            "        [3.4247e-06],\n",
            "        [1.5799e-06],\n",
            "        [1.0124e-04],\n",
            "        [9.0966e-10],\n",
            "        [8.3279e-05],\n",
            "        [1.9042e-08],\n",
            "        [2.0539e-11],\n",
            "        [3.7570e-06],\n",
            "        [3.9974e-06],\n",
            "        [5.4347e-06],\n",
            "        [1.5532e-04],\n",
            "        [2.3601e-07],\n",
            "        [1.0924e-08],\n",
            "        [2.1093e-05],\n",
            "        [4.5383e-05],\n",
            "        [1.1818e-04],\n",
            "        [2.8904e-16],\n",
            "        [1.4838e-06],\n",
            "        [4.0456e-05],\n",
            "        [1.2109e-08],\n",
            "        [2.7602e-10],\n",
            "        [1.4121e-03],\n",
            "        [1.2779e-07],\n",
            "        [2.7174e-08],\n",
            "        [6.5242e-07],\n",
            "        [6.8577e-10],\n",
            "        [7.0747e-06],\n",
            "        [1.1233e-04],\n",
            "        [6.0342e-07],\n",
            "        [2.6457e-07],\n",
            "        [1.2634e-10],\n",
            "        [9.4361e-06],\n",
            "        [4.6749e-03],\n",
            "        [3.7985e-05],\n",
            "        [1.2893e-10],\n",
            "        [6.0014e-05],\n",
            "        [1.1886e-06],\n",
            "        [2.5368e-09],\n",
            "        [4.0909e-14],\n",
            "        [6.0728e-08],\n",
            "        [2.5360e-07],\n",
            "        [7.5014e-11],\n",
            "        [2.3680e-04],\n",
            "        [1.1103e-04],\n",
            "        [9.8094e-10],\n",
            "        [1.3336e-07],\n",
            "        [2.3755e-05],\n",
            "        [1.3336e-07],\n",
            "        [3.8268e-07],\n",
            "        [3.8572e-09],\n",
            "        [1.6798e-05],\n",
            "        [1.2636e-06],\n",
            "        [6.3212e-04],\n",
            "        [3.0532e-06],\n",
            "        [3.2616e-05],\n",
            "        [1.6826e-07],\n",
            "        [1.8846e-05],\n",
            "        [8.6505e-06],\n",
            "        [6.2449e-04],\n",
            "        [1.3065e-12],\n",
            "        [6.9457e-06],\n",
            "        [2.3052e-04]], grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "torch.Size([255, 10000])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-65-8b9535a38497>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfgsm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRFGSM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0madv_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfgsm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperturb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstep_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.02\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmin_lambda_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_lambda_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0muse_sample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-63-cd83058aca0b>\u001b[0m in \u001b[0;36mperturb\u001b[0;34m(self, model, x, label, steps, step_length, min_lambda_, max_lambda_, base, verbose, use_sample)\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m             pert_x = self._perturb(model, adv_x[~done], label[~done],\n\u001b[0m\u001b[1;32m     98\u001b[0m                                    \u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                                    \u001b[0mstep_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-63-cd83058aca0b>\u001b[0m in \u001b[0;36m_perturb\u001b[0;34m(self, model, x, label, steps, step_length, lmda, use_sample)\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0mloss_natural\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_adv_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_adv_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;31m# filtering un-considered graphs & positions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched, materialize_grads)\u001b[0m\n\u001b[1;32m    392\u001b[0m         )\n\u001b[1;32m    393\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         result = Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    395\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m             \u001b[0mgrad_outputs_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_, done = get_loss(model, adv_x, y)\n",
        "done.sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yohcDcs2scM5",
        "outputId": "2111c264-4fb5-4310-c4a0-a1b2c5925871"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    }
  ]
}