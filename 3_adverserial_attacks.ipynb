{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN5kanaYdsZ8lEoVsmN3ftp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mostafa-ja/mal_adv3/blob/main/3_adverserial_attacks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy import sparse\n",
        "import gdown\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "JKDdI3K9LrlF"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "download_link = 'https://drive.google.com/uc?id=12iud4h19CZst4exbr3U2A9iDxBYvZ5U_'\n",
        "output_filepath = '/content/'\n",
        "gdown.download(download_link, output_filepath)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "0C770BMnLop2",
        "outputId": "58bb1666-ae23-4496-ab8b-9fba02d701b5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=12iud4h19CZst4exbr3U2A9iDxBYvZ5U_\n",
            "From (redirected): https://drive.google.com/uc?id=12iud4h19CZst4exbr3U2A9iDxBYvZ5U_&confirm=t&uuid=2cb9bb58-3da5-4697-ba66-610e9a01509b\n",
            "To: /content/X_redefined_sparse_matrix.npz\n",
            "100%|██████████| 2.31M/2.31M [00:00<00:00, 110MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/X_redefined_sparse_matrix.npz'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "download_link = 'https://drive.google.com/uc?id=1IhrcT3jHqlPrw2KvQ5vJkBgozxcJ1cJm'\n",
        "output_filepath = '/content/'\n",
        "gdown.download(download_link, output_filepath)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "y3O3o6ZHLpI8",
        "outputId": "50f3e15b-95a0-40b4-9b71-1143fbcad97d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1IhrcT3jHqlPrw2KvQ5vJkBgozxcJ1cJm\n",
            "To: /content/labels.pt\n",
            "100%|██████████| 517k/517k [00:00<00:00, 87.8MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/labels.pt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "download_link = 'https://drive.google.com/uc?id=13o5n06UpMDOhtk4u7B_RBSWa3kiiGXFs'\n",
        "output_filepath = '/content/'\n",
        "gdown.download(download_link, output_filepath)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "secibICoPRke",
        "outputId": "1d9577e6-3f7a-49e4-ea76-13d940747987"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=13o5n06UpMDOhtk4u7B_RBSWa3kiiGXFs\n",
            "To: /content/DNN_params.pth\n",
            "100%|██████████| 8.17M/8.17M [00:00<00:00, 109MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/DNN_params.pth'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "download_link = 'https://drive.google.com/uc?id=1PxFOLBnQAlX-EOsqkhGCSd1T3ykAD0-4'\n",
        "output_filepath = '/content/'\n",
        "gdown.download(download_link, output_filepath)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "3kpiyKpDG3Fm",
        "outputId": "a41a2e59-8c40-405f-dbe6-7c2faddc5cd4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1PxFOLBnQAlX-EOsqkhGCSd1T3ykAD0-4\n",
            "To: /content/vocab.pkl\n",
            "100%|██████████| 9.18M/9.18M [00:00<00:00, 92.6MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/vocab.pkl'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dictionary from the file\n",
        "with open('vocab.pkl', 'rb') as f:\n",
        "    vocab = pickle.load(f)\n",
        "\n",
        "for i, (key, value) in enumerate(vocab.items()):\n",
        "    print((key, value))\n",
        "    if i >= 5:\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0rDH5Q6HOmd",
        "outputId": "dd74079e-96a6-4c85-a8c3-a4ac10d471ed"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('android/media/mediaplayer->start', 141045)\n",
            "('android/app/activity->setcontentview', 140900)\n",
            "('android/os/vibrator->cancel', 141093)\n",
            "('android.permission.vibrate', 140720)\n",
            "('android.hardware.touchscreen', 137091)\n",
            "('android.intent.action.main', 138335)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "X_redefined = sparse.load_npz(\"X_redefined_sparse_matrix.npz\")\n",
        "labels_tensor = torch.load('labels.pt')"
      ],
      "metadata": {
        "id": "qHe1GZxX-ET4"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into train, validation, and test sets with stratified sampling\n",
        "X_train_val, X_test, labels_train_val, labels_test = train_test_split(X_redefined, labels_tensor, test_size=0.2, stratify=labels_tensor, random_state=42)\n",
        "X_train, X_val, labels_train, labels_val = train_test_split(X_train_val, labels_train_val, test_size=0.2, stratify=labels_train_val, random_state=42)\n",
        "\n",
        "# Combine features and labels into datasets\n",
        "train_dataset = TensorDataset(torch.tensor(X_train.toarray(), dtype=torch.float32), labels_train)\n",
        "val_dataset = TensorDataset(torch.tensor(X_val.toarray(), dtype=torch.float32), labels_val)\n",
        "test_dataset = TensorDataset(torch.tensor(X_test.toarray(), dtype=torch.float32), labels_test)\n"
      ],
      "metadata": {
        "id": "V8SALqiV-zFj"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the DataLoader for training, validation, and test sets\n",
        "batch_size = 256\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "g3BUXjXdZ9wq"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class MalwareDetectionModel(nn.Module):\n",
        "    def __init__(self, input_size=10000, hidden_1_size=200, hidden_2_size=200, num_labels=2, dropout_prob=0.6):\n",
        "        super(MalwareDetectionModel, self).__init__()\n",
        "\n",
        "        self.input_size = input_size\n",
        "        self.hidden_1_size = hidden_1_size\n",
        "        self.hidden_2_size = hidden_2_size\n",
        "        self.num_labels = num_labels\n",
        "        self.dropout_prob = dropout_prob\n",
        "\n",
        "        self.fc1 = nn.Linear(input_size, hidden_1_size)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.dropout1 = nn.Dropout(dropout_prob)\n",
        "        self.fc2 = nn.Linear(hidden_1_size, hidden_2_size)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.dropout2 = nn.Dropout(dropout_prob)\n",
        "        self.fc3 = nn.Linear(hidden_2_size, num_labels)\n",
        "        self.log_softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.dropout1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc3(x)\n",
        "        x = self.log_softmax(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "xdNbTvxTTqyw"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of your model\n",
        "model = MalwareDetectionModel()\n",
        "\n",
        "# Load model parameters\n",
        "model.load_state_dict(torch.load('DNN_params.pth'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZs3fmmZ-4PM",
        "outputId": "93eb4a52-aae6-45c6-f102-be7d9df61372"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X,y = next(iter(test_loader))\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91tjptrSb5qi",
        "outputId": "0b48569e-f1f7-4d10-9e05-194526408497"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([256, 10000])\n",
            "torch.Size([256, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "delta = torch.zeros_like(X, requires_grad=True)\n",
        "for t in range(25):\n",
        "    loss = nn.CrossEntropyLoss()(model(X + delta), y.view(-1).long())\n",
        "    loss.backward()\n",
        "    gradients = delta.grad.detach().sign() * (X < 0.5)\n",
        "    delta.data = (delta + 0.02*delta.grad.detach().sign()).clamp(0.,1.)\n",
        "    print(delta.data[0])\n",
        "    delta.grad.zero_()\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "pP6ugpgGJaCp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def round_x(x, round_threshold=0.5):\n",
        "    \"\"\"\n",
        "    Rounds x by thresholding it according to round_threshold.\n",
        "    :param x: input tensor\n",
        "    :param round_threshold: threshold parameter\n",
        "    :return: a tensor of 0s and 1s\n",
        "    \"\"\"\n",
        "    return (x >= round_threshold).float()\n",
        "\n",
        "def get_x0(x, initial_rounding_threshold=0.5, is_sample=False):\n",
        "    \"\"\"\n",
        "    Helper function to randomly initialize the inner maximizer algorithm.\n",
        "    Randomizes the input tensor while preserving its functionality.\n",
        "    :param x: input tensor\n",
        "    :param rounding_threshold: threshold for rounding\n",
        "    :param is_sample: flag to sample randomly from feasible area\n",
        "    :return: randomly sampled feasible version of x\n",
        "    \"\"\"\n",
        "    if is_sample:\n",
        "        rand_x = round_x(torch.rand(x.size()), round_threshold=rounding_threshold)\n",
        "        return (rand_x.byte() | x.byte()).float()\n",
        "    else:\n",
        "        return x\n",
        "\n",
        "def or_float_tensors(x_1, x_2):\n",
        "    \"\"\"\n",
        "    ORs two float tensors by converting them to byte and back.\n",
        "    :param x_1: tensor one\n",
        "    :param x_2: tensor two\n",
        "    :return: float tensor of 0s and 1s\n",
        "    \"\"\"\n",
        "    return (x_1.byte() | x_2.byte()).float()\n",
        "\n",
        "\n",
        "def xor_float_tensors(x_1, x_2):\n",
        "    \"\"\"\n",
        "    XORs two float tensors by converting them to byte and back\n",
        "    Note that byte() takes the first 8 bit after the decimal point of the float\n",
        "    e.g., 0.0 ==> 0\n",
        "          0.1 ==> 0\n",
        "          1.1 ==> 1\n",
        "        255.1 ==> 255\n",
        "        256.1 ==> 0\n",
        "    Subsequently the purpose of this function is to map 1s float tensors to 1\n",
        "    and those of 0s to 0. I.e., it is meant to be used on tensors of 0s and 1s.\n",
        "\n",
        "    :param x_1: tensor one\n",
        "    :param x_2: tensor two\n",
        "    :return: float tensor of 0s and 1s.\n",
        "    \"\"\"\n",
        "    return (x_1.byte() ^ x_2.byte()).float()\n",
        "\n",
        "def get_loss(model, adv_x, label):\n",
        "    \"\"\"\n",
        "    Compute the loss and prediction correctness.\n",
        "\n",
        "    Parameters:\n",
        "    - model: torch.nn.Module, a victim model\n",
        "    - adv_x: torch.FloatTensor, the adversarially perturbed input samples\n",
        "    - label: torch.LongTensor, ground truth labels\n",
        "\n",
        "    Returns:\n",
        "    - loss_no_reduction: torch.FloatTensor, the computed loss without reduction\n",
        "    - done: torch.BoolTensor, a tensor indicating if the prediction is incorrect\n",
        "    \"\"\"\n",
        "    y_prob = model(adv_x)\n",
        "    loss_no_reduction = nn.BCELoss(reduction='none')(y_prob, label)\n",
        "    y_pred = (y_prob >= 0.5).float()  # Threshold at 0.5\n",
        "    done = (y_pred != label).squeeze()\n",
        "\n",
        "    return loss_no_reduction, done"
      ],
      "metadata": {
        "id": "XCbqeJ84gfDD"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "x_1 = torch.tensor([1.0, 1.0,  1.0, 1.0, 1.0, 0.0,  0.0, 0.2])\n",
        "x_2 = torch.tensor([0.0, 0.6, -0.2, 0.9, 1.9, 1.0, -0.2, 0.3])\n",
        "result = or_float_tensors(x_1, x_2)\n",
        "             tensor([1., 1., 1., 1., 1., 1., 0., 0.])\n",
        "\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "w1QRWuCbdFqD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dfgsm_k(x, y, model, k=25, epsilon=0.02, alpha=1., initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False):\n",
        "    \"\"\"\n",
        "    FGSM^k with deterministic rounding\n",
        "    :param y: ground truth labels\n",
        "    :param x: feature vector\n",
        "    :param model: neural network model\n",
        "    :param k: number of steps\n",
        "    :param epsilon: update value in each direction\n",
        "    :param alpha: hyperparameter for controlling the portionate of rounding\n",
        "    :param initial_rounding_threshold: threshold parameter for rounding the initial x_next\n",
        "    :param round_threshold: threshold parameter for rounding\n",
        "    :param is_report_loss_diff: flag to report loss difference\n",
        "    :param is_sample: flag to sample randomly from the feasible area\n",
        "    :return: the adversarial version of x according to dfgsm_k (tensor)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Compute natural loss\n",
        "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "    loss_natural = criterion(model(x), y.view(-1).long())\n",
        "\n",
        "    # Initialize starting point\n",
        "    x_next = x.clone()\n",
        "    x_next = get_x0(x_next, initial_rounding_threshold, is_sample)\n",
        "\n",
        "    # Multi-step\n",
        "    for t in range(k):\n",
        "        # Forward pass\n",
        "        x_var = x_next.clone().detach().requires_grad_(True)\n",
        "        y_model = model(x_var)\n",
        "        loss = criterion(y_model, y.view(-1).long())\n",
        "\n",
        "        # Compute gradient\n",
        "        grad_vars = torch.autograd.grad(loss.mean(), x_var)\n",
        "        # Find the next sample\n",
        "        x_next = x_next + epsilon * torch.sign(grad_vars[0].data)\n",
        "\n",
        "        # Projection\n",
        "        x_next = torch.clamp(x_next, min=0., max=1.)\n",
        "\n",
        "    # Rounding step\n",
        "    if random:\n",
        "       round_threshold = torch.rand(x_next.size()) * alpha\n",
        "    x_next = round_x(x_next, round_threshold=round_threshold)\n",
        "\n",
        "    # Feasible projection\n",
        "    x_next = or_float_tensors(x_next, x)\n",
        "\n",
        "    # Compute adversarial loss\n",
        "    loss_adv = criterion(model(x_next), y.view(-1).long()).data\n",
        "\n",
        "    if is_report_loss_diff:\n",
        "        #print(f\"Natural loss: {loss_natural.mean():.4f}, Adversarial loss: {loss_adv.mean():.4f}, Difference: {(loss_adv.mean() - loss_natural.mean()):.4f}\")\n",
        "        outputs = model(x_next)\n",
        "        _, predicted = torch.topk(outputs, k=1)\n",
        "        done = (predicted != y).squeeze()\n",
        "        print(f\"rFGSM: attack effectiveness {done.sum().item() / x.size()[0] * 100:.3f}%.\")\n",
        "\n",
        "    # Replace with natural if adversarial loss is higher\n",
        "    replace_flag = (loss_adv < loss_natural).squeeze()\n",
        "    x_next[replace_flag] = x[replace_flag]\n",
        "\n",
        "    return x_next\n"
      ],
      "metadata": {
        "id": "H6BiF-vCHLlH"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_adv = dfgsm_k(X,y,model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTlgFwyKr3ex",
        "outputId": "a6222aeb-bc95-4c76-c992-02f1a85e6552"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rFGSM: attack effectiveness 100.000%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_adv = dfgsm_k(X,y,model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X10_IhqiAZSB",
        "outputId": "e6315ef3-8c0f-4331-bdb7-0e788ad18d3a"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Natural loss: 0.0060, Adversarial loss: 2221.2881, Difference: 2221.2820\n",
            "rFGSM: attack effectiveness 100.000%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.sum()/batch_size)\n",
        "print(x_adv.sum()/batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GafR_uFI7_l",
        "outputId": "3917d133-5f53-4eb3-c117-35b756c92b09"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(26.6289)\n",
            "tensor(3986.6562)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_adv = dfgsm_k(X,y,model,random=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4xLg9HYZ9s7",
        "outputId": "d32bb793-7d39-4f67-d414-4cb1ce14adf3"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Natural loss: 0.0060, Adversarial loss: 1290.9233, Difference: 1290.9174\n",
            "rFGSM: attack effectiveness 100.000%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.sum()/batch_size)\n",
        "print(x_adv.sum()/batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmZlatNbaN8G",
        "outputId": "aea07910-0b65-4707-b22b-7cada23fc851"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(26.6289)\n",
            "tensor(2741.3125)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_adv = dfgsm_k(X,y,model,k=1,random=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KayY50GaVVB",
        "outputId": "04ff7813-9251-4157-e8da-f50dbe8cba7b"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Natural loss: 0.0060, Adversarial loss: 38.6829, Difference: 38.6769\n",
            "rFGSM: attack effectiveness 100.000%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.sum()/batch_size)\n",
        "print(x_adv.sum()/batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bx3Eyhemae7F",
        "outputId": "f34d260a-58c1-4d69-d0af-b4a48cc00a49"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(26.6289)\n",
            "tensor(120.8047)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for alpha in range(1, 52, 10):\n",
        "  print('alpha = ',alpha)\n",
        "  x_adv = dfgsm_k(X, y, model, k=20, epsilon=0.02, alpha=alpha,random=True)\n",
        "  print(X.sum()/batch_size)\n",
        "  print(x_adv.sum()/batch_size)\n",
        "  print('***************************')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ue3RTg7WVOvD",
        "outputId": "dc2aa351-fea9-4389-9fc0-d4c79bfac7ae"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "alpha =  1\n",
            "rFGSM: attack effectiveness 100.000%.\n",
            "tensor(28.0148)\n",
            "tensor(2189.4138)\n",
            "***************************\n",
            "alpha =  11\n",
            "rFGSM: attack effectiveness 100.000%.\n",
            "tensor(28.0148)\n",
            "tensor(222.7241)\n",
            "***************************\n",
            "alpha =  21\n",
            "rFGSM: attack effectiveness 100.000%.\n",
            "tensor(28.0148)\n",
            "tensor(132.2562)\n",
            "***************************\n",
            "alpha =  31\n",
            "rFGSM: attack effectiveness 99.507%.\n",
            "tensor(28.0148)\n",
            "tensor(98.3202)\n",
            "***************************\n",
            "alpha =  41\n",
            "rFGSM: attack effectiveness 94.581%.\n",
            "tensor(28.0148)\n",
            "tensor(80.3054)\n",
            "***************************\n",
            "alpha =  51\n",
            "rFGSM: attack effectiveness 91.626%.\n",
            "tensor(28.0148)\n",
            "tensor(70.1970)\n",
            "***************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_samples = 0\n",
        "total_attack_success = 0\n",
        "total_features_x = 0\n",
        "total_features_x_adv = 0\n",
        "\n",
        "for X, y in test_loader:\n",
        "    batch_size = X.size(0)\n",
        "    x_adv = dfgsm_k(X, y, model, k=20, epsilon=0.0005, random=True,is_report_loss_diff=False)\n",
        "\n",
        "    # Compute mean number of features\n",
        "    total_features_x += X.sum().item()\n",
        "    total_features_x_adv += x_adv.sum().item()\n",
        "\n",
        "    # Compute attack effectiveness for this batch\n",
        "    outputs_adv = model(x_adv)\n",
        "    _, predicted_adv = torch.topk(outputs_adv, k=1)\n",
        "    total_attack_success += torch.sum(predicted_adv != y).item()\n",
        "    total_samples += batch_size\n",
        "\n",
        "# Compute mean number of features\n",
        "mean_features_x = total_features_x / total_samples\n",
        "mean_features_x_adv = total_features_x_adv / total_samples\n",
        "\n",
        "# Compute mean attack effectiveness\n",
        "mean_attack_effectiveness = (total_attack_success / total_samples) * 100\n",
        "\n",
        "# Print results\n",
        "print('Mean number of features (X):', mean_features_x)\n",
        "print('Mean number of features (X_adv):', mean_features_x_adv)\n",
        "print('Mean attack effectiveness:', mean_attack_effectiveness)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qI8_L180z03g",
        "outputId": "65020b0e-05f6-40a8-936b-3bfbd451c886"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean number of features (X): 27.5364492500872\n",
            "Mean number of features (X_adv): 76.25450529008255\n",
            "Mean attack effectiveness: 98.64356857729722\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_samples = 0\n",
        "total_attack_success = 0\n",
        "total_features_x = 0\n",
        "total_features_x_adv = 0\n",
        "\n",
        "for X, y in test_loader:\n",
        "    batch_size = X.size(0)\n",
        "    x_adv = dfgsm_k(X, y, model, k=20, epsilon=0.02, alpha=40,random=True,is_report_loss_diff=False)\n",
        "\n",
        "    # Compute mean number of features\n",
        "    total_features_x += X.sum().item()\n",
        "    total_features_x_adv += x_adv.sum().item()\n",
        "\n",
        "    # Compute attack effectiveness for this batch\n",
        "    outputs_adv = model(x_adv)\n",
        "    _, predicted_adv = torch.topk(outputs_adv, k=1)\n",
        "    total_attack_success += torch.sum(predicted_adv != y).item()\n",
        "    total_samples += batch_size\n",
        "\n",
        "# Compute mean number of features\n",
        "mean_features_x = total_features_x / total_samples\n",
        "mean_features_x_adv = total_features_x_adv / total_samples\n",
        "\n",
        "# Compute mean attack effectiveness\n",
        "mean_attack_effectiveness = (total_attack_success / total_samples) * 100\n",
        "\n",
        "# Print results\n",
        "print('Mean number of features (X):', mean_features_x)\n",
        "print('Mean number of features (X_adv):', mean_features_x_adv)\n",
        "print('Mean attack effectiveness:', mean_attack_effectiveness)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-c7gxOHmXqv",
        "outputId": "29185cf1-413e-48ec-c2e2-91994ee67ee6"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean number of features (X): 27.5364492500872\n",
            "Mean number of features (X_adv): 81.65845056776344\n",
            "Mean attack effectiveness: 96.50428244777738\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def dfgsm_k2(x, y, model, k=25, epsilon=0.02, alpha=1., initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False):\n",
        "    \"\"\"\n",
        "    FGSM^k with deterministic rounding\n",
        "    :param y: ground truth labels\n",
        "    :param x: feature vector\n",
        "    :param model: neural network model\n",
        "    :param k: number of steps\n",
        "    :param epsilon: update value in each direction\n",
        "    :param alpha: hyperparameter for controlling the portionate of rounding\n",
        "    :param initial_rounding_threshold: threshold parameter for rounding the initial x_next\n",
        "    :param round_threshold: threshold parameter for rounding\n",
        "    :param is_report_loss_diff: flag to report loss difference\n",
        "    :param is_sample: flag to sample randomly from the feasible area\n",
        "    :return: the adversarial version of x according to dfgsm_k (tensor)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Compute natural loss\n",
        "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "    loss_natural = criterion(model(x), y.view(-1).long())\n",
        "\n",
        "    # Initialize starting point\n",
        "    x_next = x.clone()\n",
        "    x_next = get_x0(x_next, initial_rounding_threshold, is_sample)\n",
        "\n",
        "    # Multi-step\n",
        "    for t in range(k):\n",
        "        # Forward pass\n",
        "        x_var = x_next.clone().detach().requires_grad_(True)\n",
        "        y_model = model(x_var)\n",
        "        loss = criterion(y_model, y.view(-1).long())\n",
        "\n",
        "        # Compute gradient\n",
        "        grad_vars = torch.autograd.grad(loss.mean(), x_var)\n",
        "        #print(torch.sign(grad_vars[0].data).clamp(min=0))\n",
        "        # Find the next sample\n",
        "        x_next = x_next + epsilon * (torch.sign(grad_vars[0].data).clamp(min=0))\n",
        "\n",
        "        # Projection\n",
        "        x_next = torch.clamp(x_next, min=0., max=1.)\n",
        "\n",
        "    # Rounding step\n",
        "    if random:\n",
        "       round_threshold = torch.rand(x_next.size()) * alpha\n",
        "    x_next = round_x(x_next, round_threshold=round_threshold)\n",
        "\n",
        "    # Feasible projection\n",
        "    x_next = or_float_tensors(x_next, x)\n",
        "\n",
        "    # Compute adversarial loss\n",
        "    loss_adv = criterion(model(x_next), y.view(-1).long()).data\n",
        "\n",
        "    if is_report_loss_diff:\n",
        "        #print(f\"Natural loss: {loss_natural.mean():.4f}, Adversarial loss: {loss_adv.mean():.4f}, Difference: {(loss_adv.mean() - loss_natural.mean()):.4f}\")\n",
        "        outputs = model(x_next)\n",
        "        _, predicted = torch.topk(outputs, k=1)\n",
        "        done = (predicted != y).squeeze()\n",
        "        print(f\"rFGSM: attack effectiveness {done.sum().item() / x.size()[0] * 100:.3f}%.\")\n",
        "\n",
        "    # Replace with natural if adversarial loss is higher\n",
        "    replace_flag = (loss_adv < loss_natural).squeeze()\n",
        "    x_next[replace_flag] = x[replace_flag]\n",
        "\n",
        "    return x_next"
      ],
      "metadata": {
        "id": "jJHs7RsgsHMS"
      },
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_adv = dfgsm_k2(X[:1],y[:1],model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GfFMDVbEsJzQ",
        "outputId": "eb00fd42-fc84-4c02-d9bd-d389aee31d88"
      },
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rFGSM: attack effectiveness 100.000%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for alpha in range(1, 52, 10):\n",
        "  print('alpha = ',alpha)\n",
        "  x_adv = dfgsm_k2(X, y, model, k=20, epsilon=0.02, alpha=alpha,random=True)\n",
        "  print(X.sum()/batch_size)\n",
        "  print(x_adv.sum()/batch_size)\n",
        "  print('***************************')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5povafNsuLV",
        "outputId": "15d13143-21aa-4028-f107-5814f26b046c"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "alpha =  1\n",
            "rFGSM: attack effectiveness 100.000%.\n",
            "tensor(28.0148)\n",
            "tensor(2246.3103)\n",
            "***************************\n",
            "alpha =  11\n",
            "rFGSM: attack effectiveness 100.000%.\n",
            "tensor(28.0148)\n",
            "tensor(228.2020)\n",
            "***************************\n",
            "alpha =  21\n",
            "rFGSM: attack effectiveness 100.000%.\n",
            "tensor(28.0148)\n",
            "tensor(132.3547)\n",
            "***************************\n",
            "alpha =  31\n",
            "rFGSM: attack effectiveness 99.507%.\n",
            "tensor(28.0148)\n",
            "tensor(98.7537)\n",
            "***************************\n",
            "alpha =  41\n",
            "rFGSM: attack effectiveness 98.030%.\n",
            "tensor(28.0148)\n",
            "tensor(82.3054)\n",
            "***************************\n",
            "alpha =  51\n",
            "rFGSM: attack effectiveness 88.177%.\n",
            "tensor(28.0148)\n",
            "tensor(71.4335)\n",
            "***************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_samples = 0\n",
        "total_attack_success = 0\n",
        "total_features_x = 0\n",
        "total_features_x_adv = 0\n",
        "\n",
        "for X, y in test_loader:\n",
        "    batch_size = X.size(0)\n",
        "    x_adv = dfgsm_k2(X, y, model, k=20, epsilon=0.02, alpha=40,random=True,is_report_loss_diff=False)\n",
        "\n",
        "    # Compute mean number of features\n",
        "    total_features_x += X.sum().item()\n",
        "    total_features_x_adv += x_adv.sum().item()\n",
        "\n",
        "    # Compute attack effectiveness for this batch\n",
        "    outputs_adv = model(x_adv)\n",
        "    _, predicted_adv = torch.topk(outputs_adv, k=1)\n",
        "    total_attack_success += torch.sum(predicted_adv != y).item()\n",
        "    total_samples += batch_size\n",
        "\n",
        "# Compute mean number of features\n",
        "mean_features_x = total_features_x / total_samples\n",
        "mean_features_x_adv = total_features_x_adv / total_samples\n",
        "\n",
        "# Compute mean attack effectiveness\n",
        "mean_attack_effectiveness = (total_attack_success / total_samples) * 100\n",
        "\n",
        "# Print results\n",
        "print('Mean number of features (X):', mean_features_x)\n",
        "print('Mean number of features (X_adv):', mean_features_x_adv)\n",
        "print('Mean attack effectiveness:', mean_attack_effectiveness)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJDq5_oZtPSW",
        "outputId": "7391b1a7-40a1-464c-a934-fdd4c21b118f"
      },
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean number of features (X): 27.5364492500872\n",
            "Mean number of features (X_adv): 82.96155485796226\n",
            "Mean attack effectiveness: 96.48878037437507\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ".clone(): This method creates a deep copy of the tensor, including its data and gradients (if any). It essentially creates a new tensor with the same data and properties as the original tensor. If the original tensor is part of a computation graph and requires gradients, the cloned tensor will also be part of the same computation graph and will require gradients. Any changes made to the cloned tensor will not affect the original tensor, and vice versa.\n",
        "\n",
        ".copy(): This method creates a shallow copy of the tensor. It only copies the data, not the computational graph or gradients. Therefore, the copied tensor will be detached from any computation graph and will not require gradients, even if the original tensor did. Changes made to the copied tensor will not affect the original tensor, but changes in the original tensor's data will be reflected in the copied tensor.\n",
        "\n"
      ],
      "metadata": {
        "id": "DxHlKdaVI5bQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def bga_k(x, y, model, k=25, alpha=1., is_report_loss_diff=True, use_sample=False):\n",
        "    \"\"\"\n",
        "    Multi-step bit gradient ascent\n",
        "    :param x: feature vector\n",
        "    :param y: ground truth labels\n",
        "    :param model: neural network model\n",
        "    :param k: number of steps\n",
        "    :param alpha: hyperparameter for controlling updates\n",
        "    :param is_report_loss_diff: flag to report loss difference\n",
        "    :param use_sample: flag to sample randomly from the feasible area\n",
        "    :return: the adversarial version of x according to bga_k (tensor)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Compute natural loss\n",
        "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "    loss_natural = criterion(model(x), y.view(-1).long())\n",
        "\n",
        "    # Initialize worst loss and corresponding adversarial samples\n",
        "    loss_worst = loss_natural.clone()\n",
        "    x_worst = x.clone()\n",
        "\n",
        "    # Book-keeping\n",
        "    sqrt_m = torch.sqrt(torch.tensor([x.size()[1]], dtype=torch.float))\n",
        "\n",
        "    # Multi-step with gradients\n",
        "    for t in range(k):\n",
        "        if t == 0:\n",
        "            # Initialize starting point\n",
        "            x_next = get_x0(x, use_sample)\n",
        "        else:\n",
        "            # Compute gradient\n",
        "            grad_vars = torch.autograd.grad(loss.mean(), x_var)\n",
        "            grad_data = grad_vars[0].data\n",
        "\n",
        "            # Compute the updates\n",
        "            x_update = (sqrt_m * (1. - 2. * x_next) * grad_data >= (alpha * torch.norm(grad_data, 2, 1).unsqueeze(1))).float()\n",
        "\n",
        "            # Find the next sample with projection to the feasible set\n",
        "            x_next = xor_float_tensors(x_update, x_next)\n",
        "            x_next = or_float_tensors(x_next, x)\n",
        "\n",
        "        # Forward pass\n",
        "        x_var = x_next.clone().detach().requires_grad_(True)\n",
        "        y_model = model(x_var)\n",
        "        loss = criterion(y_model, y.view(-1).long())\n",
        "\n",
        "        # Update worst loss and adversarial samples\n",
        "        replace_flag = (loss.data > loss_worst)\n",
        "        loss_worst[replace_flag] = loss.data[replace_flag]\n",
        "        x_worst[replace_flag] = x_next[replace_flag]\n",
        "\n",
        "    if is_report_loss_diff:\n",
        "        #print(f\"Natural loss: {loss_natural.mean():.4f}, Adversarial loss: {loss_worst.mean():.4f}, Difference: {(loss_worst.mean() - loss_natural.mean()):.4f}\")\n",
        "        outputs = model(x_worst)\n",
        "        _, predicted = torch.topk(outputs, k=1)\n",
        "        done = (predicted != y).squeeze()\n",
        "        print(f\"rFGSM: attack effectiveness {done.sum().item() / x.size()[0] * 100:.3f}%.\")\n",
        "\n",
        "    return x_worst\n"
      ],
      "metadata": {
        "id": "V_1x56e5UYFe"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_adv = bga_k(X, y, model, k=25, is_report_loss_diff=True, use_sample=False)\n",
        "print(X.sum()/batch_size)\n",
        "print(x_adv.sum()/batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trFNZQ0HLMZ8",
        "outputId": "d9323e97-76ac-4fdf-8c70-a03921613e53"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rFGSM: attack effectiveness 100.000%.\n",
            "tensor(28.0148)\n",
            "tensor(2289.4089)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for alpha in range(1,6):\n",
        "  print('alpha = ',alpha)\n",
        "  x_adv = bga_k(X, y, model, k=25, alpha=alpha, is_report_loss_diff=True, use_sample=False)\n",
        "  print(X.sum()/batch_size)\n",
        "  print(x_adv.sum()/batch_size)\n",
        "  print('***************************')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0MiPWLHR2th",
        "outputId": "293c61a8-4984-499f-ba34-322d6e3dd5b9"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "alpha =  1\n",
            "rFGSM: attack effectiveness 100.000%.\n",
            "tensor(28.0148)\n",
            "tensor(2289.4089)\n",
            "***************************\n",
            "alpha =  2\n",
            "rFGSM: attack effectiveness 100.000%.\n",
            "tensor(28.0148)\n",
            "tensor(577.0690)\n",
            "***************************\n",
            "alpha =  3\n",
            "rFGSM: attack effectiveness 100.000%.\n",
            "tensor(28.0148)\n",
            "tensor(185.2315)\n",
            "***************************\n",
            "alpha =  4\n",
            "rFGSM: attack effectiveness 95.567%.\n",
            "tensor(28.0148)\n",
            "tensor(71.5714)\n",
            "***************************\n",
            "alpha =  5\n",
            "rFGSM: attack effectiveness 1.478%.\n",
            "tensor(28.0148)\n",
            "tensor(28.0887)\n",
            "***************************\n"
          ]
        }
      ]
    }
  ]
}