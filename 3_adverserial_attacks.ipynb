{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMxIgVbUu2SPkK7nuoxSxFz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mostafa-ja/mal_adv3/blob/main/3_adverserial_attacks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy import sparse\n",
        "import gdown\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "JKDdI3K9LrlF"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "download_link = 'https://drive.google.com/uc?id=12iud4h19CZst4exbr3U2A9iDxBYvZ5U_'\n",
        "output_filepath = '/content/'\n",
        "gdown.download(download_link, output_filepath)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "0C770BMnLop2",
        "outputId": "8d4c2f68-e741-4b81-d3de-1582c370ed83"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=12iud4h19CZst4exbr3U2A9iDxBYvZ5U_\n",
            "To: /content/X_redefined_sparse_matrix.npz\n",
            "100%|██████████| 2.31M/2.31M [00:00<00:00, 163MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/X_redefined_sparse_matrix.npz'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "download_link = 'https://drive.google.com/uc?id=1IhrcT3jHqlPrw2KvQ5vJkBgozxcJ1cJm'\n",
        "output_filepath = '/content/'\n",
        "gdown.download(download_link, output_filepath)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "y3O3o6ZHLpI8",
        "outputId": "76fd1384-7f6a-4e87-f1e3-7a19354e58bd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1IhrcT3jHqlPrw2KvQ5vJkBgozxcJ1cJm\n",
            "To: /content/labels.pt\n",
            "100%|██████████| 517k/517k [00:00<00:00, 67.8MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/labels.pt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "download_link = 'https://drive.google.com/uc?id=13o5n06UpMDOhtk4u7B_RBSWa3kiiGXFs'\n",
        "output_filepath = '/content/'\n",
        "gdown.download(download_link, output_filepath)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "secibICoPRke",
        "outputId": "639a78ad-68a2-4358-c8e4-544d3aa74f9e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=13o5n06UpMDOhtk4u7B_RBSWa3kiiGXFs\n",
            "To: /content/DNN_params.pth\n",
            "100%|██████████| 8.17M/8.17M [00:00<00:00, 143MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/DNN_params.pth'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "download_link = 'https://drive.google.com/uc?id=1PxFOLBnQAlX-EOsqkhGCSd1T3ykAD0-4'\n",
        "output_filepath = '/content/'\n",
        "gdown.download(download_link, output_filepath)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "3kpiyKpDG3Fm",
        "outputId": "4578b0a1-4dc1-4461-f2b7-c181da77b343"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1PxFOLBnQAlX-EOsqkhGCSd1T3ykAD0-4\n",
            "To: /content/vocab.pkl\n",
            "100%|██████████| 9.18M/9.18M [00:00<00:00, 84.4MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/vocab.pkl'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dictionary from the file\n",
        "with open('vocab.pkl', 'rb') as f:\n",
        "    vocab = pickle.load(f)\n",
        "\n",
        "for i, (key, value) in enumerate(vocab.items()):\n",
        "    print((key, value))\n",
        "    if i >= 5:\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0rDH5Q6HOmd",
        "outputId": "d8a83293-732d-4f4a-d4f5-a0378275cb53"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('android/media/mediaplayer->start', 141045)\n",
            "('android/app/activity->setcontentview', 140900)\n",
            "('android/os/vibrator->cancel', 141093)\n",
            "('android.permission.vibrate', 140720)\n",
            "('android.hardware.touchscreen', 137091)\n",
            "('android.intent.action.main', 138335)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "X_redefined = sparse.load_npz(\"X_redefined_sparse_matrix.npz\")\n",
        "labels_tensor = torch.load('labels.pt')"
      ],
      "metadata": {
        "id": "qHe1GZxX-ET4"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into train, validation, and test sets with stratified sampling\n",
        "X_train_val, X_test, labels_train_val, labels_test = train_test_split(X_redefined, labels_tensor, test_size=0.2, stratify=labels_tensor, random_state=42)\n",
        "X_train, X_val, labels_train, labels_val = train_test_split(X_train_val, labels_train_val, test_size=0.2, stratify=labels_train_val, random_state=42)\n",
        "\n",
        "# Combine features and labels into datasets\n",
        "train_dataset = TensorDataset(torch.tensor(X_train.toarray(), dtype=torch.float32), labels_train)\n",
        "val_dataset = TensorDataset(torch.tensor(X_val.toarray(), dtype=torch.float32), labels_val)\n",
        "test_dataset = TensorDataset(torch.tensor(X_test.toarray(), dtype=torch.float32), labels_test)\n"
      ],
      "metadata": {
        "id": "V8SALqiV-zFj"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the DataLoader for training, validation, and test sets\n",
        "batch_size = 256\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "g3BUXjXdZ9wq"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class MalwareDetectionModel(nn.Module):\n",
        "    def __init__(self, input_size=10000, hidden_1_size=200, hidden_2_size=200, num_labels=2, dropout_prob=0.6):\n",
        "        super(MalwareDetectionModel, self).__init__()\n",
        "\n",
        "        self.input_size = input_size\n",
        "        self.hidden_1_size = hidden_1_size\n",
        "        self.hidden_2_size = hidden_2_size\n",
        "        self.num_labels = num_labels\n",
        "        self.dropout_prob = dropout_prob\n",
        "\n",
        "        self.fc1 = nn.Linear(input_size, hidden_1_size)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.dropout1 = nn.Dropout(dropout_prob)\n",
        "        self.fc2 = nn.Linear(hidden_1_size, hidden_2_size)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.dropout2 = nn.Dropout(dropout_prob)\n",
        "        self.fc3 = nn.Linear(hidden_2_size, num_labels)\n",
        "        self.log_softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.dropout1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc3(x)\n",
        "        x = self.log_softmax(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "xdNbTvxTTqyw"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of your model\n",
        "model = MalwareDetectionModel()\n",
        "\n",
        "# Load model parameters\n",
        "model.load_state_dict(torch.load('DNN_params.pth'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZs3fmmZ-4PM",
        "outputId": "8ff90dd3-295f-4d48-8ae3-01e5ae1d78e0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X,y = next(iter(test_loader))\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91tjptrSb5qi",
        "outputId": "9a7a0fa5-f132-4896-e832-49afcc3261c9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([256, 10000])\n",
            "torch.Size([256, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "delta = torch.zeros_like(X, requires_grad=True)\n",
        "for t in range(25):\n",
        "    loss = nn.CrossEntropyLoss()(model(X + delta), y.view(-1).long())\n",
        "    loss.backward()\n",
        "    gradients = delta.grad.detach().sign() * (X < 0.5)\n",
        "    delta.data = (delta + 0.02*delta.grad.detach().sign()).clamp(0.,1.)\n",
        "    print(delta.data[0])\n",
        "    delta.grad.zero_()\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "pP6ugpgGJaCp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def round_x(x, round_threshold=0.5):\n",
        "    \"\"\"\n",
        "    Rounds x by thresholding it according to round_threshold.\n",
        "    :param x: input tensor\n",
        "    :param round_threshold: threshold parameter\n",
        "    :return: a tensor of 0s and 1s\n",
        "    \"\"\"\n",
        "    return (x >= round_threshold).float()\n",
        "\n",
        "def get_x0(x, initial_rounding_threshold=0.5, is_sample=False):\n",
        "    \"\"\"\n",
        "    Helper function to randomly initialize the inner maximizer algorithm.\n",
        "    Randomizes the input tensor while preserving its functionality.\n",
        "    :param x: input tensor\n",
        "    :param rounding_threshold: threshold for rounding\n",
        "    :param is_sample: flag to sample randomly from feasible area\n",
        "    :return: randomly sampled feasible version of x\n",
        "    \"\"\"\n",
        "    if is_sample:\n",
        "        rand_x = round_x(torch.rand(x.size()), initial_rounding_threshold=initial_rounding_threshold)\n",
        "        return (rand_x.byte() | x.byte()).float()\n",
        "    else:\n",
        "        return x\n",
        "\n",
        "def or_float_tensors(x_1, x_2):\n",
        "    \"\"\"\n",
        "    ORs two float tensors by converting them to byte and back.\n",
        "    :param x_1: tensor one\n",
        "    :param x_2: tensor two\n",
        "    :return: float tensor of 0s and 1s\n",
        "    \"\"\"\n",
        "    return (x_1.byte() | x_2.byte()).float()\n",
        "\n",
        "\n",
        "def xor_float_tensors(x_1, x_2):\n",
        "    \"\"\"\n",
        "    XORs two float tensors by converting them to byte and back\n",
        "    Note that byte() takes the first 8 bit after the decimal point of the float\n",
        "    e.g., 0.0 ==> 0\n",
        "          0.1 ==> 0\n",
        "          1.1 ==> 1\n",
        "        255.1 ==> 255\n",
        "        256.1 ==> 0\n",
        "    Subsequently the purpose of this function is to map 1s float tensors to 1\n",
        "    and those of 0s to 0. I.e., it is meant to be used on tensors of 0s and 1s.\n",
        "\n",
        "    :param x_1: tensor one\n",
        "    :param x_2: tensor two\n",
        "    :return: float tensor of 0s and 1s.\n",
        "    \"\"\"\n",
        "    return (x_1.byte() ^ x_2.byte()).float()\n",
        "\n",
        "def get_loss(model, adv_x, label):\n",
        "    \"\"\"\n",
        "    Compute the loss and prediction correctness.\n",
        "\n",
        "    Parameters:\n",
        "    - model: torch.nn.Module, a victim model\n",
        "    - adv_x: torch.FloatTensor, the adversarially perturbed input samples\n",
        "    - label: torch.LongTensor, ground truth labels\n",
        "\n",
        "    Returns:\n",
        "    - loss_no_reduction: torch.FloatTensor, the computed loss without reduction\n",
        "    - done: torch.BoolTensor, a tensor indicating if the prediction is incorrect\n",
        "    \"\"\"\n",
        "    y_prob = model(adv_x)\n",
        "    loss_no_reduction = nn.BCELoss(reduction='none')(y_prob, label)\n",
        "    y_pred = (y_prob >= 0.5).float()  # Threshold at 0.5\n",
        "    done = (y_pred != label).squeeze()\n",
        "\n",
        "    return loss_no_reduction, done"
      ],
      "metadata": {
        "id": "XCbqeJ84gfDD"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "x_1 = torch.tensor([1.0, 1.0,  1.0, 1.0, 1.0, 0.0,  0.0, 0.2])\n",
        "x_2 = torch.tensor([0.0, 0.6, -0.2, 0.9, 1.9, 1.0, -0.2, 0.3])\n",
        "result = or_float_tensors(x_1, x_2)\n",
        "             tensor([1., 1., 1., 1., 1., 1., 0., 0.])\n",
        "\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "w1QRWuCbdFqD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dfgsm_k(x, y, model, k=25, epsilon=0.02, alpha=1., initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False):\n",
        "    \"\"\"\n",
        "    FGSM^k with deterministic rounding\n",
        "    :param y: ground truth labels\n",
        "    :param x: feature vector\n",
        "    :param model: neural network model\n",
        "    :param k: number of steps\n",
        "    :param epsilon: update value in each direction\n",
        "    :param alpha: hyperparameter for controlling the portionate of rounding\n",
        "    :param initial_rounding_threshold: threshold parameter for rounding the initial x_next\n",
        "    :param round_threshold: threshold parameter for rounding\n",
        "    :param is_report_loss_diff: flag to report loss difference\n",
        "    :param is_sample: flag to sample randomly from the feasible area\n",
        "    :return: the adversarial version of x according to dfgsm_k (tensor)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Compute natural loss\n",
        "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "    loss_natural = criterion(model(x), y.view(-1).long())\n",
        "\n",
        "    # Initialize starting point\n",
        "    x_next = x.clone()\n",
        "    x_next = get_x0(x_next, initial_rounding_threshold, is_sample)\n",
        "\n",
        "    # Multi-step\n",
        "    for t in range(k):\n",
        "        # Forward pass\n",
        "        x_var = x_next.clone().detach().requires_grad_(True)\n",
        "        y_model = model(x_var)\n",
        "        loss = criterion(y_model, y.view(-1).long())\n",
        "\n",
        "        # Compute gradient\n",
        "        grad_vars = torch.autograd.grad(loss.mean(), x_var)\n",
        "        # Find the next sample\n",
        "        x_next = x_next + epsilon * torch.sign(grad_vars[0].data)\n",
        "\n",
        "        # Projection\n",
        "        x_next = torch.clamp(x_next, min=0., max=1.)\n",
        "\n",
        "    # Rounding step\n",
        "    if random:\n",
        "       round_threshold = torch.rand(x_next.size()) * alpha\n",
        "    x_next = round_x(x_next, round_threshold=round_threshold)\n",
        "\n",
        "    # Feasible projection\n",
        "    x_next = or_float_tensors(x_next, x)\n",
        "\n",
        "    # Compute adversarial loss\n",
        "    loss_adv = criterion(model(x_next), y.view(-1).long()).data\n",
        "\n",
        "    if is_report_loss_diff:\n",
        "        #print(f\"Natural loss: {loss_natural.mean():.4f}, Adversarial loss: {loss_adv.mean():.4f}, Difference: {(loss_adv.mean() - loss_natural.mean()):.4f}\")\n",
        "        outputs = model(x_next)\n",
        "        _, predicted = torch.topk(outputs, k=1)\n",
        "        done = (predicted != y).squeeze()\n",
        "        print(f\"rFGSM: attack effectiveness {done.sum().item() / x.size()[0] * 100:.3f}%.\")\n",
        "\n",
        "    # Replace with natural if adversarial loss is higher\n",
        "    replace_flag = (loss_adv < loss_natural).squeeze()\n",
        "    x_next[replace_flag] = x[replace_flag]\n",
        "\n",
        "    return x_next\n"
      ],
      "metadata": {
        "id": "H6BiF-vCHLlH"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_adv = dfgsm_k(X,y,model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTlgFwyKr3ex",
        "outputId": "a6222aeb-bc95-4c76-c992-02f1a85e6552"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rFGSM: attack effectiveness 100.000%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_adv = dfgsm_k(X,y,model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X10_IhqiAZSB",
        "outputId": "e6315ef3-8c0f-4331-bdb7-0e788ad18d3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Natural loss: 0.0060, Adversarial loss: 2221.2881, Difference: 2221.2820\n",
            "rFGSM: attack effectiveness 100.000%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.sum()/batch_size)\n",
        "print(x_adv.sum()/batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GafR_uFI7_l",
        "outputId": "3917d133-5f53-4eb3-c117-35b756c92b09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(26.6289)\n",
            "tensor(3986.6562)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_adv = dfgsm_k(X,y,model,random=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4xLg9HYZ9s7",
        "outputId": "d32bb793-7d39-4f67-d414-4cb1ce14adf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Natural loss: 0.0060, Adversarial loss: 1290.9233, Difference: 1290.9174\n",
            "rFGSM: attack effectiveness 100.000%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.sum()/batch_size)\n",
        "print(x_adv.sum()/batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmZlatNbaN8G",
        "outputId": "aea07910-0b65-4707-b22b-7cada23fc851"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(26.6289)\n",
            "tensor(2741.3125)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_adv = dfgsm_k(X,y,model,k=1,random=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KayY50GaVVB",
        "outputId": "04ff7813-9251-4157-e8da-f50dbe8cba7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Natural loss: 0.0060, Adversarial loss: 38.6829, Difference: 38.6769\n",
            "rFGSM: attack effectiveness 100.000%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.sum()/batch_size)\n",
        "print(x_adv.sum()/batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bx3Eyhemae7F",
        "outputId": "f34d260a-58c1-4d69-d0af-b4a48cc00a49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(26.6289)\n",
            "tensor(120.8047)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for alpha in range(1, 52, 10):\n",
        "  print('alpha = ',alpha)\n",
        "  x_adv = dfgsm_k(X, y, model, k=20, epsilon=0.02, alpha=alpha,random=True)\n",
        "  print(X.sum()/batch_size)\n",
        "  print(x_adv.sum()/batch_size)\n",
        "  print('***************************')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ue3RTg7WVOvD",
        "outputId": "dc2aa351-fea9-4389-9fc0-d4c79bfac7ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "alpha =  1\n",
            "rFGSM: attack effectiveness 100.000%.\n",
            "tensor(28.0148)\n",
            "tensor(2189.4138)\n",
            "***************************\n",
            "alpha =  11\n",
            "rFGSM: attack effectiveness 100.000%.\n",
            "tensor(28.0148)\n",
            "tensor(222.7241)\n",
            "***************************\n",
            "alpha =  21\n",
            "rFGSM: attack effectiveness 100.000%.\n",
            "tensor(28.0148)\n",
            "tensor(132.2562)\n",
            "***************************\n",
            "alpha =  31\n",
            "rFGSM: attack effectiveness 99.507%.\n",
            "tensor(28.0148)\n",
            "tensor(98.3202)\n",
            "***************************\n",
            "alpha =  41\n",
            "rFGSM: attack effectiveness 94.581%.\n",
            "tensor(28.0148)\n",
            "tensor(80.3054)\n",
            "***************************\n",
            "alpha =  51\n",
            "rFGSM: attack effectiveness 91.626%.\n",
            "tensor(28.0148)\n",
            "tensor(70.1970)\n",
            "***************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_samples = 0\n",
        "total_attack_success = 0\n",
        "total_features_x = 0\n",
        "total_features_x_adv = 0\n",
        "\n",
        "for X, y in test_loader:\n",
        "    batch_size = X.size(0)\n",
        "    x_adv = dfgsm_k(X, y, model, k=20, epsilon=0.0005, random=True,is_report_loss_diff=False)\n",
        "\n",
        "    # Compute mean number of features\n",
        "    total_features_x += X.sum().item()\n",
        "    total_features_x_adv += x_adv.sum().item()\n",
        "\n",
        "    # Compute attack effectiveness for this batch\n",
        "    outputs_adv = model(x_adv)\n",
        "    _, predicted_adv = torch.topk(outputs_adv, k=1)\n",
        "    total_attack_success += torch.sum(predicted_adv != y).item()\n",
        "    total_samples += batch_size\n",
        "\n",
        "# Compute mean number of features\n",
        "mean_features_x = total_features_x / total_samples\n",
        "mean_features_x_adv = total_features_x_adv / total_samples\n",
        "\n",
        "# Compute mean attack effectiveness\n",
        "mean_attack_effectiveness = (total_attack_success / total_samples) * 100\n",
        "\n",
        "# Print results\n",
        "print('Mean number of features (X):', mean_features_x)\n",
        "print('Mean number of features (X_adv):', mean_features_x_adv)\n",
        "print('Mean attack effectiveness:', mean_attack_effectiveness)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qI8_L180z03g",
        "outputId": "65020b0e-05f6-40a8-936b-3bfbd451c886"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean number of features (X): 27.5364492500872\n",
            "Mean number of features (X_adv): 76.25450529008255\n",
            "Mean attack effectiveness: 98.64356857729722\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_samples = 0\n",
        "total_attack_success = 0\n",
        "total_features_x = 0\n",
        "total_features_x_adv = 0\n",
        "\n",
        "for X, y in test_loader:\n",
        "    batch_size = X.size(0)\n",
        "    x_adv = dfgsm_k(X, y, model, k=20, epsilon=0.02, alpha=40,random=True,is_report_loss_diff=False)\n",
        "\n",
        "    # Compute mean number of features\n",
        "    total_features_x += X.sum().item()\n",
        "    total_features_x_adv += x_adv.sum().item()\n",
        "\n",
        "    # Compute attack effectiveness for this batch\n",
        "    outputs_adv = model(x_adv)\n",
        "    _, predicted_adv = torch.topk(outputs_adv, k=1)\n",
        "    total_attack_success += torch.sum(predicted_adv != y).item()\n",
        "    total_samples += batch_size\n",
        "\n",
        "# Compute mean number of features\n",
        "mean_features_x = total_features_x / total_samples\n",
        "mean_features_x_adv = total_features_x_adv / total_samples\n",
        "\n",
        "# Compute mean attack effectiveness\n",
        "mean_attack_effectiveness = (total_attack_success / total_samples) * 100\n",
        "\n",
        "# Print results\n",
        "print('Mean number of features (X):', mean_features_x)\n",
        "print('Mean number of features (X_adv):', mean_features_x_adv)\n",
        "print('Mean attack effectiveness:', mean_attack_effectiveness)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-c7gxOHmXqv",
        "outputId": "29185cf1-413e-48ec-c2e2-91994ee67ee6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean number of features (X): 27.5364492500872\n",
            "Mean number of features (X_adv): 81.65845056776344\n",
            "Mean attack effectiveness: 96.50428244777738\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def dfgsm_k2(x, y, model, k=25, epsilon=0.02, alpha=1., initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False):\n",
        "    \"\"\"\n",
        "    FGSM^k with deterministic rounding\n",
        "    :param y: ground truth labels\n",
        "    :param x: feature vector\n",
        "    :param model: neural network model\n",
        "    :param k: number of steps\n",
        "    :param epsilon: update value in each direction\n",
        "    :param alpha: hyperparameter for controlling the portionate of rounding\n",
        "    :param initial_rounding_threshold: threshold parameter for rounding the initial x_next\n",
        "    :param round_threshold: threshold parameter for rounding\n",
        "    :param is_report_loss_diff: flag to report loss difference\n",
        "    :param is_sample: flag to sample randomly from the feasible area\n",
        "    :return: the adversarial version of x according to dfgsm_k (tensor)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Compute natural loss\n",
        "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "    loss_natural = criterion(model(x), y.view(-1).long())\n",
        "\n",
        "    # Initialize starting point\n",
        "    x_next = x.clone()\n",
        "    x_next = get_x0(x_next, initial_rounding_threshold, is_sample)\n",
        "\n",
        "    # Multi-step\n",
        "    for t in range(k):\n",
        "        # Forward pass\n",
        "        x_var = x_next.clone().detach().requires_grad_(True)\n",
        "        y_model = model(x_var)\n",
        "        loss = criterion(y_model, y.view(-1).long())\n",
        "\n",
        "        # Compute gradient\n",
        "        grad_vars = torch.autograd.grad(loss.mean(), x_var)\n",
        "        #print(torch.sign(grad_vars[0].data).clamp(min=0))\n",
        "        # Find the next sample\n",
        "        x_next = x_next + epsilon * (torch.sign(grad_vars[0].data).clamp(min=0))\n",
        "\n",
        "        # Projection\n",
        "        x_next = torch.clamp(x_next, min=0., max=1.)\n",
        "\n",
        "    # Rounding step\n",
        "    if random:\n",
        "       round_threshold = torch.rand(x_next.size()) * alpha\n",
        "    x_next = round_x(x_next, round_threshold=round_threshold)\n",
        "\n",
        "    # Feasible projection\n",
        "    x_next = or_float_tensors(x_next, x)\n",
        "\n",
        "    # Compute adversarial loss\n",
        "    loss_adv = criterion(model(x_next), y.view(-1).long()).data\n",
        "\n",
        "    if is_report_loss_diff:\n",
        "        #print(f\"Natural loss: {loss_natural.mean():.4f}, Adversarial loss: {loss_adv.mean():.4f}, Difference: {(loss_adv.mean() - loss_natural.mean()):.4f}\")\n",
        "        outputs = model(x_next)\n",
        "        _, predicted = torch.topk(outputs, k=1)\n",
        "        done = (predicted != y).squeeze()\n",
        "        print(f\"rFGSM: attack effectiveness {done.sum().item() / x.size()[0] * 100:.3f}%.\")\n",
        "\n",
        "    # Replace with natural if adversarial loss is higher\n",
        "    replace_flag = (loss_adv < loss_natural).squeeze()\n",
        "    x_next[replace_flag] = x[replace_flag]\n",
        "\n",
        "    return x_next"
      ],
      "metadata": {
        "id": "jJHs7RsgsHMS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_adv = dfgsm_k2(X[:1],y[:1],model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GfFMDVbEsJzQ",
        "outputId": "eb00fd42-fc84-4c02-d9bd-d389aee31d88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rFGSM: attack effectiveness 100.000%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for alpha in range(1, 52, 10):\n",
        "  print('alpha = ',alpha)\n",
        "  x_adv = dfgsm_k2(X, y, model, k=20, epsilon=0.02, alpha=alpha,random=True)\n",
        "  print(X.sum()/batch_size)\n",
        "  print(x_adv.sum()/batch_size)\n",
        "  print('***************************')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5povafNsuLV",
        "outputId": "15d13143-21aa-4028-f107-5814f26b046c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "alpha =  1\n",
            "rFGSM: attack effectiveness 100.000%.\n",
            "tensor(28.0148)\n",
            "tensor(2246.3103)\n",
            "***************************\n",
            "alpha =  11\n",
            "rFGSM: attack effectiveness 100.000%.\n",
            "tensor(28.0148)\n",
            "tensor(228.2020)\n",
            "***************************\n",
            "alpha =  21\n",
            "rFGSM: attack effectiveness 100.000%.\n",
            "tensor(28.0148)\n",
            "tensor(132.3547)\n",
            "***************************\n",
            "alpha =  31\n",
            "rFGSM: attack effectiveness 99.507%.\n",
            "tensor(28.0148)\n",
            "tensor(98.7537)\n",
            "***************************\n",
            "alpha =  41\n",
            "rFGSM: attack effectiveness 98.030%.\n",
            "tensor(28.0148)\n",
            "tensor(82.3054)\n",
            "***************************\n",
            "alpha =  51\n",
            "rFGSM: attack effectiveness 88.177%.\n",
            "tensor(28.0148)\n",
            "tensor(71.4335)\n",
            "***************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_samples = 0\n",
        "total_attack_success = 0\n",
        "total_features_x = 0\n",
        "total_features_x_adv = 0\n",
        "\n",
        "for X, y in test_loader:\n",
        "    batch_size = X.size(0)\n",
        "    x_adv = dfgsm_k2(X, y, model, k=20, epsilon=0.02, alpha=40,random=True,is_report_loss_diff=False)\n",
        "\n",
        "    # Compute mean number of features\n",
        "    total_features_x += X.sum().item()\n",
        "    total_features_x_adv += x_adv.sum().item()\n",
        "\n",
        "    # Compute attack effectiveness for this batch\n",
        "    outputs_adv = model(x_adv)\n",
        "    _, predicted_adv = torch.topk(outputs_adv, k=1)\n",
        "    total_attack_success += torch.sum(predicted_adv != y).item()\n",
        "    total_samples += batch_size\n",
        "\n",
        "# Compute mean number of features\n",
        "mean_features_x = total_features_x / total_samples\n",
        "mean_features_x_adv = total_features_x_adv / total_samples\n",
        "\n",
        "# Compute mean attack effectiveness\n",
        "mean_attack_effectiveness = (total_attack_success / total_samples) * 100\n",
        "\n",
        "# Print results\n",
        "print('Mean number of features (X):', mean_features_x)\n",
        "print('Mean number of features (X_adv):', mean_features_x_adv)\n",
        "print('Mean attack effectiveness:', mean_attack_effectiveness)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJDq5_oZtPSW",
        "outputId": "7391b1a7-40a1-464c-a934-fdd4c21b118f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean number of features (X): 27.5364492500872\n",
            "Mean number of features (X_adv): 82.96155485796226\n",
            "Mean attack effectiveness: 96.48878037437507\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ".clone(): This method creates a deep copy of the tensor, including its data and gradients (if any). It essentially creates a new tensor with the same data and properties as the original tensor. If the original tensor is part of a computation graph and requires gradients, the cloned tensor will also be part of the same computation graph and will require gradients. Any changes made to the cloned tensor will not affect the original tensor, and vice versa.\n",
        "\n",
        ".copy(): This method creates a shallow copy of the tensor. It only copies the data, not the computational graph or gradients. Therefore, the copied tensor will be detached from any computation graph and will not require gradients, even if the original tensor did. Changes made to the copied tensor will not affect the original tensor, but changes in the original tensor's data will be reflected in the copied tensor.\n",
        "\n"
      ],
      "metadata": {
        "id": "DxHlKdaVI5bQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def bga_k(x, y, model, k=25, alpha=1., is_report_loss_diff=True, use_sample=False):\n",
        "    \"\"\"\n",
        "    Multi-step bit gradient ascent\n",
        "    :param x: feature vector\n",
        "    :param y: ground truth labels\n",
        "    :param model: neural network model\n",
        "    :param k: number of steps\n",
        "    :param alpha: hyperparameter for controlling updates\n",
        "    :param is_report_loss_diff: flag to report loss difference\n",
        "    :param use_sample: flag to sample randomly from the feasible area\n",
        "    :return: the adversarial version of x according to bga_k (tensor)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Compute natural loss\n",
        "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "    loss_natural = criterion(model(x), y.view(-1).long())\n",
        "\n",
        "    # Initialize worst loss and corresponding adversarial samples\n",
        "    loss_worst = loss_natural.clone()\n",
        "    x_worst = x.clone()\n",
        "\n",
        "    # Book-keeping\n",
        "    sqrt_m = torch.sqrt(torch.tensor([x.size()[1]], dtype=torch.float))\n",
        "\n",
        "    # Multi-step with gradients\n",
        "    for t in range(k):\n",
        "        if t == 0:\n",
        "            # Initialize starting point\n",
        "            x_next = get_x0(x, use_sample)\n",
        "        else:\n",
        "            # Compute gradient\n",
        "            grad_vars = torch.autograd.grad(loss.mean(), x_var)\n",
        "            grad_data = grad_vars[0].data\n",
        "\n",
        "            # Compute the updates\n",
        "            # torch.norm(grad_data, 2, 1), 2:the L2-norm , 1:the norm along dimension 1\n",
        "            x_update = (sqrt_m * (1. - 2. * x_next) * grad_data >= (alpha * torch.norm(grad_data, 2, 1).unsqueeze(1))).float()\n",
        "\n",
        "            # Find the next sample with projection to the feasible set\n",
        "            x_next = xor_float_tensors(x_update, x_next)\n",
        "            x_next = or_float_tensors(x_next, x)\n",
        "\n",
        "        # Forward pass\n",
        "        x_var = x_next.clone().detach().requires_grad_(True)\n",
        "        y_model = model(x_var)\n",
        "        loss = criterion(y_model, y.view(-1).long())\n",
        "\n",
        "        # Update worst loss and adversarial samples\n",
        "        replace_flag = (loss.data > loss_worst)\n",
        "        loss_worst[replace_flag] = loss.data[replace_flag]\n",
        "        x_worst[replace_flag] = x_next[replace_flag]\n",
        "\n",
        "    if is_report_loss_diff:\n",
        "        #print(f\"Natural loss: {loss_natural.mean():.4f}, Adversarial loss: {loss_worst.mean():.4f}, Difference: {(loss_worst.mean() - loss_natural.mean()):.4f}\")\n",
        "        outputs = model(x_worst)\n",
        "        _, predicted = torch.topk(outputs, k=1)\n",
        "        done = (predicted != y).squeeze()\n",
        "        print(f\"bga_k: attack effectiveness {done.sum().item() / x.size()[0] * 100:.3f}%.\")\n",
        "\n",
        "    return x_worst\n"
      ],
      "metadata": {
        "id": "V_1x56e5UYFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_adv = bga_k(X, y, model, k=25, is_report_loss_diff=True, use_sample=False)\n",
        "print(X.sum()/batch_size)\n",
        "print(x_adv.sum()/batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trFNZQ0HLMZ8",
        "outputId": "8921d8d7-7c8a-4ea0-eac6-2d8d34cda80f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bga_k: attack effectiveness 100.000%.\n",
            "tensor(26.6289)\n",
            "tensor(2297.2891)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for alpha in range(1,6):\n",
        "  print('alpha = ',alpha)\n",
        "  x_adv = bga_k(X, y, model, k=25, alpha=alpha, is_report_loss_diff=True, use_sample=False)\n",
        "  print(X.sum()/batch_size)\n",
        "  print(x_adv.sum()/batch_size)\n",
        "  print('***************************')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0MiPWLHR2th",
        "outputId": "293c61a8-4984-499f-ba34-322d6e3dd5b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "alpha =  1\n",
            "rFGSM: attack effectiveness 100.000%.\n",
            "tensor(28.0148)\n",
            "tensor(2289.4089)\n",
            "***************************\n",
            "alpha =  2\n",
            "rFGSM: attack effectiveness 100.000%.\n",
            "tensor(28.0148)\n",
            "tensor(577.0690)\n",
            "***************************\n",
            "alpha =  3\n",
            "rFGSM: attack effectiveness 100.000%.\n",
            "tensor(28.0148)\n",
            "tensor(185.2315)\n",
            "***************************\n",
            "alpha =  4\n",
            "rFGSM: attack effectiveness 95.567%.\n",
            "tensor(28.0148)\n",
            "tensor(71.5714)\n",
            "***************************\n",
            "alpha =  5\n",
            "rFGSM: attack effectiveness 1.478%.\n",
            "tensor(28.0148)\n",
            "tensor(28.0887)\n",
            "***************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def bca_k(x, y, model, k=25, is_report_loss_diff=True, use_sample=False):\n",
        "    \"\"\"\n",
        "    Multi-step bit coordinate ascent\n",
        "    :param use_sample:\n",
        "    :param is_report_loss_diff:\n",
        "    :param y:\n",
        "    :param x: (tensor) feature vector\n",
        "    :param model: nn model\n",
        "    :param k: num of steps\n",
        "    :return: the adversarial version of x according to bca_k (tensor)\n",
        "    \"\"\"\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    # Compute natural loss\n",
        "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "    loss_natural = criterion(model(x), y.view(-1).long())\n",
        "\n",
        "    # keeping worst loss\n",
        "    loss_worst = loss_natural.clone()\n",
        "    x_worst = x.clone()\n",
        "\n",
        "    # multi-step with gradients\n",
        "    loss = None\n",
        "    x_var = None\n",
        "    x_next = None\n",
        "    for t in range(k):\n",
        "        if t == 0:\n",
        "            # initialize starting point\n",
        "            x_next = get_x0(x, use_sample)\n",
        "        else:\n",
        "            # compute gradient\n",
        "            grad_vars = torch.autograd.grad(loss.mean(), x_var)\n",
        "            grad_data = grad_vars[0].data\n",
        "\n",
        "            # compute the updates (can be made more efficient than this)\n",
        "            aug_grad = (1. - 2. * x_next) * grad_data\n",
        "            val, _ = torch.topk(aug_grad, 1)\n",
        "            x_update = (aug_grad >= val.expand_as(aug_grad)).float()\n",
        "\n",
        "            # find the next sample with projection to the feasible set\n",
        "            x_next = xor_float_tensors(x_update, x_next)\n",
        "            x_next = or_float_tensors(x_next, x)\n",
        "\n",
        "        # forward pass\n",
        "        x_var = x_next.clone().detach().requires_grad_(True)\n",
        "        y_model = model(x_var)\n",
        "        loss = criterion(y_model, y.view(-1).long())\n",
        "\n",
        "        # update worst loss and adversarial samples\n",
        "        replace_flag = (loss.data > loss_worst)\n",
        "        loss_worst[replace_flag] = loss.data[replace_flag]\n",
        "        x_worst[replace_flag] = x_next[replace_flag]\n",
        "\n",
        "    if is_report_loss_diff:\n",
        "        #print(\"Natural loss (%.4f) vs Adversarial loss (%.4f), Difference: (%.4f)\" %(loss_natural.mean(), loss_worst.mean(), loss_worst.mean() - loss_natural.mean()))\n",
        "        outputs = model(x_worst)\n",
        "        _, predicted = torch.topk(outputs, k=1)\n",
        "        done = (predicted != y).squeeze()\n",
        "        print(f\"bca_k: attack effectiveness {done.sum().item() / x.size()[0] * 100:.3f}%.\")\n",
        "\n",
        "\n",
        "\n",
        "    return x_worst"
      ],
      "metadata": {
        "id": "l5w-UPPVeDe5"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XcHWWydFh1n0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_adv = bca_k(X, y, model, k=3, is_report_loss_diff=True, use_sample=False)\n",
        "print(X.sum()/batch_size)\n",
        "print(x_adv.sum()/batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZKn-cfefC4m",
        "outputId": "72215200-69ed-42d2-fafa-674a9d65cc0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bca_k: attack effectiveness 44.922%.\n",
            "tensor(26.6289)\n",
            "tensor(28.5430)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for k in range(5, 55, 5):\n",
        "  print('k = ',k)\n",
        "  x_adv = bca_k(X, y, model, k=k, is_report_loss_diff=True, use_sample=False)\n",
        "  print(X.sum()/batch_size)\n",
        "  print(x_adv.sum()/batch_size)\n",
        "  print('***************************')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knqrt4j9fcBp",
        "outputId": "44c53b1c-67e3-4af8-9de2-cd493ea83963"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "k =  5\n",
            "bca_k: attack effectiveness 91.406%.\n",
            "tensor(26.6289)\n",
            "tensor(30.5039)\n",
            "***************************\n",
            "k =  10\n",
            "bca_k: attack effectiveness 97.266%.\n",
            "tensor(26.6289)\n",
            "tensor(35.3906)\n",
            "***************************\n",
            "k =  15\n",
            "bca_k: attack effectiveness 97.266%.\n",
            "tensor(26.6289)\n",
            "tensor(40.2031)\n",
            "***************************\n",
            "k =  20\n",
            "bca_k: attack effectiveness 97.266%.\n",
            "tensor(26.6289)\n",
            "tensor(45.0078)\n",
            "***************************\n",
            "k =  25\n",
            "bca_k: attack effectiveness 97.266%.\n",
            "tensor(26.6289)\n",
            "tensor(49.8125)\n",
            "***************************\n",
            "k =  30\n",
            "bca_k: attack effectiveness 97.266%.\n",
            "tensor(26.6289)\n",
            "tensor(54.6172)\n",
            "***************************\n",
            "k =  35\n",
            "bca_k: attack effectiveness 97.266%.\n",
            "tensor(26.6289)\n",
            "tensor(59.4219)\n",
            "***************************\n",
            "k =  40\n",
            "bca_k: attack effectiveness 97.266%.\n",
            "tensor(26.6289)\n",
            "tensor(64.2266)\n",
            "***************************\n",
            "k =  45\n",
            "bca_k: attack effectiveness 97.266%.\n",
            "tensor(26.6289)\n",
            "tensor(69.0312)\n",
            "***************************\n",
            "k =  50\n",
            "bca_k: attack effectiveness 97.266%.\n",
            "tensor(26.6289)\n",
            "tensor(73.8359)\n",
            "***************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.rand((10,10000))\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HjDiJdVfjyL8",
        "outputId": "15778f2a-0553-4db1-82ee-3a7b46b0dc72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2620, 0.9656, 0.6516,  ..., 0.0038, 0.3084, 0.7131],\n",
              "        [0.5588, 0.2493, 0.0950,  ..., 0.9978, 0.9718, 0.1974],\n",
              "        [0.7188, 0.9575, 0.2771,  ..., 0.1128, 0.0172, 0.7418],\n",
              "        ...,\n",
              "        [0.0582, 0.2115, 0.6837,  ..., 0.8870, 0.7203, 0.6274],\n",
              "        [0.7887, 0.0591, 0.3733,  ..., 0.8148, 0.6377, 0.2545],\n",
              "        [0.6163, 0.1027, 0.4877,  ..., 0.8024, 0.8279, 0.1123]])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val, index = torch.topk(a, 10)"
      ],
      "metadata": {
        "id": "Yhh5P37vi8JE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val[:,-1:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4qsw0r3xjEXz",
        "outputId": "577b20d0-c66f-4a6b-936c-a26fc195c43f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.9994],\n",
              "        [0.9992],\n",
              "        [0.9989],\n",
              "        [0.9990],\n",
              "        [0.9992],\n",
              "        [0.9993],\n",
              "        [0.9993],\n",
              "        [0.9988],\n",
              "        [0.9993],\n",
              "        [0.9990]])"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def bca_k2(x, y, model, k=25, alpha=1, is_report_loss_diff=True, use_sample=False):\n",
        "    \"\"\"\n",
        "    Multi-step bit coordinate ascent\n",
        "    :param use_sample:\n",
        "    :param is_report_loss_diff:\n",
        "    :param y:\n",
        "    :param x: (tensor) feature vector\n",
        "    :param model: nn model\n",
        "    :param k: num of steps\n",
        "    :param alpha: top k gradients\n",
        "    :return: the adversarial version of x according to bca_k (tensor)\n",
        "    \"\"\"\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    # Compute natural loss\n",
        "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "    loss_natural = criterion(model(x), y.view(-1).long())\n",
        "\n",
        "    # keeping worst loss\n",
        "    loss_worst = loss_natural.clone()\n",
        "    x_worst = x.clone()\n",
        "\n",
        "    # multi-step with gradients\n",
        "    loss = None\n",
        "    x_var = None\n",
        "    x_next = None\n",
        "    for t in range(k):\n",
        "        if t == 0:\n",
        "            # initialize starting point\n",
        "            x_next = get_x0(x, use_sample)\n",
        "        else:\n",
        "            # compute gradient\n",
        "            grad_vars = torch.autograd.grad(loss.mean(), x_var)\n",
        "            grad_data = grad_vars[0].data\n",
        "\n",
        "            # compute the updates (can be made more efficient than this)\n",
        "            aug_grad = (1. - 2. * x_next) * grad_data\n",
        "            val, _ = torch.topk(aug_grad, alpha)\n",
        "            x_update = (aug_grad >= val[:,-1:].expand_as(aug_grad)).float()\n",
        "\n",
        "            # find the next sample with projection to the feasible set\n",
        "            x_next = xor_float_tensors(x_update, x_next)\n",
        "            x_next = or_float_tensors(x_next, x)\n",
        "\n",
        "        # forward pass\n",
        "        x_var = x_next.clone().detach().requires_grad_(True)\n",
        "        y_model = model(x_var)\n",
        "        loss = criterion(y_model, y.view(-1).long())\n",
        "\n",
        "        # update worst loss and adversarial samples\n",
        "        replace_flag = (loss.data > loss_worst)\n",
        "        loss_worst[replace_flag] = loss.data[replace_flag]\n",
        "        x_worst[replace_flag] = x_next[replace_flag]\n",
        "\n",
        "    if is_report_loss_diff:\n",
        "        #print(\"Natural loss (%.4f) vs Adversarial loss (%.4f), Difference: (%.4f)\" %(loss_natural.mean(), loss_worst.mean(), loss_worst.mean() - loss_natural.mean()))\n",
        "        outputs = model(x_worst)\n",
        "        _, predicted = torch.topk(outputs, k=1)\n",
        "        done = (predicted != y).squeeze()\n",
        "        print(f\"bca_k: attack effectiveness {done.sum().item() / x.size()[0] * 100:.3f}%.\")\n",
        "\n",
        "\n",
        "\n",
        "    return x_worst"
      ],
      "metadata": {
        "id": "ONJMTgcojcB1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for k in range(2, 9):\n",
        "  print('k = ',k)\n",
        "  x_adv = bca_k2(X, y, model, k=k, alpha=5, is_report_loss_diff=True, use_sample=False)\n",
        "  print(X.sum()/batch_size)\n",
        "  print(x_adv.sum()/batch_size)\n",
        "  print('***************************')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dP95NXQHkbLu",
        "outputId": "91c580de-01cb-4574-e75a-baefe2b6d9ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "k =  2\n",
            "bca_k: attack effectiveness 94.922%.\n",
            "tensor(26.6289)\n",
            "tensor(31.5430)\n",
            "***************************\n",
            "k =  3\n",
            "bca_k: attack effectiveness 99.609%.\n",
            "tensor(26.6289)\n",
            "tensor(36.5195)\n",
            "***************************\n",
            "k =  4\n",
            "bca_k: attack effectiveness 99.609%.\n",
            "tensor(26.6289)\n",
            "tensor(41.4805)\n",
            "***************************\n",
            "k =  5\n",
            "bca_k: attack effectiveness 99.609%.\n",
            "tensor(26.6289)\n",
            "tensor(46.4453)\n",
            "***************************\n",
            "k =  6\n",
            "bca_k: attack effectiveness 99.609%.\n",
            "tensor(26.6289)\n",
            "tensor(51.4102)\n",
            "***************************\n",
            "k =  7\n",
            "bca_k: attack effectiveness 99.609%.\n",
            "tensor(26.6289)\n",
            "tensor(56.3750)\n",
            "***************************\n",
            "k =  8\n",
            "bca_k: attack effectiveness 100.000%.\n",
            "tensor(26.6289)\n",
            "tensor(61.3477)\n",
            "***************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1, 12):\n",
        "  print('top k = ',i)\n",
        "  x_adv = bca_k2(X, y, model, k=2, alpha=i, is_report_loss_diff=True, use_sample=False)\n",
        "  print(X.sum()/batch_size)\n",
        "  print(x_adv.sum()/batch_size)\n",
        "  print('***************************')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7de41H0mq5B",
        "outputId": "277ee99e-b4a3-4fe6-c61f-bdaeae92d582"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "top k =  1\n",
            "bca_k: attack effectiveness 4.688%.\n",
            "tensor(26.6289)\n",
            "tensor(27.5664)\n",
            "***************************\n",
            "top k =  2\n",
            "bca_k: attack effectiveness 37.500%.\n",
            "tensor(26.6289)\n",
            "tensor(28.5508)\n",
            "***************************\n",
            "top k =  3\n",
            "bca_k: attack effectiveness 75.391%.\n",
            "tensor(26.6289)\n",
            "tensor(29.5352)\n",
            "***************************\n",
            "top k =  4\n",
            "bca_k: attack effectiveness 91.016%.\n",
            "tensor(26.6289)\n",
            "tensor(30.5430)\n",
            "***************************\n",
            "top k =  5\n",
            "bca_k: attack effectiveness 94.922%.\n",
            "tensor(26.6289)\n",
            "tensor(31.5430)\n",
            "***************************\n",
            "top k =  6\n",
            "bca_k: attack effectiveness 96.094%.\n",
            "tensor(26.6289)\n",
            "tensor(32.5391)\n",
            "***************************\n",
            "top k =  7\n",
            "bca_k: attack effectiveness 97.266%.\n",
            "tensor(26.6289)\n",
            "tensor(33.5234)\n",
            "***************************\n",
            "top k =  8\n",
            "bca_k: attack effectiveness 98.828%.\n",
            "tensor(26.6289)\n",
            "tensor(34.5195)\n",
            "***************************\n",
            "top k =  9\n",
            "bca_k: attack effectiveness 99.219%.\n",
            "tensor(26.6289)\n",
            "tensor(35.5078)\n",
            "***************************\n",
            "top k =  10\n",
            "bca_k: attack effectiveness 99.609%.\n",
            "tensor(26.6289)\n",
            "tensor(36.5039)\n",
            "***************************\n",
            "top k =  11\n",
            "bca_k: attack effectiveness 99.609%.\n",
            "tensor(26.6289)\n",
            "tensor(37.4961)\n",
            "***************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def grosse_k(x, y, model, k=25, is_report_loss_diff=True, use_sample=False):\n",
        "    \"\"\"\n",
        "    Multi-step bit coordinate ascent\n",
        "    :param use_sample:\n",
        "    :param is_report_loss_diff:\n",
        "    :param y:\n",
        "    :param x: (tensor) feature vector\n",
        "    :param model: nn model\n",
        "    :param k: num of steps\n",
        "    :return: the adversarial version of x according to bca_k (tensor)\n",
        "    \"\"\"\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    # Compute natural loss\n",
        "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "    loss_natural = criterion(model(x), y.view(-1).long())\n",
        "\n",
        "    # keeping worst loss\n",
        "    loss_worst = loss_natural.clone()\n",
        "    x_worst = x.clone()\n",
        "\n",
        "    # multi-step with gradients\n",
        "    output = None\n",
        "    x_var = None\n",
        "    x_next = None\n",
        "    for t in range(k):\n",
        "        if t == 0:\n",
        "            # initialize starting point\n",
        "            x_next = get_x0(x, use_sample)\n",
        "        else:\n",
        "            # compute gradient\n",
        "            # ouput.shape=([batch_size, 2]) because of 2 neoruns, so we just use the output of the first neorun(benign)\n",
        "            grad_vars = torch.autograd.grad(output[:, 0].mean(), x_var)\n",
        "            grad_data = grad_vars[0].data\n",
        "\n",
        "            # compute the updates (can be made more efficient than this)\n",
        "            aug_grad = (1. - x_next) * grad_data\n",
        "            val, _ = torch.topk(aug_grad, 1)\n",
        "            x_update = (aug_grad >= val.expand_as(aug_grad)).float()\n",
        "\n",
        "            # find the next sample with projection to the feasible set\n",
        "            x_next = xor_float_tensors(x_update, x_next)\n",
        "            x_next = or_float_tensors(x_next, x)\n",
        "\n",
        "        # forward pass\n",
        "        x_var = x_next.clone().detach().requires_grad_(True)\n",
        "        output = model(x_var)\n",
        "        loss = criterion(output, y.view(-1).long())\n",
        "\n",
        "        # update worst loss and adversarial samples\n",
        "        replace_flag = (loss.data > loss_worst)\n",
        "        loss_worst[replace_flag] = loss.data[replace_flag]\n",
        "        x_worst[replace_flag] = x_next[replace_flag]\n",
        "\n",
        "    if is_report_loss_diff:\n",
        "        #print(\"Natural loss (%.4f) vs Adversarial loss (%.4f), Difference: (%.4f)\" %(loss_natural.mean(), loss_worst.mean(), loss_worst.mean() - loss_natural.mean()))\n",
        "        outputs = model(x_worst)\n",
        "        _, predicted = torch.topk(outputs, k=1)\n",
        "        done = (predicted != y).squeeze()\n",
        "        print(f\"grosse_k: attack effectiveness {done.sum().item() / x.size()[0] * 100:.3f}%.\")\n",
        "\n",
        "\n",
        "\n",
        "    return x_worst"
      ],
      "metadata": {
        "id": "2jjbi-wHwYKz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grosse_k(X, y, model, k=25, is_report_loss_diff=True, use_sample=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "de8dsYkvxLz2",
        "outputId": "c82a724f-4476-45b7-8b5c-3d203d2a788b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "grosse_k: attack effectiveness 5.078%.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [1., 1., 1.,  ..., 1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pgd(x, y, model, k=25, step_length=0.02, norm='linf', initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False):\n",
        "    \"\"\"\n",
        "    Projected Gradient Descent (PGD) adversarial attack.\n",
        "    :param y: Ground truth labels\n",
        "    :param x: Feature vector\n",
        "    :param model: Neural network model\n",
        "    :param k: Number of steps\n",
        "    :param step_length: Step size for each iteration\n",
        "    :param norm: Norm used for perturbation ('linf' or 'l2')\n",
        "    :param initial_rounding_threshold: Threshold parameter for rounding the initial x_next\n",
        "    :param round_threshold: Threshold parameter for rounding\n",
        "    :param random: Flag to generate random thresholds\n",
        "    :param is_report_loss_diff: Flag to report loss difference\n",
        "    :param is_sample: Flag to sample randomly from the feasible area\n",
        "    :return: The adversarial version of x (tensor)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Compute natural loss\n",
        "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "    loss_natural = criterion(model(x), y.view(-1).long())\n",
        "\n",
        "    # Initialize starting point\n",
        "    x_next = x.clone()\n",
        "    x_next = get_x0(x_next, initial_rounding_threshold, is_sample)\n",
        "\n",
        "    # Multi-step PGD\n",
        "    for t in range(k):\n",
        "        # Forward pass\n",
        "        x_var = x_next.clone().detach().requires_grad_(True)\n",
        "        y_model = model(x_var)\n",
        "        loss = criterion(y_model, y.view(-1).long())\n",
        "\n",
        "        # Compute gradient\n",
        "        grad_vars = torch.autograd.grad(loss.mean(), x_var)\n",
        "        grad_data = grad_vars[0].data\n",
        "        gradients = grad_data * (x < 0.5)\n",
        "\n",
        "        # Norm\n",
        "        if norm == 'linf':\n",
        "            perturbation = torch.sign(gradients)\n",
        "        elif norm == 'l2':\n",
        "            l2norm = torch.linalg.norm(gradients, dim=-1, keepdim=True)\n",
        "            perturbation = torch.minimum(torch.tensor(1., dtype=x.dtype, device=x.device), gradients / l2norm)\n",
        "            perturbation[torch.isnan(perturbation)] = 0.\n",
        "            perturbation[torch.isinf(perturbation)] = 1.\n",
        "        elif norm == 'l1':\n",
        "            #ignore the gradient of indice which is updated\n",
        "            gradients = gradients * (x_next < 0.5)\n",
        "            val, _ = torch.topk(gradients, 1)\n",
        "            perturbation = torch.sign(gradients >= val.expand_as(gradients))\n",
        "            # stop perturbing the examples that are successful to evade the victim\n",
        "            outputs = model(x_next)\n",
        "            _, predicted = torch.topk(outputs, k=1)\n",
        "            done = (predicted != y).squeeze()\n",
        "            if torch.all(done):\n",
        "                break\n",
        "            perturbation[done] = 0.\n",
        "        else:\n",
        "            raise ValueError(\"Expect 'l1' or 'l2' or 'linf' norm.\")\n",
        "\n",
        "        # Update x_next\n",
        "        x_next = torch.clamp(x_next + perturbation * step_length, min=0., max=1.)\n",
        "\n",
        "    # Rounding step\n",
        "    if random:\n",
        "       round_threshold = torch.rand(x_next.size()) * round_threshold\n",
        "    x_next = round_x(x_next, round_threshold=round_threshold)\n",
        "\n",
        "    # Feasible projection\n",
        "    x_next = or_float_tensors(x_next, x)\n",
        "\n",
        "    # Compute adversarial loss\n",
        "    loss_adv = criterion(model(x_next), y.view(-1).long()).data\n",
        "\n",
        "    if is_report_loss_diff:\n",
        "        outputs = model(x_next)\n",
        "        _, predicted = torch.topk(outputs, k=1)\n",
        "        done = (predicted != y).squeeze()\n",
        "        print(f\"PGD {norm}: Attack effectiveness {done.sum().item() / x.size()[0] * 100:.3f}%.\")\n",
        "\n",
        "    # Replace with natural if adversarial loss is higher\n",
        "    replace_flag = (loss_adv < loss_natural).squeeze()\n",
        "    x_next[replace_flag] = x[replace_flag]\n",
        "\n",
        "    return x_next\n"
      ],
      "metadata": {
        "id": "j0HTVirP5Gtq"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_adv = pgd(X, y, model, k=250, step_length=0.002, norm='linf', initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False)\n",
        "print(X.sum()/batch_size)\n",
        "print(x_adv.sum()/batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1vtfW4C-sXq",
        "outputId": "6cf2b900-8bad-4937-a88e-35a0723c0fa6"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PGD: Attack effectiveness 100.000%.\n",
            "tensor(26.6289)\n",
            "tensor(3903.8359)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_adv = dfgsm_k(X, y, model, k=250, epsilon=0.002, alpha=1., initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False)\n",
        "print(X.sum()/batch_size)\n",
        "print(x_adv.sum()/batch_size)"
      ],
      "metadata": {
        "id": "XC4RZFAN8MEa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_adv = pgd(X, y, model, k=200, step_length=0.05, norm='l2', initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False)\n",
        "print(X.sum()/batch_size)\n",
        "print(x_adv.sum()/batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMf1VtXg0nmP",
        "outputId": "3055332e-975e-40e3-9a21-1fa027d2fc13"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PGD l2: Attack effectiveness 93.359%.\n",
            "tensor(26.6289)\n",
            "tensor(35.3633)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_adv = pgd(X, y, model, k=227, step_length=0.05, norm='l2', initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False)\n",
        "print(X.sum()/batch_size)\n",
        "print(x_adv.sum()/batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cP1lR7xHCGbC",
        "outputId": "d0f03a73-0f15-47c0-92d7-74469f378ce4"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PGD: Attack effectiveness 98.438%.\n",
            "tensor(26.6289)\n",
            "tensor(44.4180)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_adv = pgd(X, y, model, k=50, step_length=1., norm='l1', initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False)\n",
        "print(X.sum()/batch_size)\n",
        "print(x_adv.sum()/batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nK611ZO4973",
        "outputId": "06bbc711-ef8f-4880-97a2-6067606f1264"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PGD: Attack effectiveness 100.000%.\n",
            "tensor(26.6289)\n",
            "tensor(29.4453)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_adv = bca_k(X, y, model, k=53, is_report_loss_diff=True, use_sample=False)\n",
        "print(X.sum()/batch_size)\n",
        "print(x_adv.sum()/batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2xuFvYHAI08",
        "outputId": "d3e1266f-4a76-42b7-f525-24569adf1069"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bca_k: attack effectiveness 97.266%.\n",
            "tensor(26.6289)\n",
            "tensor(76.7188)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_loss(x,y,model):\n",
        "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "    outputs = model(x)\n",
        "    loss = criterion(outputs, y.view(-1).long())\n",
        "    _, predicted = torch.topk(outputs, k=1)\n",
        "    done = (predicted != y).squeeze()\n",
        "\n",
        "    return loss, done"
      ],
      "metadata": {
        "id": "sS1YupQG28Fi"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = X\n",
        "steps_max=5\n",
        "attack_list = ['linf', 'l2', 'l1']\n",
        "is_sample = False\n",
        "varepsilon = 1e-20\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    loss, done = get_loss(x,y,model) #shape:[samples],[samples]\n",
        "pre_loss = loss\n",
        "n, red_n = x.shape[0], x.shape[1]\n",
        "adv_x = x.detach().clone()\n",
        "stop_flag = torch.zeros(n, dtype=torch.bool) #[samples]\n",
        "\n",
        "for t in range(steps_max):\n",
        "  num_sample_red = n - torch.sum(stop_flag)\n",
        "  print('num_sample_red : ',num_sample_red)\n",
        "  if num_sample_red <= 0:\n",
        "      break\n",
        "\n",
        "  red_label = y[~stop_flag]\n",
        "  pertbx = []\n",
        "\n",
        "\n",
        "  for norm in attack_list:\n",
        "      if norm=='l1':\n",
        "        l1 = pgd(adv_x[~stop_flag], red_label, model, k=50, step_length=1., norm='l1', is_sample=is_sample)\n",
        "        pertbx.append(l1)\n",
        "      elif norm=='l2':\n",
        "        l2 = pgd(adv_x[~stop_flag], red_label, model, k=200, step_length=0.05, norm='l2', is_sample=is_sample)\n",
        "        pertbx.append(l2)\n",
        "      elif norm=='linf':\n",
        "        linf = pgd(adv_x[~stop_flag], red_label, model, k=500, step_length=0.002, norm='linf', is_sample=is_sample)\n",
        "        pertbx.append(linf)\n",
        "      else :\n",
        "        raise ValueError(\"Expect 'l1' or 'l2' or 'linf' norm.\")\n",
        "\n",
        "  # here pertbx.shape = a list of (number of attacks  ,(num_sample_red,features))\n",
        "  pertbx = torch.vstack(pertbx)\n",
        "  # here pertbx.shape = a tensor (num_sample_red*number of attacks samples, features)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    red_label_ext = torch.cat([red_label] * len(attack_list)) #(labels*number of attacks )\n",
        "    loss, done = get_loss(pertbx, red_label_ext,model) #(labels*number of attacks )\n",
        "    loss = loss.reshape(len(attack_list), num_sample_red).permute(1, 0) #(num_sample_red,number of attacks)\n",
        "    done = done.reshape(len(attack_list), num_sample_red).permute(1, 0) #(num_sample_red,number of attacks)\n",
        "\n",
        "    success_flag = torch.any(done, dim=-1) #(num_sample_red)\n",
        "    # for a sample, if there is at least one successful attack, we will select the one with maximum loss;\n",
        "    # while if no attacks evade the victim successful, all perturbed examples are reminded for selection\n",
        "\n",
        "    done[~torch.any(done, dim=-1)] = 1 #loss.shape=done.shape=(samples,number of attacks)\n",
        "    loss = (loss * done.to(torch.float)) + torch.min(loss) * (~done).to(torch.float) #(num_sample_red,number of attacks)\n",
        "    pertbx = pertbx.reshape(len(attack_list), num_sample_red, red_n).permute([1, 0, 2])#(num_sample_red,attacks,features)\n",
        "    _, indices = loss.max(dim=-1) # ans:(samples), max loss among attacks which worked, and max loss among all attacks for sample , none of them worked\n",
        "    adv_x[~stop_flag] = pertbx[torch.arange(num_sample_red), indices]\n",
        "    a_loss = loss[torch.arange(num_sample_red), indices]\n",
        "    pre_stop_flag = stop_flag.clone()\n",
        "    stop_flag[~stop_flag] = (torch.abs(pre_loss[~stop_flag] - a_loss) < varepsilon) | success_flag\n",
        "    pre_loss[~pre_stop_flag] = a_loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGJYJzXD4k9T",
        "outputId": "3c5080ab-2d25-4af9-c420-ab9f0dd56ee5"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_sample_red :  tensor(256)\n",
            "PGD linf: Attack effectiveness 100.000%.\n",
            "PGD l2: Attack effectiveness 93.359%.\n",
            "PGD l1: Attack effectiveness 100.000%.\n",
            "num_sample_red :  tensor(0)\n"
          ]
        }
      ]
    }
  ]
}