{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mostafa-ja/mal_adv3/blob/main/malware_cnn2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming binary_vector is your 1D binary vector of length 10000\n",
        "binary_vector = np.random.randint(2, size=9800)\n",
        "\n",
        "# Reshape the vector into a 2D array with each element being an 8-length binary vector\n",
        "image = np.reshape(binary_vector, (35, 35, 8))\n",
        "\n",
        "# Convert binary values to gray-scale intensities\n",
        "gray_image = np.packbits(image, axis=-1)\n",
        "\n",
        "# Display the gray-scale image\n",
        "plt.imshow(gray_image, cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "4ZG8enqYt5ga",
        "outputId": "cad3e974-7ddb-4542-809d-d1fe09b8baa8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZfX_N-gQHKp",
        "outputId": "82d6a8b9-0ab9-4ef3-8636-dd8466d29af6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv3/raw/main/data/X_redefined_sparse_matrix.npz\n",
            "To: /content/X_redefined_sparse_matrix.npz\n",
            "100%|██████████| 2.31M/2.31M [00:00<00:00, 13.9MB/s]\n",
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv3/raw/main/data/labels.pt\n",
            "To: /content/labels.pt\n",
            "100%|██████████| 517k/517k [00:00<00:00, 6.80MB/s]\n"
          ]
        }
      ],
      "source": [
        "download_links = ['https://github.com/mostafa-ja/mal_adv3/raw/main/data/X_redefined_sparse_matrix.npz',\n",
        "                  'https://github.com/mostafa-ja/mal_adv3/raw/main/data/labels.pt'\n",
        "]\n",
        "\n",
        "\n",
        "import gdown\n",
        "output_filepath = '/content/'\n",
        "for link in download_links:\n",
        "  gdown.download(link, output_filepath)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy import sparse\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "import time\n",
        "\n",
        "\n",
        "torch.manual_seed(0)\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usjRDnBCQK9l",
        "outputId": "2d95236b-4ebc-45cc-96e2-1dc06fffccbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "X_redefined = sparse.load_npz(\"X_redefined_sparse_matrix.npz\")\n",
        "labels_tensor = torch.load('labels.pt')\n",
        "\n",
        "# Split data into train, validation, and test sets with stratified sampling\n",
        "X_train_val, X_test, labels_train_val, labels_test = train_test_split(X_redefined, labels_tensor, test_size=0.2, stratify=labels_tensor, random_state=42)\n",
        "X_train, X_val, labels_train, labels_val = train_test_split(X_train_val, labels_train_val, test_size=0.2, stratify=labels_train_val, random_state=42)\n",
        "\n",
        "# Combine features and labels into datasets\n",
        "# we use dtype=torch.int8, for Memory-Efficient here, later we will convert to float\n",
        "train_dataset = TensorDataset(torch.tensor(X_train.toarray(), dtype=torch.int8), labels_train)\n",
        "val_dataset = TensorDataset(torch.tensor(X_val.toarray(), dtype=torch.int8), labels_val)\n",
        "test_dataset = TensorDataset(torch.tensor(X_test.toarray(), dtype=torch.int8), labels_test)\n",
        "\n",
        "# Clear unnecessary variables\n",
        "del X_redefined, labels_tensor, X_train_val, X_test, labels_train_val, labels_test, X_train, X_val, labels_train, labels_val"
      ],
      "metadata": {
        "id": "OlfUNSCJQQiN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the DataLoader for training, validation, and test sets\n",
        "batch_size = 256\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "_DeOfARzQRc6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pad_binary_vector(binary_vector, new_size):\n",
        "    batch_size, vector_length = binary_vector.size()\n",
        "\n",
        "    # Calculate the number of zeros to add\n",
        "    num_zeros = new_size - vector_length\n",
        "\n",
        "    # Create a tensor filled with zeros\n",
        "    zeros_tensor = torch.zeros(batch_size, num_zeros, dtype=torch.int)\n",
        "\n",
        "    # Concatenate the binary vector with the zeros tensor along the second dimension\n",
        "    padded_binary_vector = torch.cat([binary_vector, zeros_tensor], dim=1)\n",
        "\n",
        "    return padded_binary_vector"
      ],
      "metadata": {
        "id": "U57qM9nEH6ki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def batch_binary_vectors_to_gray_images(binary_vectors, image_size=36):\n",
        "    \"\"\"\n",
        "    Convert a batch of binary vectors to gray-scale images.\n",
        "\n",
        "    Parameters:\n",
        "        batch_binary_vectors (numpy.ndarray): Batch of binary vectors with shape (batch_size, vector_length).\n",
        "        image_size (int): Size of the square image (default is 36).\n",
        "\n",
        "    Returns:\n",
        "        gray_images: Batch of gray-scale images with shape (batch_size, image_size, image_size).\n",
        "    \"\"\"\n",
        "    batch_binary_vectors = pad_binary_vector(binary_vectors, 10368)\n",
        "\n",
        "    # Reshape each binary vector in the batch into a 2D array with each element being an 8-length binary vector\n",
        "    batch_images = np.reshape(batch_binary_vectors, (-1, image_size, image_size, 8))\n",
        "\n",
        "    # Convert binary values to gray-scale intensities\n",
        "    gray_images = np.packbits(batch_images, axis=-1)\n",
        "\n",
        "    # Remove the last dimension (single channel) from the gray_images array\n",
        "    gray_images = np.squeeze(gray_images, axis=-1)\n",
        "\n",
        "    return gray_images\n"
      ],
      "metadata": {
        "id": "yo0LOBhSIDd2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for X,Y in train_loader:\n",
        "  print(X.shape)\n",
        "  print(Y.shape)\n",
        "  break\n",
        "\n",
        "m = batch_binary_vectors_to_gray_images(X, image_size=36)\n",
        "print(m.shape)\n",
        "\n",
        "plt.imshow(m[2], cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "ev4l8hNVIMPA",
        "outputId": "ebbbbabf-cab0-4f59-e3c0-8fafee26bd35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([256, 10000])\n",
            "torch.Size([256, 1])\n",
            "(256, 36, 36)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.zeros(256, 10368, dtype=torch.int)\n",
        "a[:,:10000] =  X\n",
        "\n",
        "m = batch_binary_vectors_to_gray_images(a, image_size=36)\n",
        "print(m.shape)\n",
        "\n",
        "plt.imshow(m[2], cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "NvbXIKk5I4_7",
        "outputId": "3e901740-56f5-43e1-b1e6-23240bfb741a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(256, 36, 36)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)  # Change input channels from 1 to 2\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1, stride=2)\n",
        "        self.conv3 = nn.Conv2d(64, 64, 3, padding=1, stride=2)\n",
        "        self.fc1 = nn.Linear(64 * 9 * 9, 64)\n",
        "        self.fc2 = nn.Linear(64, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.unsqueeze(1)\n",
        "        x = nn.functional.relu(self.conv1(x))\n",
        "        x = nn.functional.relu(self.conv2(x))\n",
        "        x = nn.functional.relu(self.conv3(x))\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = nn.functional.relu(self.fc1(x))\n",
        "        x = self.sigmoid(self.fc2(x))\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "FQ1ZC4oXI7ar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "# Create an instance of the model and move it to the GPU\n",
        "model = CNN().to(device)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
        "\n",
        "# Initialize variables to track best F1 score and corresponding model state\n",
        "best_f1_score = 0.0\n",
        "best_model_state = None\n",
        "\n",
        "# Train the model\n",
        "num_epochs = 50\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct_train = 0\n",
        "    total_train = 0\n",
        "    for X_train, labels_train in train_loader:\n",
        "        # Move data to GPU\n",
        "        labels_train = labels_train.to(device)\n",
        "        images_train = torch.tensor(batch_binary_vectors_to_gray_images(X_train, image_size=36),device=device) / 255.0\n",
        "        optimizer.zero_grad()\n",
        "        outputs_train = model(images_train)\n",
        "        loss_train = criterion(outputs_train.squeeze(), labels_train.squeeze())\n",
        "        loss_train.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss_train.item()\n",
        "\n",
        "        # Calculate training accuracy\n",
        "        predicted_train = torch.round(outputs_train.squeeze())\n",
        "        total_train += labels_train.size(0)\n",
        "        correct_train += (predicted_train == labels_train.squeeze()).sum().item()\n",
        "\n",
        "    train_accuracy = 100 * correct_train / total_train\n",
        "    avg_loss = running_loss / len(train_loader)\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%\")\n",
        "\n",
        "    # Evaluate the model on the validation dataset\n",
        "    model.eval()\n",
        "    true_labels_val = []\n",
        "    predicted_labels_val = []\n",
        "    with torch.no_grad():\n",
        "        for X_val, labels_val in val_loader:\n",
        "            labels_val = labels_val.to(device)\n",
        "            val_images = torch.tensor(batch_binary_vectors_to_gray_images(X_val, image_size=36),device=device) / 255.0\n",
        "            val_outputs = model(val_images)\n",
        "            predicted_val = torch.round(val_outputs.squeeze())\n",
        "\n",
        "            # Append true and predicted labels to the lists\n",
        "            true_labels_val.extend(labels_val.squeeze().tolist())\n",
        "            predicted_labels_val.extend(predicted_val.tolist())\n",
        "\n",
        "    # Convert the lists to numpy arrays\n",
        "    true_labels_val = np.array(true_labels_val)\n",
        "    predicted_labels_val = np.array(predicted_labels_val)\n",
        "\n",
        "    # Compute precision, recall, and F1 score for validation set\n",
        "    precision_val = precision_score(true_labels_val, predicted_labels_val)\n",
        "    recall_val = recall_score(true_labels_val, predicted_labels_val)\n",
        "    f1_val = f1_score(true_labels_val, predicted_labels_val)\n",
        "\n",
        "    print(f\"Validation Precision: {precision_val:.4f}, Recall: {recall_val:.4f}, F1 Score: {f1_val:.4f}\")\n",
        "\n",
        "    # Evaluate the model on the test dataset\n",
        "    true_labels_test = []\n",
        "    predicted_labels_test = []\n",
        "    with torch.no_grad():\n",
        "        for X_test, labels_test in test_loader:\n",
        "            labels_test = labels_test.to(device)\n",
        "            test_images = torch.tensor(batch_binary_vectors_to_gray_images(X_test, image_size=36),device=device) / 255.0\n",
        "            test_outputs = model(test_images)\n",
        "            predicted_test = torch.round(test_outputs.squeeze())\n",
        "\n",
        "            # Append true and predicted labels to the lists\n",
        "            true_labels_test.extend(labels_test.squeeze().tolist())\n",
        "            predicted_labels_test.extend(predicted_test.tolist())\n",
        "\n",
        "    # Convert the lists to numpy arrays\n",
        "    true_labels_test = np.array(true_labels_test)\n",
        "    predicted_labels_test = np.array(predicted_labels_test)\n",
        "\n",
        "    # Compute precision, recall, and F1 score for test set\n",
        "    precision_test = precision_score(true_labels_test, predicted_labels_test)\n",
        "    recall_test = recall_score(true_labels_test, predicted_labels_test)\n",
        "    f1_test = f1_score(true_labels_test, predicted_labels_test)\n",
        "\n",
        "    print(f\"Test Precision: {precision_test:.4f}, Recall: {recall_test:.4f}, F1 Score: {f1_test:.4f}\")\n",
        "\n",
        "    # Check if the current model has the best F1 score\n",
        "    if f1_val > best_f1_score:\n",
        "        best_f1_score = f1_val\n",
        "        best_model_state = model.state_dict()\n",
        "\n",
        "# Save the best model based on F1 score\n",
        "if best_model_state is not None:\n",
        "    torch.save(best_model_state, 'best_model.pth')\n",
        "    print(\"Best model saved.\")\n",
        "\n",
        "# After training, print final accuracy on the test set\n",
        "model.load_state_dict(best_model_state)  # Load the best model's state dictionary\n",
        "model.eval()\n",
        "correct_test = 0\n",
        "total_test = 0\n",
        "with torch.no_grad():\n",
        "    for X_test, labels_test in test_loader:\n",
        "        labels_test = labels_test.to(device)\n",
        "        test_images = torch.tensor(batch_binary_vectors_to_gray_images(X_test, image_size=36),device=device) / 255.0\n",
        "        test_outputs = model(test_images)\n",
        "        predicted_test = torch.round(test_outputs.squeeze())\n",
        "        total_test += labels_test.size(0)\n",
        "        correct_test += (predicted_test == labels_test.squeeze()).sum().item()\n",
        "\n",
        "test_accuracy = 100 * correct_test / total_test\n",
        "print(f\"Accuracy on test set: {test_accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqlRmBJcvCIO",
        "outputId": "5b8ea4d3-c856-4b37-b296-0adf9d9ef0ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/50], Train Loss: 0.1474, Train Accuracy: 95.99%\n",
            "Validation Precision: 0.7282, Recall: 0.4876, F1 Score: 0.5841\n",
            "Test Precision: 0.7304, Recall: 0.4703, F1 Score: 0.5722\n",
            "Epoch [2/50], Train Loss: 0.0771, Train Accuracy: 97.46%\n",
            "Validation Precision: 0.7122, Recall: 0.7506, F1 Score: 0.7309\n",
            "Test Precision: 0.7286, Recall: 0.7581, F1 Score: 0.7431\n",
            "Epoch [3/50], Train Loss: 0.0658, Train Accuracy: 97.88%\n",
            "Validation Precision: 0.8854, Recall: 0.6596, F1 Score: 0.7560\n",
            "Test Precision: 0.8905, Recall: 0.6439, F1 Score: 0.7474\n",
            "Epoch [4/50], Train Loss: 0.0581, Train Accuracy: 98.19%\n",
            "Validation Precision: 0.8648, Recall: 0.7404, F1 Score: 0.7978\n",
            "Test Precision: 0.8734, Recall: 0.7383, F1 Score: 0.8002\n",
            "Epoch [5/50], Train Loss: 0.0549, Train Accuracy: 98.27%\n",
            "Validation Precision: 0.9195, Recall: 0.6933, F1 Score: 0.7905\n",
            "Test Precision: 0.9216, Recall: 0.6763, F1 Score: 0.7801\n",
            "Epoch [6/50], Train Loss: 0.0499, Train Accuracy: 98.44%\n",
            "Validation Precision: 0.8972, Recall: 0.7652, F1 Score: 0.8260\n",
            "Test Precision: 0.8954, Recall: 0.7464, F1 Score: 0.8141\n",
            "Epoch [7/50], Train Loss: 0.0463, Train Accuracy: 98.55%\n",
            "Validation Precision: 0.8828, Recall: 0.7955, F1 Score: 0.8369\n",
            "Test Precision: 0.8827, Recall: 0.7779, F1 Score: 0.8270\n",
            "Epoch [8/50], Train Loss: 0.0427, Train Accuracy: 98.69%\n",
            "Validation Precision: 0.8844, Recall: 0.8079, F1 Score: 0.8444\n",
            "Test Precision: 0.8928, Recall: 0.8013, F1 Score: 0.8445\n",
            "Epoch [9/50], Train Loss: 0.0399, Train Accuracy: 98.75%\n",
            "Validation Precision: 0.8648, Recall: 0.8483, F1 Score: 0.8565\n",
            "Test Precision: 0.8781, Recall: 0.8354, F1 Score: 0.8562\n",
            "Epoch [10/50], Train Loss: 0.0377, Train Accuracy: 98.83%\n",
            "Validation Precision: 0.8536, Recall: 0.8517, F1 Score: 0.8526\n",
            "Test Precision: 0.8702, Recall: 0.8498, F1 Score: 0.8599\n",
            "Epoch [11/50], Train Loss: 0.0359, Train Accuracy: 98.92%\n",
            "Validation Precision: 0.9077, Recall: 0.8393, F1 Score: 0.8722\n",
            "Test Precision: 0.9155, Recall: 0.8282, F1 Score: 0.8697\n",
            "Epoch [12/50], Train Loss: 0.0336, Train Accuracy: 99.00%\n",
            "Validation Precision: 0.9158, Recall: 0.8191, F1 Score: 0.8648\n",
            "Test Precision: 0.9158, Recall: 0.8121, F1 Score: 0.8608\n",
            "Epoch [13/50], Train Loss: 0.0317, Train Accuracy: 99.05%\n",
            "Validation Precision: 0.9152, Recall: 0.8371, F1 Score: 0.8744\n",
            "Test Precision: 0.9186, Recall: 0.8219, F1 Score: 0.8676\n",
            "Epoch [14/50], Train Loss: 0.0296, Train Accuracy: 99.13%\n",
            "Validation Precision: 0.9290, Recall: 0.8382, F1 Score: 0.8813\n",
            "Test Precision: 0.9242, Recall: 0.8228, F1 Score: 0.8706\n",
            "Epoch [15/50], Train Loss: 0.0291, Train Accuracy: 99.12%\n",
            "Validation Precision: 0.8828, Recall: 0.8629, F1 Score: 0.8727\n",
            "Test Precision: 0.9040, Recall: 0.8552, F1 Score: 0.8789\n",
            "Epoch [16/50], Train Loss: 0.0271, Train Accuracy: 99.20%\n",
            "Validation Precision: 0.9107, Recall: 0.8596, F1 Score: 0.8844\n",
            "Test Precision: 0.9200, Recall: 0.8480, F1 Score: 0.8825\n",
            "Epoch [17/50], Train Loss: 0.0258, Train Accuracy: 99.25%\n",
            "Validation Precision: 0.9071, Recall: 0.8663, F1 Score: 0.8862\n",
            "Test Precision: 0.9172, Recall: 0.8471, F1 Score: 0.8808\n",
            "Epoch [18/50], Train Loss: 0.0244, Train Accuracy: 99.29%\n",
            "Validation Precision: 0.9349, Recall: 0.8393, F1 Score: 0.8845\n",
            "Test Precision: 0.9244, Recall: 0.8246, F1 Score: 0.8717\n",
            "Epoch [19/50], Train Loss: 0.0225, Train Accuracy: 99.34%\n",
            "Validation Precision: 0.8867, Recall: 0.8798, F1 Score: 0.8832\n",
            "Test Precision: 0.8948, Recall: 0.8723, F1 Score: 0.8834\n",
            "Epoch [20/50], Train Loss: 0.0218, Train Accuracy: 99.36%\n",
            "Validation Precision: 0.9013, Recall: 0.8618, F1 Score: 0.8811\n",
            "Test Precision: 0.9164, Recall: 0.8579, F1 Score: 0.8862\n",
            "Epoch [21/50], Train Loss: 0.0210, Train Accuracy: 99.40%\n",
            "Validation Precision: 0.9269, Recall: 0.8551, F1 Score: 0.8895\n",
            "Test Precision: 0.9260, Recall: 0.8444, F1 Score: 0.8833\n",
            "Epoch [22/50], Train Loss: 0.0195, Train Accuracy: 99.44%\n",
            "Validation Precision: 0.9185, Recall: 0.8607, F1 Score: 0.8886\n",
            "Test Precision: 0.9285, Recall: 0.8525, F1 Score: 0.8889\n",
            "Epoch [23/50], Train Loss: 0.0194, Train Accuracy: 99.44%\n",
            "Validation Precision: 0.9300, Recall: 0.8213, F1 Score: 0.8723\n",
            "Test Precision: 0.9442, Recall: 0.8210, F1 Score: 0.8783\n",
            "Epoch [24/50], Train Loss: 0.0181, Train Accuracy: 99.48%\n",
            "Validation Precision: 0.9373, Recall: 0.8393, F1 Score: 0.8856\n",
            "Test Precision: 0.9425, Recall: 0.8255, F1 Score: 0.8802\n",
            "Epoch [25/50], Train Loss: 0.0176, Train Accuracy: 99.47%\n",
            "Validation Precision: 0.9121, Recall: 0.8629, F1 Score: 0.8868\n",
            "Test Precision: 0.9237, Recall: 0.8597, F1 Score: 0.8905\n",
            "Epoch [26/50], Train Loss: 0.0168, Train Accuracy: 99.52%\n",
            "Validation Precision: 0.9105, Recall: 0.8798, F1 Score: 0.8949\n",
            "Test Precision: 0.9155, Recall: 0.8669, F1 Score: 0.8905\n",
            "Epoch [27/50], Train Loss: 0.0166, Train Accuracy: 99.51%\n",
            "Validation Precision: 0.9396, Recall: 0.8213, F1 Score: 0.8765\n",
            "Test Precision: 0.9483, Recall: 0.8076, F1 Score: 0.8723\n",
            "Epoch [28/50], Train Loss: 0.0157, Train Accuracy: 99.53%\n",
            "Validation Precision: 0.9220, Recall: 0.8629, F1 Score: 0.8915\n",
            "Test Precision: 0.9320, Recall: 0.8498, F1 Score: 0.8890\n",
            "Epoch [29/50], Train Loss: 0.0148, Train Accuracy: 99.55%\n",
            "Validation Precision: 0.9470, Recall: 0.8225, F1 Score: 0.8803\n",
            "Test Precision: 0.9436, Recall: 0.8121, F1 Score: 0.8729\n",
            "Epoch [30/50], Train Loss: 0.0147, Train Accuracy: 99.57%\n",
            "Validation Precision: 0.9422, Recall: 0.8427, F1 Score: 0.8897\n",
            "Test Precision: 0.9450, Recall: 0.8336, F1 Score: 0.8858\n",
            "Epoch [31/50], Train Loss: 0.0136, Train Accuracy: 99.59%\n",
            "Validation Precision: 0.8785, Recall: 0.8854, F1 Score: 0.8819\n",
            "Test Precision: 0.8962, Recall: 0.8930, F1 Score: 0.8946\n",
            "Epoch [32/50], Train Loss: 0.0133, Train Accuracy: 99.62%\n",
            "Validation Precision: 0.9233, Recall: 0.8652, F1 Score: 0.8933\n",
            "Test Precision: 0.9351, Recall: 0.8552, F1 Score: 0.8934\n",
            "Epoch [33/50], Train Loss: 0.0129, Train Accuracy: 99.61%\n",
            "Validation Precision: 0.9274, Recall: 0.8618, F1 Score: 0.8934\n",
            "Test Precision: 0.9393, Recall: 0.8489, F1 Score: 0.8918\n",
            "Epoch [34/50], Train Loss: 0.0120, Train Accuracy: 99.63%\n",
            "Validation Precision: 0.9377, Recall: 0.8281, F1 Score: 0.8795\n",
            "Test Precision: 0.9484, Recall: 0.8103, F1 Score: 0.8739\n",
            "Epoch [35/50], Train Loss: 0.0121, Train Accuracy: 99.63%\n",
            "Validation Precision: 0.9296, Recall: 0.8607, F1 Score: 0.8938\n",
            "Test Precision: 0.9349, Recall: 0.8399, F1 Score: 0.8849\n",
            "Epoch [36/50], Train Loss: 0.0116, Train Accuracy: 99.65%\n",
            "Validation Precision: 0.8930, Recall: 0.8910, F1 Score: 0.8920\n",
            "Test Precision: 0.9025, Recall: 0.8822, F1 Score: 0.8922\n",
            "Epoch [37/50], Train Loss: 0.0109, Train Accuracy: 99.68%\n",
            "Validation Precision: 0.9299, Recall: 0.8640, F1 Score: 0.8957\n",
            "Test Precision: 0.9396, Recall: 0.8534, F1 Score: 0.8944\n",
            "Epoch [38/50], Train Loss: 0.0107, Train Accuracy: 99.66%\n",
            "Validation Precision: 0.9062, Recall: 0.8899, F1 Score: 0.8980\n",
            "Test Precision: 0.9103, Recall: 0.8759, F1 Score: 0.8928\n",
            "Epoch [39/50], Train Loss: 0.0106, Train Accuracy: 99.65%\n",
            "Validation Precision: 0.9226, Recall: 0.8843, F1 Score: 0.9030\n",
            "Test Precision: 0.9235, Recall: 0.8687, F1 Score: 0.8953\n",
            "Epoch [40/50], Train Loss: 0.0101, Train Accuracy: 99.68%\n",
            "Validation Precision: 0.9001, Recall: 0.9011, F1 Score: 0.9006\n",
            "Test Precision: 0.9135, Recall: 0.8831, F1 Score: 0.8980\n",
            "Epoch [41/50], Train Loss: 0.0098, Train Accuracy: 99.70%\n",
            "Validation Precision: 0.9385, Recall: 0.8573, F1 Score: 0.8961\n",
            "Test Precision: 0.9504, Recall: 0.8444, F1 Score: 0.8943\n",
            "Epoch [42/50], Train Loss: 0.0101, Train Accuracy: 99.67%\n",
            "Validation Precision: 0.8793, Recall: 0.9169, F1 Score: 0.8977\n",
            "Test Precision: 0.8900, Recall: 0.9092, F1 Score: 0.8995\n",
            "Epoch [43/50], Train Loss: 0.0094, Train Accuracy: 99.70%\n",
            "Validation Precision: 0.8882, Recall: 0.9101, F1 Score: 0.8990\n",
            "Test Precision: 0.9112, Recall: 0.9047, F1 Score: 0.9079\n",
            "Epoch [44/50], Train Loss: 0.0087, Train Accuracy: 99.74%\n",
            "Validation Precision: 0.9372, Recall: 0.8719, F1 Score: 0.9034\n",
            "Test Precision: 0.9440, Recall: 0.8489, F1 Score: 0.8939\n",
            "Epoch [45/50], Train Loss: 0.0089, Train Accuracy: 99.72%\n",
            "Validation Precision: 0.9070, Recall: 0.8989, F1 Score: 0.9029\n",
            "Test Precision: 0.9164, Recall: 0.8876, F1 Score: 0.9018\n",
            "Epoch [46/50], Train Loss: 0.0088, Train Accuracy: 99.72%\n",
            "Validation Precision: 0.9245, Recall: 0.8944, F1 Score: 0.9092\n",
            "Test Precision: 0.9304, Recall: 0.8777, F1 Score: 0.9033\n",
            "Epoch [47/50], Train Loss: 0.0081, Train Accuracy: 99.75%\n",
            "Validation Precision: 0.9180, Recall: 0.8933, F1 Score: 0.9055\n",
            "Test Precision: 0.9221, Recall: 0.8732, F1 Score: 0.8970\n",
            "Epoch [48/50], Train Loss: 0.0085, Train Accuracy: 99.73%\n",
            "Validation Precision: 0.9272, Recall: 0.8876, F1 Score: 0.9070\n",
            "Test Precision: 0.9287, Recall: 0.8669, F1 Score: 0.8967\n",
            "Epoch [49/50], Train Loss: 0.0081, Train Accuracy: 99.76%\n",
            "Validation Precision: 0.9284, Recall: 0.8888, F1 Score: 0.9082\n",
            "Test Precision: 0.9286, Recall: 0.8777, F1 Score: 0.9025\n",
            "Epoch [50/50], Train Loss: 0.0081, Train Accuracy: 99.75%\n",
            "Validation Precision: 0.9542, Recall: 0.8663, F1 Score: 0.9081\n",
            "Test Precision: 0.9521, Recall: 0.8408, F1 Score: 0.8930\n",
            "Best model saved.\n",
            "Accuracy on test set: 99.13%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3qZsw4593yT8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the best model\n",
        "best_model_state = torch.load('best_model.pth')\n",
        "model = CNN()\n",
        "model.load_state_dict(best_model_state)\n",
        "model.eval()\n",
        "\n",
        "# Move model to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "# Initialize test metrics\n",
        "true_labels_test = []\n",
        "predicted_labels_test = []\n",
        "\n",
        "# Perform testing\n",
        "with torch.no_grad():\n",
        "    for X_test, labels_test in test_loader:\n",
        "        labels_test = labels_test.to(device)\n",
        "        test_images = torch.tensor(batch_binary_vectors_to_gray_images(X_test, image_size=36),device=device) / 255.0\n",
        "        test_outputs = model(test_images)\n",
        "        predicted_test = torch.round(test_outputs.squeeze())\n",
        "\n",
        "        # Append true and predicted labels to the lists\n",
        "        true_labels_test.extend(labels_test.squeeze().tolist())\n",
        "        predicted_labels_test.extend(predicted_test.tolist())\n",
        "\n",
        "# Convert the lists to numpy arrays\n",
        "true_labels_test = np.array(true_labels_test)\n",
        "predicted_labels_test = np.array(predicted_labels_test)\n",
        "\n",
        "# Compute precision, recall, and F1 score for test set\n",
        "precision_test = precision_score(true_labels_test, predicted_labels_test)\n",
        "recall_test = recall_score(true_labels_test, predicted_labels_test)\n",
        "f1_test = f1_score(true_labels_test, predicted_labels_test)\n",
        "\n",
        "print(f\"Test Precision: {precision_test:.4f}, Recall: {recall_test:.4f}, F1 Score: {f1_test:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zsziOGQE3K-k",
        "outputId": "e55f56e1-3175-4508-a42f-e039907ca77f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Precision: 0.9521, Recall: 0.8408, F1 Score: 0.8930\n"
          ]
        }
      ]
    }
  ]
}